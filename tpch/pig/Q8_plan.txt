48   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
49   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
684  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1461 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-default-f80a47a4-5b58-4f7d-bd2d-cd740b5d19c5
1461 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2751 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 2 time(s).
2790 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2823 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2862 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2960 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $5, $6, $7, $8
2963 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $4, $5, $6
2963 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $3
2964 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $1, $2, $4, $5, $6, $7
2964 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for part: $1, $2, $3, $5, $6, $7, $8
2965 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $3, $4, $7, $8, $9, $10, $11, $12, $13, $14, $15
2965 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for region: $2
#-----------------------------------------------
# New Logical Plan:
#-----------------------------------------------
sortResult: (Name: LOStore Schema: group#156:chararray,#170:double)ColumnPrune:OutputUids=[170, 156]ColumnPrune:InputUids=[170, 156]
|
|---sortResult: (Name: LOSort Schema: group#156:chararray,#170:double)ColumnPrune:OutputUids=[170, 156]ColumnPrune:InputUids=[170, 156]
    |   |
    |   group:(Name: Project Type: chararray Uid: 156 Input: 0 Column: 0)
    |
    |---sumResult: (Name: LOForEach Schema: group#156:chararray,#170:double)ColumnPrune:OutputUids=[170, 156]ColumnPrune:InputUids=[162, 156]
        |   |
        |   (Name: LOGenerate[false,false] Schema: group#156:chararray,#170:double)ColumnPrune:OutputUids=[170, 156]ColumnPrune:InputUids=[162, 156]
        |   |   |
        |   |   group:(Name: Project Type: chararray Uid: 156 Input: 0 Column: (*))
        |   |   |
        |   |   (Name: Divide Type: double Uid: 170)
        |   |   |
        |   |   |---(Name: UserFunc(org.apache.pig.builtin.DoubleSum) Type: double Uid: 166)
        |   |   |   |
        |   |   |   |---(Name: Dereference Type: bag Uid: 165 Column:[2])
        |   |   |       |
        |   |   |       |---sels1:(Name: Project Type: bag Uid: 162 Input: 1 Column: (*))
        |   |   |
        |   |   |---(Name: UserFunc(org.apache.pig.builtin.DoubleSum) Type: double Uid: 169)
        |   |       |
        |   |       |---(Name: Dereference Type: bag Uid: 168 Column:[1])
        |   |           |
        |   |           |---sels1:(Name: Project Type: bag Uid: 162 Input: 2 Column: (*))
        |   |
        |   |---(Name: LOInnerLoad[0] Schema: group#156:chararray)
        |   |
        |   |---sels1: (Name: LOInnerLoad[1] Schema: o_year#156:chararray,s1::p1::lineitem::volume#153:double,case_volume#161:double)
        |   |
        |   |---sels1: (Name: LOInnerLoad[1] Schema: o_year#156:chararray,s1::p1::lineitem::volume#153:double,case_volume#161:double)
        |
        |---grResult: (Name: LOCogroup Schema: group#156:chararray,sels1#162:bag{#293:tuple(o_year#156:chararray,s1::p1::lineitem::volume#153:double,case_volume#161:double)})ColumnPrune:OutputUids=[162, 156]ColumnPrune:InputUids=[161, 153, 156]
            |   |
            |   o_year:(Name: Project Type: chararray Uid: 156 Input: 0 Column: 0)
            |
            |---sels1: (Name: LOForEach Schema: o_year#156:chararray,s1::p1::lineitem::volume#153:double,case_volume#161:double)ColumnPrune:OutputUids=[161, 153, 156]ColumnPrune:InputUids=[145, 153, 10]
                |   |
                |   (Name: LOGenerate[false,false,false] Schema: o_year#156:chararray,s1::p1::lineitem::volume#153:double,case_volume#161:double)ColumnPrune:OutputUids=[161, 153, 156]ColumnPrune:InputUids=[145, 153, 10]
                |   |   |
                |   |   (Name: UserFunc(org.apache.pig.builtin.SUBSTRING) Type: chararray Uid: 156)
                |   |   |
                |   |   |---o1::forders::o_orderdate:(Name: Project Type: chararray Uid: 10 Input: 0 Column: (*))
                |   |   |
                |   |   |---(Name: Constant Type: int Uid: 154)
                |   |   |
                |   |   |---(Name: Constant Type: int Uid: 155)
                |   |   |
                |   |   s1::p1::lineitem::volume:(Name: Project Type: double Uid: 153 Input: 1 Column: (*))
                |   |   |
                |   |   (Name: BinCond Type: double Uid: 161)
                |   |   |
                |   |   |---(Name: Equal Type: boolean Uid: 158)
                |   |   |   |
                |   |   |   |---s1::n2::nation::n_name:(Name: Project Type: chararray Uid: 145 Input: 2 Column: (*))
                |   |   |   |
                |   |   |   |---(Name: Constant Type: chararray Uid: 157)
                |   |   |
                |   |   |---s1::p1::lineitem::volume:(Name: Project Type: double Uid: 153 Input: 3 Column: (*))
                |   |   |
                |   |   |---(Name: Constant Type: double Uid: 159)
                |   |
                |   |---(Name: LOInnerLoad[1] Schema: o1::forders::o_orderdate#10:chararray)
                |   |
                |   |---(Name: LOInnerLoad[4] Schema: s1::p1::lineitem::volume#153:double)
                |   |
                |   |---(Name: LOInnerLoad[2] Schema: s1::n2::nation::n_name#145:chararray)
                |   |
                |   |---(Name: LOInnerLoad[4] Schema: s1::p1::lineitem::volume#153:double)
                |
                |---l1: (Name: LOJoin(HASH) Schema: o1::forders::o_orderkey#6:long,o1::forders::o_orderdate#10:chararray,s1::n2::nation::n_name#145:chararray,s1::p1::lineitem::l_orderkey#50:long,s1::p1::lineitem::volume#153:double)ColumnPrune:OutputUids=[145, 153, 10]ColumnPrune:InputUids=[145, 50, 6, 153, 10]
                    |   |
                    |   forders::o_orderkey:(Name: Project Type: long Uid: 6 Input: 0 Column: 0)
                    |   |
                    |   p1::lineitem::l_orderkey:(Name: Project Type: long Uid: 50 Input: 1 Column: 1)
                    |
                    |---o1: (Name: LOForEach Schema: forders::o_orderkey#6:long,forders::o_orderdate#10:chararray)
                    |   |   |
                    |   |   (Name: LOGenerate[false,false] Schema: forders::o_orderkey#6:long,forders::o_orderdate#10:chararray)
                    |   |   |   |
                    |   |   |   forders::o_orderkey:(Name: Project Type: long Uid: 6 Input: 0 Column: (*))
                    |   |   |   |
                    |   |   |   forders::o_orderdate:(Name: Project Type: chararray Uid: 10 Input: 1 Column: (*))
                    |   |   |
                    |   |   |---(Name: LOInnerLoad[0] Schema: forders::o_orderkey#6:long)
                    |   |   |
                    |   |   |---(Name: LOInnerLoad[2] Schema: forders::o_orderdate#10:chararray)
                    |   |
                    |   |---o1: (Name: LOJoin(HASH) Schema: forders::o_orderkey#6:long,forders::o_custkey#7:long,forders::o_orderdate#10:chararray,selc1::customer::c_custkey#35:long)ColumnPrune:OutputUids=[6, 10]ColumnPrune:InputUids=[35, 6, 7, 10]
                    |       |   |
                    |       |   o_custkey:(Name: Project Type: long Uid: 7 Input: 0 Column: 1)
                    |       |   |
                    |       |   customer::c_custkey:(Name: Project Type: long Uid: 35 Input: 1 Column: 0)
                    |       |
                    |       |---forders: (Name: LOFilter Schema: o_orderkey#6:long,o_custkey#7:long,o_orderdate#10:chararray)ColumnPrune:OutputUids=[6, 7, 10]ColumnPrune:InputUids=[6, 7, 10]
                    |       |   |   |
                    |       |   |   (Name: And Type: boolean Uid: 262)
                    |       |   |   |
                    |       |   |   |---(Name: LessThanEqual Type: boolean Uid: 132)
                    |       |   |   |   |
                    |       |   |   |   |---o_orderdate:(Name: Project Type: chararray Uid: 10 Input: 0 Column: 2)
                    |       |   |   |   |
                    |       |   |   |   |---(Name: Constant Type: chararray Uid: 131)
                    |       |   |   |
                    |       |   |   |---(Name: GreaterThanEqual Type: boolean Uid: 134)
                    |       |   |       |
                    |       |   |       |---o_orderdate:(Name: Project Type: chararray Uid: 10 Input: 0 Column: 2)
                    |       |   |       |
                    |       |   |       |---(Name: Constant Type: chararray Uid: 133)
                    |       |   |
                    |       |   |---orders: (Name: LOForEach Schema: o_orderkey#6:long,o_custkey#7:long,o_orderdate#10:chararray)ColumnPrune:OutputUids=[6, 7, 10]ColumnPrune:InputUids=[6, 7, 10]
                    |       |       |   |
                    |       |       |   (Name: LOGenerate[false,false,false] Schema: o_orderkey#6:long,o_custkey#7:long,o_orderdate#10:chararray)ColumnPrune:OutputUids=[6, 7, 10]ColumnPrune:InputUids=[6, 7, 10]
                    |       |       |   |   |
                    |       |       |   |   (Name: Cast Type: long Uid: 6)
                    |       |       |   |   |
                    |       |       |   |   |---o_orderkey:(Name: Project Type: bytearray Uid: 6 Input: 0 Column: (*))
                    |       |       |   |   |
                    |       |       |   |   (Name: Cast Type: long Uid: 7)
                    |       |       |   |   |
                    |       |       |   |   |---o_custkey:(Name: Project Type: bytearray Uid: 7 Input: 1 Column: (*))
                    |       |       |   |   |
                    |       |       |   |   (Name: Cast Type: chararray Uid: 10)
                    |       |       |   |   |
                    |       |       |   |   |---o_orderdate:(Name: Project Type: bytearray Uid: 10 Input: 2 Column: (*))
                    |       |       |   |
                    |       |       |   |---(Name: LOInnerLoad[0] Schema: o_orderkey#6:bytearray)
                    |       |       |   |
                    |       |       |   |---(Name: LOInnerLoad[1] Schema: o_custkey#7:bytearray)
                    |       |       |   |
                    |       |       |   |---(Name: LOInnerLoad[2] Schema: o_orderdate#10:bytearray)
                    |       |       |
                    |       |       |---orders: (Name: LOLoad Schema: o_orderkey#6:bytearray,o_custkey#7:bytearray,o_orderdate#10:bytearray)ColumnPrune:OutputUids=[6, 7, 10]ColumnPrune:InputUids=[6, 7, 10]ColumnPrune:RequiredColumns=[0, 1, 4]RequiredFields:[0, 1, 4]
                    |       |
                    |       |---selc1: (Name: LOForEach Schema: customer::c_custkey#35:long)ColumnPrune:OutputUids=[35]ColumnPrune:InputUids=[35]
                    |           |   |
                    |           |   (Name: LOGenerate[false] Schema: customer::c_custkey#35:long)ColumnPrune:OutputUids=[35]ColumnPrune:InputUids=[35]
                    |           |   |   |
                    |           |   |   customer::c_custkey:(Name: Project Type: long Uid: 35 Input: 0 Column: (*))
                    |           |   |
                    |           |   |---(Name: LOInnerLoad[0] Schema: customer::c_custkey#35:long)
                    |           |
                    |           |---c1: (Name: LOJoin(REPLICATED) Schema: customer::c_custkey#35:long,customer::c_nationkey#38:int,seln1::nation::n_nationkey#137:int)ColumnPrune:OutputUids=[35]ColumnPrune:InputUids=[35, 38, 137]
                    |               |   |
                    |               |   c_nationkey:(Name: Project Type: int Uid: 38 Input: 0 Column: 1)
                    |               |   |
                    |               |   nation::n_nationkey:(Name: Project Type: int Uid: 137 Input: 1 Column: 0)
                    |               |
                    |               |---customer: (Name: LOForEach Schema: c_custkey#35:long,c_nationkey#38:int)ColumnPrune:OutputUids=[35, 38]ColumnPrune:InputUids=[35, 38]
                    |               |   |   |
                    |               |   |   (Name: LOGenerate[false,false] Schema: c_custkey#35:long,c_nationkey#38:int)ColumnPrune:OutputUids=[35, 38]ColumnPrune:InputUids=[35, 38]
                    |               |   |   |   |
                    |               |   |   |   (Name: Cast Type: long Uid: 35)
                    |               |   |   |   |
                    |               |   |   |   |---c_custkey:(Name: Project Type: bytearray Uid: 35 Input: 0 Column: (*))
                    |               |   |   |   |
                    |               |   |   |   (Name: Cast Type: int Uid: 38)
                    |               |   |   |   |
                    |               |   |   |   |---c_nationkey:(Name: Project Type: bytearray Uid: 38 Input: 1 Column: (*))
                    |               |   |   |
                    |               |   |   |---(Name: LOInnerLoad[0] Schema: c_custkey#35:bytearray)
                    |               |   |   |
                    |               |   |   |---(Name: LOInnerLoad[1] Schema: c_nationkey#38:bytearray)
                    |               |   |
                    |               |   |---customer: (Name: LOLoad Schema: c_custkey#35:bytearray,c_nationkey#38:bytearray)ColumnPrune:OutputUids=[35, 38]ColumnPrune:InputUids=[35, 38]ColumnPrune:RequiredColumns=[0, 3]RequiredFields:[0, 3]
                    |               |
                    |               |---seln1: (Name: LOForEach Schema: nation::n_nationkey#137:int)ColumnPrune:OutputUids=[137]ColumnPrune:InputUids=[137]
                    |                   |   |
                    |                   |   (Name: LOGenerate[false] Schema: nation::n_nationkey#137:int)ColumnPrune:OutputUids=[137]ColumnPrune:InputUids=[137]
                    |                   |   |   |
                    |                   |   |   nation::n_nationkey:(Name: Project Type: int Uid: 137 Input: 0 Column: (*))
                    |                   |   |
                    |                   |   |---(Name: LOInnerLoad[0] Schema: nation::n_nationkey#137:int)
                    |                   |
                    |                   |---n1: (Name: LOJoin(REPLICATED) Schema: nation::n_nationkey#137:int,nation::n_regionkey#139:int,fregion::r_regionkey#1:int)ColumnPrune:OutputUids=[137]ColumnPrune:InputUids=[1, 137, 139]
                    |                       |   |
                    |                       |   n_regionkey:(Name: Project Type: int Uid: 139 Input: 0 Column: 1)
                    |                       |   |
                    |                       |   r_regionkey:(Name: Project Type: int Uid: 1 Input: 1 Column: 0)
                    |                       |
                    |                       |---nation: (Name: LOSplitOutput Schema: n_nationkey#137:int,n_regionkey#139:int)ColumnPrune:OutputUids=[137, 139]ColumnPrune:InputUids=[33, 31]
                    |                       |   |   |
                    |                       |   |   (Name: Constant Type: boolean Uid: 136)
                    |                       |   |
                    |                       |   |---nation: (Name: LOForEach Schema: n_nationkey#31:int,n_regionkey#33:int)
                    |                       |       |   |
                    |                       |       |   (Name: LOGenerate[false,false] Schema: n_nationkey#31:int,n_regionkey#33:int)
                    |                       |       |   |   |
                    |                       |       |   |   n_nationkey:(Name: Project Type: int Uid: 31 Input: 0 Column: (*))
                    |                       |       |   |   |
                    |                       |       |   |   n_regionkey:(Name: Project Type: int Uid: 33 Input: 1 Column: (*))
                    |                       |       |   |
                    |                       |       |   |---(Name: LOInnerLoad[0] Schema: n_nationkey#31:int)
                    |                       |       |   |
                    |                       |       |   |---(Name: LOInnerLoad[2] Schema: n_regionkey#33:int)
                    |                       |       |
                    |                       |       |---nation: (Name: LOSplit Schema: n_nationkey#31:int,n_name#32:chararray,n_regionkey#33:int)ColumnPrune:OutputUids=[32, 33, 31]ColumnPrune:InputUids=[32, 33, 31]
                    |                       |           |
                    |                       |           |---nation: (Name: LOForEach Schema: n_nationkey#31:int,n_name#32:chararray,n_regionkey#33:int)ColumnPrune:OutputUids=[32, 33, 31]ColumnPrune:InputUids=[32, 33, 31]
                    |                       |               |   |
                    |                       |               |   (Name: LOGenerate[false,false,false] Schema: n_nationkey#31:int,n_name#32:chararray,n_regionkey#33:int)ColumnPrune:OutputUids=[32, 33, 31]ColumnPrune:InputUids=[32, 33, 31]
                    |                       |               |   |   |
                    |                       |               |   |   (Name: Cast Type: int Uid: 31)
                    |                       |               |   |   |
                    |                       |               |   |   |---n_nationkey:(Name: Project Type: bytearray Uid: 31 Input: 0 Column: (*))
                    |                       |               |   |   |
                    |                       |               |   |   (Name: Cast Type: chararray Uid: 32)
                    |                       |               |   |   |
                    |                       |               |   |   |---n_name:(Name: Project Type: bytearray Uid: 32 Input: 1 Column: (*))
                    |                       |               |   |   |
                    |                       |               |   |   (Name: Cast Type: int Uid: 33)
                    |                       |               |   |   |
                    |                       |               |   |   |---n_regionkey:(Name: Project Type: bytearray Uid: 33 Input: 2 Column: (*))
                    |                       |               |   |
                    |                       |               |   |---(Name: LOInnerLoad[0] Schema: n_nationkey#31:bytearray)
                    |                       |               |   |
                    |                       |               |   |---(Name: LOInnerLoad[1] Schema: n_name#32:bytearray)
                    |                       |               |   |
                    |                       |               |   |---(Name: LOInnerLoad[2] Schema: n_regionkey#33:bytearray)
                    |                       |               |
                    |                       |               |---nation: (Name: LOLoad Schema: n_nationkey#31:bytearray,n_name#32:bytearray,n_regionkey#33:bytearray)ColumnPrune:OutputUids=[32, 33, 31]ColumnPrune:InputUids=[32, 33, 31]ColumnPrune:RequiredColumns=[0, 1, 2]RequiredFields:[0, 1, 2]
                    |                       |
                    |                       |---fregion: (Name: LOForEach Schema: r_regionkey#1:int)
                    |                           |   |
                    |                           |   (Name: LOGenerate[false] Schema: r_regionkey#1:int)
                    |                           |   |   |
                    |                           |   |   r_regionkey:(Name: Project Type: int Uid: 1 Input: 0 Column: (*))
                    |                           |   |
                    |                           |   |---(Name: LOInnerLoad[0] Schema: r_regionkey#1:int)
                    |                           |
                    |                           |---fregion: (Name: LOFilter Schema: r_regionkey#1:int,r_name#2:chararray)ColumnPrune:OutputUids=[1]ColumnPrune:InputUids=[1, 2]
                    |                               |   |
                    |                               |   (Name: Equal Type: boolean Uid: 142)
                    |                               |   |
                    |                               |   |---r_name:(Name: Project Type: chararray Uid: 2 Input: 0 Column: 1)
                    |                               |   |
                    |                               |   |---(Name: Constant Type: chararray Uid: 141)
                    |                               |
                    |                               |---region: (Name: LOForEach Schema: r_regionkey#1:int,r_name#2:chararray)ColumnPrune:OutputUids=[1, 2]ColumnPrune:InputUids=[1, 2]
                    |                                   |   |
                    |                                   |   (Name: LOGenerate[false,false] Schema: r_regionkey#1:int,r_name#2:chararray)ColumnPrune:OutputUids=[1, 2]ColumnPrune:InputUids=[1, 2]
                    |                                   |   |   |
                    |                                   |   |   (Name: Cast Type: int Uid: 1)
                    |                                   |   |   |
                    |                                   |   |   |---r_regionkey:(Name: Project Type: bytearray Uid: 1 Input: 0 Column: (*))
                    |                                   |   |   |
                    |                                   |   |   (Name: Cast Type: chararray Uid: 2)
                    |                                   |   |   |
                    |                                   |   |   |---r_name:(Name: Project Type: bytearray Uid: 2 Input: 1 Column: (*))
                    |                                   |   |
                    |                                   |   |---(Name: LOInnerLoad[0] Schema: r_regionkey#1:bytearray)
                    |                                   |   |
                    |                                   |   |---(Name: LOInnerLoad[1] Schema: r_name#2:bytearray)
                    |                                   |
                    |                                   |---region: (Name: LOLoad Schema: r_regionkey#1:bytearray,r_name#2:bytearray)ColumnPrune:OutputUids=[1, 2]ColumnPrune:InputUids=[1, 2]ColumnPrune:RequiredColumns=[0, 1]RequiredFields:[0, 1]
                    |
                    |---s1: (Name: LOForEach Schema: n2::nation::n_name#145:chararray,p1::lineitem::l_orderkey#50:long,p1::lineitem::volume#153:double)
                        |   |
                        |   (Name: LOGenerate[false,false,false] Schema: n2::nation::n_name#145:chararray,p1::lineitem::l_orderkey#50:long,p1::lineitem::volume#153:double)
                        |   |   |
                        |   |   n2::nation::n_name:(Name: Project Type: chararray Uid: 145 Input: 0 Column: (*))
                        |   |   |
                        |   |   p1::lineitem::l_orderkey:(Name: Project Type: long Uid: 50 Input: 1 Column: (*))
                        |   |   |
                        |   |   p1::lineitem::volume:(Name: Project Type: double Uid: 153 Input: 2 Column: (*))
                        |   |
                        |   |---(Name: LOInnerLoad[1] Schema: n2::nation::n_name#145:chararray)
                        |   |
                        |   |---(Name: LOInnerLoad[3] Schema: p1::lineitem::l_orderkey#50:long)
                        |   |
                        |   |---(Name: LOInnerLoad[4] Schema: p1::lineitem::volume#153:double)
                        |
                        |---s1: (Name: LOJoin(HASH) Schema: n2::supplier::s_suppkey#43:long,n2::nation::n_name#145:chararray,p1::lineitem::l_suppkey#52:long,p1::lineitem::l_orderkey#50:long,p1::lineitem::volume#153:double)ColumnPrune:OutputUids=[145, 50, 153]ColumnPrune:InputUids=[145, 50, 52, 153, 43]
                            |   |
                            |   supplier::s_suppkey:(Name: Project Type: long Uid: 43 Input: 0 Column: 0)
                            |   |
                            |   lineitem::l_suppkey:(Name: Project Type: long Uid: 52 Input: 1 Column: 0)
                            |
                            |---n2: (Name: LOForEach Schema: supplier::s_suppkey#43:long,nation::n_name#145:chararray)
                            |   |   |
                            |   |   (Name: LOGenerate[false,false] Schema: supplier::s_suppkey#43:long,nation::n_name#145:chararray)
                            |   |   |   |
                            |   |   |   supplier::s_suppkey:(Name: Project Type: long Uid: 43 Input: 0 Column: (*))
                            |   |   |   |
                            |   |   |   nation::n_name:(Name: Project Type: chararray Uid: 145 Input: 1 Column: (*))
                            |   |   |
                            |   |   |---(Name: LOInnerLoad[0] Schema: supplier::s_suppkey#43:long)
                            |   |   |
                            |   |   |---(Name: LOInnerLoad[3] Schema: nation::n_name#145:chararray)
                            |   |
                            |   |---n2: (Name: LOJoin(REPLICATED) Schema: supplier::s_suppkey#43:long,supplier::s_nationkey#46:int,nation::n_nationkey#144:int,nation::n_name#145:chararray)ColumnPrune:OutputUids=[145, 43]ColumnPrune:InputUids=[144, 145, 43, 46]
                            |       |   |
                            |       |   s_nationkey:(Name: Project Type: int Uid: 46 Input: 0 Column: 1)
                            |       |   |
                            |       |   n_nationkey:(Name: Project Type: int Uid: 144 Input: 1 Column: 0)
                            |       |
                            |       |---supplier: (Name: LOForEach Schema: s_suppkey#43:long,s_nationkey#46:int)ColumnPrune:OutputUids=[43, 46]ColumnPrune:InputUids=[43, 46]
                            |       |   |   |
                            |       |   |   (Name: LOGenerate[false,false] Schema: s_suppkey#43:long,s_nationkey#46:int)ColumnPrune:OutputUids=[43, 46]ColumnPrune:InputUids=[43, 46]
                            |       |   |   |   |
                            |       |   |   |   (Name: Cast Type: long Uid: 43)
                            |       |   |   |   |
                            |       |   |   |   |---s_suppkey:(Name: Project Type: bytearray Uid: 43 Input: 0 Column: (*))
                            |       |   |   |   |
                            |       |   |   |   (Name: Cast Type: int Uid: 46)
                            |       |   |   |   |
                            |       |   |   |   |---s_nationkey:(Name: Project Type: bytearray Uid: 46 Input: 1 Column: (*))
                            |       |   |   |
                            |       |   |   |---(Name: LOInnerLoad[0] Schema: s_suppkey#43:bytearray)
                            |       |   |   |
                            |       |   |   |---(Name: LOInnerLoad[1] Schema: s_nationkey#46:bytearray)
                            |       |   |
                            |       |   |---supplier: (Name: LOLoad Schema: s_suppkey#43:bytearray,s_nationkey#46:bytearray)ColumnPrune:OutputUids=[43, 46]ColumnPrune:InputUids=[43, 46]ColumnPrune:RequiredColumns=[0, 3]RequiredFields:[0, 3]
                            |       |
                            |       |---nation: (Name: LOSplitOutput Schema: n_nationkey#144:int,n_name#145:chararray)ColumnPrune:OutputUids=[144, 145]ColumnPrune:InputUids=[32, 31]
                            |           |   |
                            |           |   (Name: Constant Type: boolean Uid: 143)
                            |           |
                            |           |---nation: (Name: LOForEach Schema: n_nationkey#31:int,n_name#32:chararray)
                            |               |   |
                            |               |   (Name: LOGenerate[false,false] Schema: n_nationkey#31:int,n_name#32:chararray)
                            |               |   |   |
                            |               |   |   n_nationkey:(Name: Project Type: int Uid: 31 Input: 0 Column: (*))
                            |               |   |   |
                            |               |   |   n_name:(Name: Project Type: chararray Uid: 32 Input: 1 Column: (*))
                            |               |   |
                            |               |   |---(Name: LOInnerLoad[0] Schema: n_nationkey#31:int)
                            |               |   |
                            |               |   |---(Name: LOInnerLoad[1] Schema: n_name#32:chararray)
                            |               |
                            |               |---nation: (Name: LOSplit Schema: n_nationkey#31:int,n_name#32:chararray,n_regionkey#33:int)ColumnPrune:OutputUids=[32, 33, 31]ColumnPrune:InputUids=[32, 33, 31]
                            |                   |
                            |                   |---nation: (Name: LOForEach Schema: n_nationkey#31:int,n_name#32:chararray,n_regionkey#33:int)ColumnPrune:OutputUids=[32, 33, 31]ColumnPrune:InputUids=[32, 33, 31]
                            |                       |   |
                            |                       |   (Name: LOGenerate[false,false,false] Schema: n_nationkey#31:int,n_name#32:chararray,n_regionkey#33:int)ColumnPrune:OutputUids=[32, 33, 31]ColumnPrune:InputUids=[32, 33, 31]
                            |                       |   |   |
                            |                       |   |   (Name: Cast Type: int Uid: 31)
                            |                       |   |   |
                            |                       |   |   |---n_nationkey:(Name: Project Type: bytearray Uid: 31 Input: 0 Column: (*))
                            |                       |   |   |
                            |                       |   |   (Name: Cast Type: chararray Uid: 32)
                            |                       |   |   |
                            |                       |   |   |---n_name:(Name: Project Type: bytearray Uid: 32 Input: 1 Column: (*))
                            |                       |   |   |
                            |                       |   |   (Name: Cast Type: int Uid: 33)
                            |                       |   |   |
                            |                       |   |   |---n_regionkey:(Name: Project Type: bytearray Uid: 33 Input: 2 Column: (*))
                            |                       |   |
                            |                       |   |---(Name: LOInnerLoad[0] Schema: n_nationkey#31:bytearray)
                            |                       |   |
                            |                       |   |---(Name: LOInnerLoad[1] Schema: n_name#32:bytearray)
                            |                       |   |
                            |                       |   |---(Name: LOInnerLoad[2] Schema: n_regionkey#33:bytearray)
                            |                       |
                            |                       |---nation: (Name: LOLoad Schema: n_nationkey#31:bytearray,n_name#32:bytearray,n_regionkey#33:bytearray)ColumnPrune:OutputUids=[32, 33, 31]ColumnPrune:InputUids=[32, 33, 31]ColumnPrune:RequiredColumns=[0, 1, 2]RequiredFields:[0, 1, 2]
                            |
                            |---p1: (Name: LOForEach Schema: lineitem::l_suppkey#52:long,lineitem::l_orderkey#50:long,lineitem::volume#153:double)
                                |   |
                                |   (Name: LOGenerate[false,false,false] Schema: lineitem::l_suppkey#52:long,lineitem::l_orderkey#50:long,lineitem::volume#153:double)
                                |   |   |
                                |   |   lineitem::l_suppkey:(Name: Project Type: long Uid: 52 Input: 0 Column: (*))
                                |   |   |
                                |   |   lineitem::l_orderkey:(Name: Project Type: long Uid: 50 Input: 1 Column: (*))
                                |   |   |
                                |   |   lineitem::volume:(Name: Project Type: double Uid: 153 Input: 2 Column: (*))
                                |   |
                                |   |---(Name: LOInnerLoad[2] Schema: lineitem::l_suppkey#52:long)
                                |   |
                                |   |---(Name: LOInnerLoad[3] Schema: lineitem::l_orderkey#50:long)
                                |   |
                                |   |---(Name: LOInnerLoad[4] Schema: lineitem::volume#153:double)
                                |
                                |---p1: (Name: LOJoin(HASH) Schema: fpart::p_partkey#20:long,lineitem::l_partkey#51:long,lineitem::l_suppkey#52:long,lineitem::l_orderkey#50:long,lineitem::volume#153:double)ColumnPrune:OutputUids=[50, 52, 153]ColumnPrune:InputUids=[50, 51, 52, 20, 153]
                                    |   |
                                    |   p_partkey:(Name: Project Type: long Uid: 20 Input: 0 Column: 0)
                                    |   |
                                    |   l_partkey:(Name: Project Type: long Uid: 51 Input: 1 Column: 0)
                                    |
                                    |---fpart: (Name: LOForEach Schema: p_partkey#20:long)
                                    |   |   |
                                    |   |   (Name: LOGenerate[false] Schema: p_partkey#20:long)
                                    |   |   |   |
                                    |   |   |   p_partkey:(Name: Project Type: long Uid: 20 Input: 0 Column: (*))
                                    |   |   |
                                    |   |   |---(Name: LOInnerLoad[0] Schema: p_partkey#20:long)
                                    |   |
                                    |   |---fpart: (Name: LOFilter Schema: p_partkey#20:long,p_type#24:chararray)ColumnPrune:OutputUids=[20]ColumnPrune:InputUids=[20, 24]
                                    |       |   |
                                    |       |   (Name: Equal Type: boolean Uid: 149)
                                    |       |   |
                                    |       |   |---p_type:(Name: Project Type: chararray Uid: 24 Input: 0 Column: 1)
                                    |       |   |
                                    |       |   |---(Name: Constant Type: chararray Uid: 148)
                                    |       |
                                    |       |---part: (Name: LOForEach Schema: p_partkey#20:long,p_type#24:chararray)ColumnPrune:OutputUids=[20, 24]ColumnPrune:InputUids=[20, 24]
                                    |           |   |
                                    |           |   (Name: LOGenerate[false,false] Schema: p_partkey#20:long,p_type#24:chararray)ColumnPrune:OutputUids=[20, 24]ColumnPrune:InputUids=[20, 24]
                                    |           |   |   |
                                    |           |   |   (Name: Cast Type: long Uid: 20)
                                    |           |   |   |
                                    |           |   |   |---p_partkey:(Name: Project Type: bytearray Uid: 20 Input: 0 Column: (*))
                                    |           |   |   |
                                    |           |   |   (Name: Cast Type: chararray Uid: 24)
                                    |           |   |   |
                                    |           |   |   |---p_type:(Name: Project Type: bytearray Uid: 24 Input: 1 Column: (*))
                                    |           |   |
                                    |           |   |---(Name: LOInnerLoad[0] Schema: p_partkey#20:bytearray)
                                    |           |   |
                                    |           |   |---(Name: LOInnerLoad[1] Schema: p_type#24:bytearray)
                                    |           |
                                    |           |---part: (Name: LOLoad Schema: p_partkey#20:bytearray,p_type#24:bytearray)ColumnPrune:OutputUids=[20, 24]ColumnPrune:InputUids=[20, 24]ColumnPrune:RequiredColumns=[0, 4]RequiredFields:[0, 4]
                                    |
                                    |---lineitem: (Name: LOForEach Schema: l_partkey#51:long,l_suppkey#52:long,l_orderkey#50:long,volume#305:double)
                                        |   |
                                        |   (Name: LOGenerate[false,false,false,false] Schema: l_partkey#51:long,l_suppkey#52:long,l_orderkey#50:long,volume#305:double)
                                        |   |   |
                                        |   |   (Name: Cast Type: long Uid: 51)
                                        |   |   |
                                        |   |   |---l_partkey:(Name: Project Type: bytearray Uid: 51 Input: 0 Column: (*))
                                        |   |   |
                                        |   |   (Name: Cast Type: long Uid: 52)
                                        |   |   |
                                        |   |   |---l_suppkey:(Name: Project Type: bytearray Uid: 52 Input: 1 Column: (*))
                                        |   |   |
                                        |   |   (Name: Cast Type: long Uid: 50)
                                        |   |   |
                                        |   |   |---l_orderkey:(Name: Project Type: bytearray Uid: 50 Input: 2 Column: (*))
                                        |   |   |
                                        |   |   (Name: Multiply Type: double Uid: 305)
                                        |   |   |
                                        |   |   |---(Name: Cast Type: double Uid: 55)
                                        |   |   |   |
                                        |   |   |   |---l_extendedprice:(Name: Project Type: bytearray Uid: 55 Input: 3 Column: (*))
                                        |   |   |
                                        |   |   |---(Name: Subtract Type: double Uid: 304)
                                        |   |       |
                                        |   |       |---(Name: Constant Type: double Uid: 302)
                                        |   |       |
                                        |   |       |---(Name: Cast Type: double Uid: 56)
                                        |   |           |
                                        |   |           |---l_discount:(Name: Project Type: bytearray Uid: 56 Input: 4 Column: (*))
                                        |   |
                                        |   |---(Name: LOInnerLoad[1] Schema: l_partkey#51:bytearray)
                                        |   |
                                        |   |---(Name: LOInnerLoad[2] Schema: l_suppkey#52:bytearray)
                                        |   |
                                        |   |---(Name: LOInnerLoad[0] Schema: l_orderkey#50:bytearray)
                                        |   |
                                        |   |---(Name: LOInnerLoad[3] Schema: l_extendedprice#55:bytearray)
                                        |   |
                                        |   |---(Name: LOInnerLoad[4] Schema: l_discount#56:bytearray)
                                        |
                                        |---lineitem: (Name: LOLoad Schema: l_orderkey#50:bytearray,l_partkey#51:bytearray,l_suppkey#52:bytearray,l_extendedprice#55:bytearray,l_discount#56:bytearray)ColumnPrune:OutputUids=[50, 51, 52, 55, 56]ColumnPrune:InputUids=[50, 51, 52, 55, 56]ColumnPrune:RequiredColumns=[0, 1, 2, 5, 6]RequiredFields:[0, 1, 2, 5, 6]
#-----------------------------------------------
# Physical Plan:
#-----------------------------------------------
sortResult: Store(/tpch/out1/Q8out:PigStorage('|')) - scope-247
|
|---sortResult: POSort[bag]() - scope-246
    |   |
    |   Project[chararray][0] - scope-245
    |
    |---sumResult: New For Each(false,false)[bag] - scope-244
        |   |
        |   Project[chararray][0] - scope-233
        |   |
        |   Divide[double] - scope-241
        |   |
        |   |---POUserFunc(org.apache.pig.builtin.DoubleSum)[double] - scope-237
        |   |   |
        |   |   |---Project[bag][2] - scope-236
        |   |       |
        |   |       |---Project[bag][1] - scope-235
        |   |
        |   |---POUserFunc(org.apache.pig.builtin.DoubleSum)[double] - scope-240
        |       |
        |       |---Project[bag][1] - scope-239
        |           |
        |           |---Project[bag][1] - scope-238
        |
        |---grResult: Package(Packager)[tuple]{chararray} - scope-230
            |
            |---grResult: Global Rearrange[tuple] - scope-229
                |
                |---grResult: Local Rearrange[tuple]{chararray}(false) - scope-231
                    |   |
                    |   Project[chararray][0] - scope-232
                    |
                    |---sels1: New For Each(false,false,false)[bag] - scope-228
                        |   |
                        |   POUserFunc(org.apache.pig.builtin.SUBSTRING)[chararray] - scope-216
                        |   |
                        |   |---Project[chararray][1] - scope-213
                        |   |
                        |   |---Constant(0) - scope-214
                        |   |
                        |   |---Constant(4) - scope-215
                        |   |
                        |   Project[double][4] - scope-218
                        |   |
                        |   POBinCond[double] - scope-225
                        |   |
                        |   |---Equal To[boolean] - scope-222
                        |   |   |
                        |   |   |---Project[chararray][2] - scope-220
                        |   |   |
                        |   |   |---Constant(BRAZIL) - scope-221
                        |   |
                        |   |---Project[double][4] - scope-223
                        |   |
                        |   |---Constant(0.0) - scope-224
                        |
                        |---l1: New For Each(true,true)[tuple] - scope-212
                            |   |
                            |   Project[bag][1] - scope-210
                            |   |
                            |   Project[bag][2] - scope-211
                            |
                            |---l1: Package(Packager)[tuple]{long} - scope-205
                                |
                                |---l1: Global Rearrange[tuple] - scope-204
                                    |
                                    |---l1: Local Rearrange[tuple]{long}(false) - scope-206
                                    |   |   |
                                    |   |   Project[long][0] - scope-207
                                    |   |
                                    |   |---o1: New For Each(false,false)[bag] - scope-102
                                    |       |   |
                                    |       |   Project[long][0] - scope-98
                                    |       |   |
                                    |       |   Project[chararray][2] - scope-100
                                    |       |
                                    |       |---o1: New For Each(true,true)[tuple] - scope-97
                                    |           |   |
                                    |           |   Project[bag][1] - scope-95
                                    |           |   |
                                    |           |   Project[bag][2] - scope-96
                                    |           |
                                    |           |---o1: Package(Packager)[tuple]{long} - scope-90
                                    |               |
                                    |               |---o1: Global Rearrange[tuple] - scope-89
                                    |                   |
                                    |                   |---o1: Local Rearrange[tuple]{long}(false) - scope-91
                                    |                   |   |   |
                                    |                   |   |   Project[long][1] - scope-92
                                    |                   |   |
                                    |                   |   |---forders: Filter[bag] - scope-15
                                    |                   |       |   |
                                    |                   |       |   And[boolean] - scope-22
                                    |                   |       |   |
                                    |                   |       |   |---Less Than or Equal[boolean] - scope-18
                                    |                   |       |   |   |
                                    |                   |       |   |   |---Project[chararray][2] - scope-16
                                    |                   |       |   |   |
                                    |                   |       |   |   |---Constant(1996-12-31) - scope-17
                                    |                   |       |   |
                                    |                   |       |   |---Greater Than or Equal[boolean] - scope-21
                                    |                   |       |       |
                                    |                   |       |       |---Project[chararray][2] - scope-19
                                    |                   |       |       |
                                    |                   |       |       |---Constant(1995-01-01) - scope-20
                                    |                   |       |
                                    |                   |       |---orders: New For Each(false,false,false)[bag] - scope-14
                                    |                   |           |   |
                                    |                   |           |   Cast[long] - scope-6
                                    |                   |           |   |
                                    |                   |           |   |---Project[bytearray][0] - scope-5
                                    |                   |           |   |
                                    |                   |           |   Cast[long] - scope-9
                                    |                   |           |   |
                                    |                   |           |   |---Project[bytearray][1] - scope-8
                                    |                   |           |   |
                                    |                   |           |   Cast[chararray] - scope-12
                                    |                   |           |   |
                                    |                   |           |   |---Project[bytearray][2] - scope-11
                                    |                   |           |
                                    |                   |           |---orders: Load(/tpch/in/orders:PigStorage('|')) - scope-4
                                    |                   |
                                    |                   |---o1: Local Rearrange[tuple]{long}(false) - scope-93
                                    |                       |   |
                                    |                       |   Project[long][0] - scope-94
                                    |                       |
                                    |                       |---selc1: New For Each(false)[bag] - scope-86
                                    |                           |   |
                                    |                           |   Project[long][0] - scope-84
                                    |                           |
                                    |                           |---c1: FRJoin[tuple] - scope-78
                                    |                               |   |
                                    |                               |   Project[int][1] - scope-76
                                    |                               |   |
                                    |                               |   Project[int][0] - scope-77
                                    |                               |
                                    |                               |---customer: New For Each(false,false)[bag] - scope-30
                                    |                               |   |   |
                                    |                               |   |   Cast[long] - scope-25
                                    |                               |   |   |
                                    |                               |   |   |---Project[bytearray][0] - scope-24
                                    |                               |   |   |
                                    |                               |   |   Cast[int] - scope-28
                                    |                               |   |   |
                                    |                               |   |   |---Project[bytearray][1] - scope-27
                                    |                               |   |
                                    |                               |   |---customer: Load(/tpch/in/customer:PigStorage('|')) - scope-23
                                    |                               |
                                    |                               |---seln1: New For Each(false)[bag] - scope-75
                                    |                                   |   |
                                    |                                   |   Project[int][0] - scope-73
                                    |                                   |
                                    |                                   |---n1: FRJoin[tuple] - scope-67
                                    |                                       |   |
                                    |                                       |   Project[int][1] - scope-65
                                    |                                       |   |
                                    |                                       |   Project[int][0] - scope-66
                                    |                                       |
                                    |                                       |---nation: Filter[bag] - scope-48
                                    |                                       |   |   |
                                    |                                       |   |   Constant(true) - scope-49
                                    |                                       |   |
                                    |                                       |   |---nation: New For Each(false,false)[bag] - scope-47
                                    |                                       |       |   |
                                    |                                       |       |   Project[int][0] - scope-43
                                    |                                       |       |   |
                                    |                                       |       |   Project[int][2] - scope-45
                                    |                                       |       |
                                    |                                       |       |---nation: Split - scope-42
                                    |                                       |           |
                                    |                                       |           |---nation: New For Each(false,false,false)[bag] - scope-41
                                    |                                       |               |   |
                                    |                                       |               |   Cast[int] - scope-33
                                    |                                       |               |   |
                                    |                                       |               |   |---Project[bytearray][0] - scope-32
                                    |                                       |               |   |
                                    |                                       |               |   Cast[chararray] - scope-36
                                    |                                       |               |   |
                                    |                                       |               |   |---Project[bytearray][1] - scope-35
                                    |                                       |               |   |
                                    |                                       |               |   Cast[int] - scope-39
                                    |                                       |               |   |
                                    |                                       |               |   |---Project[bytearray][2] - scope-38
                                    |                                       |               |
                                    |                                       |               |---nation: Load(/tpch/in/nation:PigStorage('|')) - scope-31
                                    |                                       |
                                    |                                       |---fregion: New For Each(false)[bag] - scope-64
                                    |                                           |   |
                                    |                                           |   Project[int][0] - scope-62
                                    |                                           |
                                    |                                           |---fregion: Filter[bag] - scope-58
                                    |                                               |   |
                                    |                                               |   Equal To[boolean] - scope-61
                                    |                                               |   |
                                    |                                               |   |---Project[chararray][1] - scope-59
                                    |                                               |   |
                                    |                                               |   |---Constant(AMERICA) - scope-60
                                    |                                               |
                                    |                                               |---region: New For Each(false,false)[bag] - scope-57
                                    |                                                   |   |
                                    |                                                   |   Cast[int] - scope-52
                                    |                                                   |   |
                                    |                                                   |   |---Project[bytearray][0] - scope-51
                                    |                                                   |   |
                                    |                                                   |   Cast[chararray] - scope-55
                                    |                                                   |   |
                                    |                                                   |   |---Project[bytearray][1] - scope-54
                                    |                                                   |
                                    |                                                   |---region: Load(/tpch/in/region:PigStorage('|')) - scope-50
                                    |
                                    |---l1: Local Rearrange[tuple]{long}(false) - scope-208
                                        |   |
                                        |   Project[long][1] - scope-209
                                        |
                                        |---s1: New For Each(false,false,false)[bag] - scope-201
                                            |   |
                                            |   Project[chararray][1] - scope-195
                                            |   |
                                            |   Project[long][3] - scope-197
                                            |   |
                                            |   Project[double][4] - scope-199
                                            |
                                            |---s1: New For Each(true,true)[tuple] - scope-194
                                                |   |
                                                |   Project[bag][1] - scope-192
                                                |   |
                                                |   Project[bag][2] - scope-193
                                                |
                                                |---s1: Package(Packager)[tuple]{long} - scope-187
                                                    |
                                                    |---s1: Global Rearrange[tuple] - scope-186
                                                        |
                                                        |---s1: Local Rearrange[tuple]{long}(false) - scope-188
                                                        |   |   |
                                                        |   |   Project[long][0] - scope-189
                                                        |   |
                                                        |   |---n2: New For Each(false,false)[bag] - scope-130
                                                        |       |   |
                                                        |       |   Project[long][0] - scope-126
                                                        |       |   |
                                                        |       |   Project[chararray][3] - scope-128
                                                        |       |
                                                        |       |---n2: FRJoin[tuple] - scope-120
                                                        |           |   |
                                                        |           |   Project[int][1] - scope-118
                                                        |           |   |
                                                        |           |   Project[int][0] - scope-119
                                                        |           |
                                                        |           |---supplier: New For Each(false,false)[bag] - scope-110
                                                        |           |   |   |
                                                        |           |   |   Cast[long] - scope-105
                                                        |           |   |   |
                                                        |           |   |   |---Project[bytearray][0] - scope-104
                                                        |           |   |   |
                                                        |           |   |   Cast[int] - scope-108
                                                        |           |   |   |
                                                        |           |   |   |---Project[bytearray][1] - scope-107
                                                        |           |   |
                                                        |           |   |---supplier: Load(/tpch/in/supplier:PigStorage('|')) - scope-103
                                                        |           |
                                                        |           |---nation: Filter[bag] - scope-116
                                                        |               |   |
                                                        |               |   Constant(true) - scope-117
                                                        |               |
                                                        |               |---nation: New For Each(false,false)[bag] - scope-115
                                                        |                   |   |
                                                        |                   |   Project[int][0] - scope-111
                                                        |                   |   |
                                                        |                   |   Project[chararray][1] - scope-113
                                                        |                   |
                                                        |                   |---nation: Split - scope-42
                                                        |                       |
                                                        |                       |---nation: New For Each(false,false,false)[bag] - scope-41
                                                        |                           |   |
                                                        |                           |   Cast[int] - scope-33
                                                        |                           |   |
                                                        |                           |   |---Project[bytearray][0] - scope-32
                                                        |                           |   |
                                                        |                           |   Cast[chararray] - scope-36
                                                        |                           |   |
                                                        |                           |   |---Project[bytearray][1] - scope-35
                                                        |                           |   |
                                                        |                           |   Cast[int] - scope-39
                                                        |                           |   |
                                                        |                           |   |---Project[bytearray][2] - scope-38
                                                        |                           |
                                                        |                           |---nation: Load(/tpch/in/nation:PigStorage('|')) - scope-31
                                                        |
                                                        |---s1: Local Rearrange[tuple]{long}(false) - scope-190
                                                            |   |
                                                            |   Project[long][0] - scope-191
                                                            |
                                                            |---p1: New For Each(false,false,false)[bag] - scope-183
                                                                |   |
                                                                |   Project[long][2] - scope-177
                                                                |   |
                                                                |   Project[long][3] - scope-179
                                                                |   |
                                                                |   Project[double][4] - scope-181
                                                                |
                                                                |---p1: New For Each(true,true)[tuple] - scope-176
                                                                    |   |
                                                                    |   Project[bag][1] - scope-174
                                                                    |   |
                                                                    |   Project[bag][2] - scope-175
                                                                    |
                                                                    |---p1: Package(Packager)[tuple]{long} - scope-169
                                                                        |
                                                                        |---p1: Global Rearrange[tuple] - scope-168
                                                                            |
                                                                            |---p1: Local Rearrange[tuple]{long}(false) - scope-170
                                                                            |   |   |
                                                                            |   |   Project[long][0] - scope-171
                                                                            |   |
                                                                            |   |---fpart: New For Each(false)[bag] - scope-145
                                                                            |       |   |
                                                                            |       |   Project[long][0] - scope-143
                                                                            |       |
                                                                            |       |---fpart: Filter[bag] - scope-139
                                                                            |           |   |
                                                                            |           |   Equal To[boolean] - scope-142
                                                                            |           |   |
                                                                            |           |   |---Project[chararray][1] - scope-140
                                                                            |           |   |
                                                                            |           |   |---Constant(ECONOMY ANODIZED STEEL) - scope-141
                                                                            |           |
                                                                            |           |---part: New For Each(false,false)[bag] - scope-138
                                                                            |               |   |
                                                                            |               |   Cast[long] - scope-133
                                                                            |               |   |
                                                                            |               |   |---Project[bytearray][0] - scope-132
                                                                            |               |   |
                                                                            |               |   Cast[chararray] - scope-136
                                                                            |               |   |
                                                                            |               |   |---Project[bytearray][1] - scope-135
                                                                            |               |
                                                                            |               |---part: Load(/tpch/in/part:PigStorage('|')) - scope-131
                                                                            |
                                                                            |---p1: Local Rearrange[tuple]{long}(false) - scope-172
                                                                                |   |
                                                                                |   Project[long][0] - scope-173
                                                                                |
                                                                                |---lineitem: New For Each(false,false,false,false)[bag] - scope-165
                                                                                    |   |
                                                                                    |   Cast[long] - scope-148
                                                                                    |   |
                                                                                    |   |---Project[bytearray][1] - scope-147
                                                                                    |   |
                                                                                    |   Cast[long] - scope-151
                                                                                    |   |
                                                                                    |   |---Project[bytearray][2] - scope-150
                                                                                    |   |
                                                                                    |   Cast[long] - scope-154
                                                                                    |   |
                                                                                    |   |---Project[bytearray][0] - scope-153
                                                                                    |   |
                                                                                    |   Multiply[double] - scope-162
                                                                                    |   |
                                                                                    |   |---Cast[double] - scope-157
                                                                                    |   |   |
                                                                                    |   |   |---Project[bytearray][3] - scope-156
                                                                                    |   |
                                                                                    |   |---Subtract[double] - scope-161
                                                                                    |       |
                                                                                    |       |---Constant(1.0) - scope-158
                                                                                    |       |
                                                                                    |       |---Cast[double] - scope-160
                                                                                    |           |
                                                                                    |           |---Project[bytearray][4] - scope-159
                                                                                    |
                                                                                    |---lineitem: Load(/tpch/in/lineitem:PigStorage('|')) - scope-146

3101 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3118 [main] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
3165 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 1
3177 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
3177 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 1
3180 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 100
3181 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - Insert a file-concatenation job
3188 [main] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
3192 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 1
3192 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
3192 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 1
3192 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 0
3209 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3228 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-288
3232 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3233 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3233 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3233 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3240 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 12
3241 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 map-only splittees.
3241 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 out of total 3 MR operators.
3241 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 11
#--------------------------------------------------
# Map Reduce Plan                                  
#--------------------------------------------------
MapReduce node scope-271
Map Plan
Union[tuple] - scope-272
|
|---p1: Local Rearrange[tuple]{long}(false) - scope-170
|   |   |
|   |   Project[long][0] - scope-171
|   |
|   |---fpart: New For Each(false)[bag] - scope-145
|       |   |
|       |   Project[long][0] - scope-143
|       |
|       |---fpart: Filter[bag] - scope-139
|           |   |
|           |   Equal To[boolean] - scope-142
|           |   |
|           |   |---Project[chararray][1] - scope-140
|           |   |
|           |   |---Constant(ECONOMY ANODIZED STEEL) - scope-141
|           |
|           |---part: New For Each(false,false)[bag] - scope-138
|               |   |
|               |   Cast[long] - scope-133
|               |   |
|               |   |---Project[bytearray][0] - scope-132
|               |   |
|               |   Cast[chararray] - scope-136
|               |   |
|               |   |---Project[bytearray][1] - scope-135
|               |
|               |---part: Load(/tpch/in/part:PigStorage('|')) - scope-131
|
|---p1: Local Rearrange[tuple]{long}(false) - scope-172
    |   |
    |   Project[long][0] - scope-173
    |
    |---lineitem: New For Each(false,false,false,false)[bag] - scope-165
        |   |
        |   Cast[long] - scope-148
        |   |
        |   |---Project[bytearray][1] - scope-147
        |   |
        |   Cast[long] - scope-151
        |   |
        |   |---Project[bytearray][2] - scope-150
        |   |
        |   Cast[long] - scope-154
        |   |
        |   |---Project[bytearray][0] - scope-153
        |   |
        |   Multiply[double] - scope-162
        |   |
        |   |---Cast[double] - scope-157
        |   |   |
        |   |   |---Project[bytearray][3] - scope-156
        |   |
        |   |---Subtract[double] - scope-161
        |       |
        |       |---Constant(1.0) - scope-158
        |       |
        |       |---Cast[double] - scope-160
        |           |
        |           |---Project[bytearray][4] - scope-159
        |
        |---lineitem: Load(/tpch/in/lineitem:PigStorage('|')) - scope-146--------
Reduce Plan
Store(hdfs://neu-5-1:9000/tmp/temp-1529549620/tmp330098609:org.apache.pig.impl.io.InterStorage) - scope-273
|
|---p1: New For Each(false,false,false)[bag] - scope-183
    |   |
    |   Project[long][2] - scope-177
    |   |
    |   Project[long][3] - scope-179
    |   |
    |   Project[double][4] - scope-181
    |
    |---p1: Package(JoinPackager(true,true))[tuple]{long} - scope-169--------
Global sort: false
----------------

MapReduce node scope-250
Map Plan
Split - scope-338
|   |
|   Store(hdfs://neu-5-1:9000/tmp/temp-1529549620/tmp-816736508:org.apache.pig.impl.io.InterStorage) - scope-268
|   |
|   |---nation: New For Each(false,false)[bag] - scope-115
|       |   |
|       |   Project[int][0] - scope-111
|       |   |
|       |   Project[chararray][1] - scope-113
|   |
|   Store(hdfs://neu-5-1:9000/tmp/temp-1529549620/tmp73180507:org.apache.pig.impl.io.InterStorage) - scope-251
|
|---nation: New For Each(false,false,false)[bag] - scope-41
    |   |
    |   Cast[int] - scope-33
    |   |
    |   |---Project[bytearray][0] - scope-32
    |   |
    |   Cast[chararray] - scope-36
    |   |
    |   |---Project[bytearray][1] - scope-35
    |   |
    |   Cast[int] - scope-39
    |   |
    |   |---Project[bytearray][2] - scope-38
    |
    |---nation: Load(/tpch/in/nation:PigStorage('|')) - scope-31--------
Global sort: false
----------------

MapReduce node scope-276
Map Plan
Union[tuple] - scope-277
|
|---s1: Local Rearrange[tuple]{long}(false) - scope-188
|   |   |
|   |   Project[long][0] - scope-189
|   |
|   |---n2: New For Each(false,false)[bag] - scope-130
|       |   |
|       |   Project[long][0] - scope-126
|       |   |
|       |   Project[chararray][3] - scope-128
|       |
|       |---n2: FRJoin[tuple] - scope-120
|           |   |
|           |   Project[int][1] - scope-118
|           |   |
|           |   Project[int][0] - scope-119
|           |
|           |---supplier: New For Each(false,false)[bag] - scope-110
|               |   |
|               |   Cast[long] - scope-105
|               |   |
|               |   |---Project[bytearray][0] - scope-104
|               |   |
|               |   Cast[int] - scope-108
|               |   |
|               |   |---Project[bytearray][1] - scope-107
|               |
|               |---supplier: Load(/tpch/in/supplier:PigStorage('|')) - scope-103
|
|---s1: Local Rearrange[tuple]{long}(false) - scope-190
    |   |
    |   Project[long][0] - scope-191
    |
    |---Load(hdfs://neu-5-1:9000/tmp/temp-1529549620/tmp330098609:org.apache.pig.impl.io.InterStorage) - scope-274--------
Reduce Plan
Store(hdfs://neu-5-1:9000/tmp/temp-1529549620/tmp-43299717:org.apache.pig.impl.io.InterStorage) - scope-278
|
|---s1: New For Each(false,false,false)[bag] - scope-201
    |   |
    |   Project[chararray][1] - scope-195
    |   |
    |   Project[long][3] - scope-197
    |   |
    |   Project[double][4] - scope-199
    |
    |---s1: Package(JoinPackager(true,true))[tuple]{long} - scope-187--------
Global sort: false
----------------

MapReduce node scope-254
Map Plan
Store(hdfs://neu-5-1:9000/tmp/temp-1529549620/tmp734316590:org.apache.pig.impl.io.InterStorage) - scope-255
|
|---fregion: New For Each(false)[bag] - scope-64
    |   |
    |   Project[int][0] - scope-62
    |
    |---fregion: Filter[bag] - scope-58
        |   |
        |   Equal To[boolean] - scope-61
        |   |
        |   |---Project[chararray][1] - scope-59
        |   |
        |   |---Constant(AMERICA) - scope-60
        |
        |---region: New For Each(false,false)[bag] - scope-57
            |   |
            |   Cast[int] - scope-52
            |   |
            |   |---Project[bytearray][0] - scope-51
            |   |
            |   Cast[chararray] - scope-55
            |   |
            |   |---Project[bytearray][1] - scope-54
            |
            |---region: Load(/tpch/in/region:PigStorage('|')) - scope-50--------
Global sort: false
----------------

MapReduce node scope-253
Map Plan
Store(hdfs://neu-5-1:9000/tmp/temp-1529549620/tmp-347781086:org.apache.pig.impl.io.InterStorage) - scope-257
|
|---seln1: New For Each(false)[bag] - scope-75
    |   |
    |   Project[int][0] - scope-73
    |
    |---n1: FRJoin[tuple] - scope-67
        |   |
        |   Project[int][1] - scope-65
        |   |
        |   Project[int][0] - scope-66
        |
        |---nation: New For Each(false,false)[bag] - scope-47
            |   |
            |   Project[int][0] - scope-43
            |   |
            |   Project[int][2] - scope-45
            |
            |---Load(hdfs://neu-5-1:9000/tmp/temp-1529549620/tmp73180507:org.apache.pig.impl.io.InterStorage) - scope-252--------
Global sort: false
----------------

MapReduce node scope-259
Map Plan
Store(hdfs://neu-5-1:9000/tmp/temp-1529549620/tmp-1336016624:org.apache.pig.impl.io.InterStorage) - scope-256
|
|---Load(hdfs://neu-5-1:9000/tmp/temp-1529549620/tmp-347781086:org.apache.pig.impl.io.InterStorage) - scope-258--------
Global sort: false
----------------

MapReduce node scope-260
Map Plan
Union[tuple] - scope-261
|
|---o1: Local Rearrange[tuple]{long}(false) - scope-91
|   |   |
|   |   Project[long][1] - scope-92
|   |
|   |---forders: Filter[bag] - scope-15
|       |   |
|       |   And[boolean] - scope-22
|       |   |
|       |   |---Less Than or Equal[boolean] - scope-18
|       |   |   |
|       |   |   |---Project[chararray][2] - scope-16
|       |   |   |
|       |   |   |---Constant(1996-12-31) - scope-17
|       |   |
|       |   |---Greater Than or Equal[boolean] - scope-21
|       |       |
|       |       |---Project[chararray][2] - scope-19
|       |       |
|       |       |---Constant(1995-01-01) - scope-20
|       |
|       |---orders: New For Each(false,false,false)[bag] - scope-14
|           |   |
|           |   Cast[long] - scope-6
|           |   |
|           |   |---Project[bytearray][0] - scope-5
|           |   |
|           |   Cast[long] - scope-9
|           |   |
|           |   |---Project[bytearray][1] - scope-8
|           |   |
|           |   Cast[chararray] - scope-12
|           |   |
|           |   |---Project[bytearray][2] - scope-11
|           |
|           |---orders: Load(/tpch/in/orders:PigStorage('|')) - scope-4
|
|---o1: Local Rearrange[tuple]{long}(false) - scope-93
    |   |
    |   Project[long][0] - scope-94
    |
    |---selc1: New For Each(false)[bag] - scope-86
        |   |
        |   Project[long][0] - scope-84
        |
        |---c1: FRJoin[tuple] - scope-78
            |   |
            |   Project[int][1] - scope-76
            |   |
            |   Project[int][0] - scope-77
            |
            |---customer: New For Each(false,false)[bag] - scope-30
                |   |
                |   Cast[long] - scope-25
                |   |
                |   |---Project[bytearray][0] - scope-24
                |   |
                |   Cast[int] - scope-28
                |   |
                |   |---Project[bytearray][1] - scope-27
                |
                |---customer: Load(/tpch/in/customer:PigStorage('|')) - scope-23--------
Reduce Plan
Store(hdfs://neu-5-1:9000/tmp/temp-1529549620/tmp332782451:org.apache.pig.impl.io.InterStorage) - scope-262
|
|---o1: New For Each(false,false)[bag] - scope-102
    |   |
    |   Project[long][0] - scope-98
    |   |
    |   Project[chararray][2] - scope-100
    |
    |---o1: Package(JoinPackager(true,true))[tuple]{long} - scope-90--------
Global sort: false
----------------

MapReduce node scope-281
Map Plan
Union[tuple] - scope-282
|
|---l1: Local Rearrange[tuple]{long}(false) - scope-206
|   |   |
|   |   Project[long][0] - scope-207
|   |
|   |---Load(hdfs://neu-5-1:9000/tmp/temp-1529549620/tmp332782451:org.apache.pig.impl.io.InterStorage) - scope-263
|
|---l1: Local Rearrange[tuple]{long}(false) - scope-208
    |   |
    |   Project[long][1] - scope-209
    |
    |---Load(hdfs://neu-5-1:9000/tmp/temp-1529549620/tmp-43299717:org.apache.pig.impl.io.InterStorage) - scope-279--------
Reduce Plan
Store(hdfs://neu-5-1:9000/tmp/temp-1529549620/tmp1886414322:org.apache.pig.impl.io.InterStorage) - scope-283
|
|---sels1: New For Each(false,false,false)[bag] - scope-228
    |   |
    |   POUserFunc(org.apache.pig.builtin.SUBSTRING)[chararray] - scope-216
    |   |
    |   |---Project[chararray][1] - scope-213
    |   |
    |   |---Constant(0) - scope-214
    |   |
    |   |---Constant(4) - scope-215
    |   |
    |   Project[double][4] - scope-218
    |   |
    |   POBinCond[double] - scope-225
    |   |
    |   |---Equal To[boolean] - scope-222
    |   |   |
    |   |   |---Project[chararray][2] - scope-220
    |   |   |
    |   |   |---Constant(BRAZIL) - scope-221
    |   |
    |   |---Project[double][4] - scope-223
    |   |
    |   |---Constant(0.0) - scope-224
    |
    |---l1: Package(JoinPackager(true,true))[tuple]{long} - scope-205--------
Global sort: false
----------------

MapReduce node scope-285
Map Plan
grResult: Local Rearrange[tuple]{chararray}(false) - scope-326
|   |
|   Project[chararray][0] - scope-328
|
|---sumResult: New For Each(false,false,false)[bag] - scope-308
    |   |
    |   Project[chararray][0] - scope-309
    |   |
    |   POUserFunc(org.apache.pig.builtin.AlgebraicMathBase$Initial)[tuple] - scope-310
    |   |
    |   |---Project[bag][2] - scope-311
    |       |
    |       |---Project[bag][1] - scope-312
    |   |
    |   POUserFunc(org.apache.pig.builtin.AlgebraicMathBase$Initial)[tuple] - scope-313
    |   |
    |   |---Project[bag][1] - scope-314
    |       |
    |       |---Project[bag][1] - scope-315
    |
    |---Pre Combiner Local Rearrange[tuple]{Unknown} - scope-329
        |
        |---Load(hdfs://neu-5-1:9000/tmp/temp-1529549620/tmp1886414322:org.apache.pig.impl.io.InterStorage) - scope-284--------
Combine Plan
grResult: Local Rearrange[tuple]{chararray}(false) - scope-330
|   |
|   Project[chararray][0] - scope-332
|
|---sumResult: New For Each(false,false,false)[bag] - scope-316
    |   |
    |   Project[chararray][0] - scope-317
    |   |
    |   POUserFunc(org.apache.pig.builtin.DoubleSum$Intermediate)[tuple] - scope-318
    |   |
    |   |---Project[bag][1] - scope-319
    |   |
    |   POUserFunc(org.apache.pig.builtin.DoubleSum$Intermediate)[tuple] - scope-320
    |   |
    |   |---Project[bag][2] - scope-321
    |
    |---grResult: Package(CombinerPackager)[tuple]{chararray} - scope-325--------
Reduce Plan
Store(hdfs://neu-5-1:9000/tmp/temp-1529549620/tmp-1691660349:org.apache.pig.impl.io.InterStorage) - scope-286
|
|---sumResult: New For Each(false,false)[bag] - scope-244
    |   |
    |   Project[chararray][0] - scope-233
    |   |
    |   Divide[double] - scope-241
    |   |
    |   |---POUserFunc(org.apache.pig.builtin.DoubleSum$Final)[double] - scope-237
    |   |   |
    |   |   |---Project[bag][1] - scope-322
    |   |
    |   |---POUserFunc(org.apache.pig.builtin.DoubleSum$Final)[double] - scope-240
    |       |
    |       |---Project[bag][2] - scope-323
    |
    |---grResult: Package(CombinerPackager)[tuple]{chararray} - scope-230--------
Global sort: false
----------------

MapReduce node scope-288
Map Plan
sortResult: Local Rearrange[tuple]{tuple}(false) - scope-292
|   |
|   Constant(all) - scope-291
|
|---New For Each(false)[tuple] - scope-290
    |   |
    |   Project[chararray][0] - scope-289
    |
    |---Load(hdfs://neu-5-1:9000/tmp/temp-1529549620/tmp-1691660349:org.apache.pig.impl.builtin.RandomSampleLoader('org.apache.pig.impl.io.InterStorage','100')) - scope-287--------
Reduce Plan
Store(hdfs://neu-5-1:9000/tmp/temp-1529549620/tmp23500196:org.apache.pig.impl.io.InterStorage) - scope-301
|
|---New For Each(false)[tuple] - scope-300
    |   |
    |   POUserFunc(org.apache.pig.impl.builtin.FindQuantiles)[tuple] - scope-299
    |   |
    |   |---Project[tuple][*] - scope-298
    |
    |---New For Each(false,false)[tuple] - scope-297
        |   |
        |   Constant(-1) - scope-296
        |   |
        |   Project[bag][1] - scope-294
        |
        |---Package(Packager)[tuple]{chararray} - scope-293--------
Global sort: false
Secondary sort: true
----------------

MapReduce node scope-303
Map Plan
sortResult: Local Rearrange[tuple]{chararray}(false) - scope-304
|   |
|   Project[chararray][0] - scope-245
|
|---Load(hdfs://neu-5-1:9000/tmp/temp-1529549620/tmp-1691660349:org.apache.pig.impl.io.InterStorage) - scope-302--------
Reduce Plan
sortResult: Store(/tpch/out1/Q8out:PigStorage('|')) - scope-247
|
|---New For Each(true)[tuple] - scope-307
    |   |
    |   Project[bag][1] - scope-306
    |
    |---Package(LitePackager)[tuple]{chararray} - scope-305--------
Global sort: true
Quantile file: hdfs://neu-5-1:9000/tmp/temp-1529549620/tmp23500196
----------------

3276 [main] INFO  org.apache.pig.Main  - Pig script completed in 3 seconds and 437 milliseconds (3437 ms)













Delete tmp floders
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-1]
ok: [neu-3-7]
ok: [neu-5-6]
 _______________________________
< TASK [Delete namenode folder] >
 -------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-1]
changed: [neu-5-6]
changed: [neu-3-7]
 _______________________________
< TASK [Delete namenode folder] >
 -------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-1]
changed: [neu-3-7]
changed: [neu-5-6]
 __________________________
< TASK [Delete dfs folder] >
 --------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-1]
ok: [neu-5-6]
ok: [neu-3-7]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-7                    : ok=4    changed=2    unreachable=0    failed=0   
neu-5-1                    : ok=4    changed=3    unreachable=0    failed=0   
neu-5-6                    : ok=4    changed=2    unreachable=0    failed=0   

Fortmat Namenode
DEPRECATED: Use of this script to execute hdfs command is deprecated.
Instead use the hdfs command for it.

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/alluxio-1.8.0-hadoop-2.8/client/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
19/01/04 10:56:10 INFO namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   user = root
STARTUP_MSG:   host = master/10.255.5.1
STARTUP_MSG:   args = [-format]
STARTUP_MSG:   version = 2.8.4
STARTUP_MSG:   classpath = /opt/hadoop-2.8.4/etc/hadoop:/opt/hadoop-2.8.4/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/hadoop-auth-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/httpclient-4.5.2.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/hadoop-annotations-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/httpcore-4.4.4.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/alluxio-1.8.0-client.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/json-smart-1.3.1.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.8.4/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.8.4/share/hadoop/common/hadoop-nfs-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/common/hadoop-common-2.8.4-tests.jar:/opt/hadoop-2.8.4/share/hadoop/common/hadoop-common-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/aws-java-sdk-s3-1.10.6.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/aws-java-sdk-core-1.10.6.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/jackson-annotations-2.2.3.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/okio-1.4.0.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/aws-java-sdk-kms-1.10.6.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/hadoop-aws-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/jackson-databind-2.2.3.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/jackson-core-2.2.3.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.4-tests.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/hadoop-hdfs-client-2.8.4-tests.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/hadoop-hdfs-2.8.4-tests.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/hadoop-hdfs-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/hdfs/hadoop-hdfs-client-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/commons-math-2.2.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/hadoop-yarn-client-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/hadoop-yarn-server-common-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/hadoop-yarn-registry-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/hadoop-yarn-common-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/yarn/hadoop-yarn-api-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.4-tests.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.4.jar:/opt/hadoop-2.8.4/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.4.jar:/opt/alluxio-1.8.0-hadoop-2.8/client/alluxio-1.8.0-client.jar:/usr/lib/jvm/java-1.8.0-openjdk-amd64/jre/lib/tools.jar:/opt/hadoop-2.8.4/contrib/capacity-scheduler/*.jar:/opt/hadoop-2.8.4/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 17e75c2a11685af3e043aa5e604dc831e5b14674; compiled by 'jdu' on 2018-05-08T02:50Z
STARTUP_MSG:   java = 1.8.0_191
************************************************************/
19/01/04 10:56:10 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
19/01/04 10:56:10 INFO namenode.NameNode: createNameNode [-format]
19/01/04 10:56:11 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/01/04 10:56:11 WARN common.Util: Path /local0/data/nameNode should be specified as a URI in configuration files. Please update hdfs configuration.
19/01/04 10:56:11 WARN common.Util: Path /local0/data/nameNode should be specified as a URI in configuration files. Please update hdfs configuration.
Formatting using clusterid: CID-c2522833-79b9-4655-a7e2-fb18bf0be336
19/01/04 10:56:11 INFO namenode.FSEditLog: Edit logging is async:true
19/01/04 10:56:11 INFO namenode.FSNamesystem: KeyProvider: null
19/01/04 10:56:11 INFO namenode.FSNamesystem: fsLock is fair: true
19/01/04 10:56:11 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
19/01/04 10:56:11 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
19/01/04 10:56:11 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
19/01/04 10:56:11 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
19/01/04 10:56:11 INFO blockmanagement.BlockManager: The block deletion will start around 2019 Jan 04 10:56:11
19/01/04 10:56:11 INFO util.GSet: Computing capacity for map BlocksMap
19/01/04 10:56:11 INFO util.GSet: VM type       = 64-bit
19/01/04 10:56:11 INFO util.GSet: 2.0% max memory 958.5 MB = 19.2 MB
19/01/04 10:56:11 INFO util.GSet: capacity      = 2^21 = 2097152 entries
19/01/04 10:56:11 INFO blockmanagement.BlockManager: dfs.block.access.token.enable=false
19/01/04 10:56:11 INFO blockmanagement.BlockManager: defaultReplication         = 3
19/01/04 10:56:11 INFO blockmanagement.BlockManager: maxReplication             = 512
19/01/04 10:56:11 INFO blockmanagement.BlockManager: minReplication             = 1
19/01/04 10:56:11 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2
19/01/04 10:56:11 INFO blockmanagement.BlockManager: replicationRecheckInterval = 3000
19/01/04 10:56:11 INFO blockmanagement.BlockManager: encryptDataTransfer        = false
19/01/04 10:56:11 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
19/01/04 10:56:11 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
19/01/04 10:56:11 INFO namenode.FSNamesystem: supergroup          = root
19/01/04 10:56:11 INFO namenode.FSNamesystem: isPermissionEnabled = true
19/01/04 10:56:11 INFO namenode.FSNamesystem: HA Enabled: false
19/01/04 10:56:11 INFO namenode.FSNamesystem: Append Enabled: true
19/01/04 10:56:11 INFO util.GSet: Computing capacity for map INodeMap
19/01/04 10:56:11 INFO util.GSet: VM type       = 64-bit
19/01/04 10:56:11 INFO util.GSet: 1.0% max memory 958.5 MB = 9.6 MB
19/01/04 10:56:11 INFO util.GSet: capacity      = 2^20 = 1048576 entries
19/01/04 10:56:11 INFO namenode.FSDirectory: ACLs enabled? false
19/01/04 10:56:11 INFO namenode.FSDirectory: XAttrs enabled? true
19/01/04 10:56:11 INFO namenode.NameNode: Caching file names occurring more than 10 times
19/01/04 10:56:11 INFO util.GSet: Computing capacity for map cachedBlocks
19/01/04 10:56:11 INFO util.GSet: VM type       = 64-bit
19/01/04 10:56:11 INFO util.GSet: 0.25% max memory 958.5 MB = 2.4 MB
19/01/04 10:56:11 INFO util.GSet: capacity      = 2^18 = 262144 entries
19/01/04 10:56:11 INFO namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
19/01/04 10:56:11 INFO namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
19/01/04 10:56:11 INFO namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
19/01/04 10:56:11 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
19/01/04 10:56:11 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
19/01/04 10:56:11 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
19/01/04 10:56:11 INFO namenode.FSNamesystem: Retry cache on namenode is enabled
19/01/04 10:56:11 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
19/01/04 10:56:11 INFO util.GSet: Computing capacity for map NameNodeRetryCache
19/01/04 10:56:11 INFO util.GSet: VM type       = 64-bit
19/01/04 10:56:11 INFO util.GSet: 0.029999999329447746% max memory 958.5 MB = 294.5 KB
19/01/04 10:56:11 INFO util.GSet: capacity      = 2^15 = 32768 entries
19/01/04 10:56:11 INFO namenode.FSImage: Allocated new BlockPoolId: BP-733314208-10.255.5.1-1546617371771
19/01/04 10:56:11 INFO common.Storage: Storage directory /local0/data/nameNode has been successfully formatted.
19/01/04 10:56:11 INFO namenode.FSImageFormatProtobuf: Saving image file /local0/data/nameNode/current/fsimage.ckpt_0000000000000000000 using no compression
19/01/04 10:56:11 INFO namenode.FSImageFormatProtobuf: Image file /local0/data/nameNode/current/fsimage.ckpt_0000000000000000000 of size 306 bytes saved in 0 seconds.
19/01/04 10:56:11 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0
19/01/04 10:56:11 INFO util.ExitUtil: Exiting with status 0
19/01/04 10:56:11 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at master/10.255.5.1
************************************************************/
Start DFS
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/alluxio-1.8.0-hadoop-2.8/client/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
19/01/04 10:56:12 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Starting namenodes on [neu-5-1]
neu-5-1: starting namenode, logging to /opt/hadoop-2.8.4/logs/hadoop-root-namenode-neu-5-1.out
neu-5-1: SLF4J: Class path contains multiple SLF4J bindings.
neu-5-1: SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
neu-5-1: SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
neu-5-1: SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
neu-5-1: SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
neu-5-6: starting datanode, logging to /opt/hadoop-2.8.4/logs/hadoop-root-datanode-neu-5-6.out
neu-5-1: starting datanode, logging to /opt/hadoop-2.8.4/logs/hadoop-root-datanode-neu-5-1.out
neu-3-7: starting datanode, logging to /opt/hadoop-2.8.4/logs/hadoop-root-datanode-neu-3-7.out
neu-5-1: SLF4J: Class path contains multiple SLF4J bindings.
neu-5-1: SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
neu-5-1: SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
neu-5-1: SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
neu-5-1: SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Starting secondary namenodes [0.0.0.0]
0.0.0.0: starting secondarynamenode, logging to /opt/hadoop-2.8.4/logs/hadoop-root-secondarynamenode-neu-5-1.out
0.0.0.0: SLF4J: Class path contains multiple SLF4J bindings.
0.0.0.0: SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
0.0.0.0: SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
0.0.0.0: SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
0.0.0.0: SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/alluxio-1.8.0-hadoop-2.8/client/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
19/01/04 10:56:32 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Start Yarn
starting yarn daemons
starting resourcemanager, logging to /opt/hadoop-2.8.4/logs/yarn-root-resourcemanager-neu-5-1.out
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/alluxio-1.8.0-hadoop-2.8/client/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
neu-3-7: starting nodemanager, logging to /opt/hadoop-2.8.4/logs/yarn-root-nodemanager-neu-3-7.out
neu-5-1: starting nodemanager, logging to /opt/hadoop-2.8.4/logs/yarn-root-nodemanager-neu-5-1.out
neu-5-6: starting nodemanager, logging to /opt/hadoop-2.8.4/logs/yarn-root-nodemanager-neu-5-6.out
neu-3-7: SLF4J: Class path contains multiple SLF4J bindings.
neu-3-7: SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
neu-3-7: SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
neu-3-7: SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
neu-3-7: SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
neu-5-1: SLF4J: Class path contains multiple SLF4J bindings.
neu-5-1: SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
neu-5-1: SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
neu-5-1: SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
neu-5-1: SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
neu-5-6: SLF4J: Class path contains multiple SLF4J bindings.
neu-5-6: SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
neu-5-6: SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
neu-5-6: SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
neu-5-6: SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Start History Tracker
starting historyserver, logging to /opt/hadoop-2.8.4/logs/mapred-root-historyserver-neu-5-1.out
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/alluxio-1.8.0-hadoop-2.8/client/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
root@neu-5-1:~/papers/KARIZ/scripts/setup_tools# hadoop fs -ls s3a://alluxio/data
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/alluxio-1.8.0-hadoop-2.8/client/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
19/01/04 10:57:03 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
ls: `s3a://alluxio/data': No such file or directory
root@neu-5-1:~/papers/KARIZ/scripts/setup_tools# hadoop fs -ls s3a://alluxio/
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/alluxio-1.8.0-hadoop-2.8/client/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
19/01/04 10:58:28 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Found 3 items
-rw-rw-rw-   1 root root       1398 2018-12-02 18:36 s3a://alluxio/core-site.xml
drwxrwxrwx   - root root          0 2019-01-04 10:58 s3a://alluxio/default_tests_files
drwxrwxrwx   - root root          0 2019-01-04 10:58 s3a://alluxio/tpch
root@neu-5-1:~/papers/KARIZ/scripts/setup_tools# hadoop fs -ls s3a://alluxio/tpch
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/alluxio-1.8.0-hadoop-2.8/client/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
19/01/04 10:58:34 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Found 4 items
drwxrwxrwx   - root root          0 2019-01-04 10:58 s3a://alluxio/tpch/in
drwxrwxrwx   - root root          0 2019-01-04 10:58 s3a://alluxio/tpch/out1
drwxrwxrwx   - root root          0 2019-01-04 10:58 s3a://alluxio/tpch/out2
drwxrwxrwx   - root root          0 2019-01-04 10:58 s3a://alluxio/tpch/out3
root@neu-5-1:~/papers/KARIZ/scripts/setup_tools# hadoop fs -ls s3a://alluxio/tpch/in
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/alluxio-1.8.0-hadoop-2.8/client/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
19/01/04 10:58:40 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Found 8 items
drwxrwxrwx   - root root          0 2019-01-04 10:58 s3a://alluxio/tpch/in/customer
drwxrwxrwx   - root root          0 2019-01-04 10:58 s3a://alluxio/tpch/in/lineitem
drwxrwxrwx   - root root          0 2019-01-04 10:58 s3a://alluxio/tpch/in/nation
drwxrwxrwx   - root root          0 2019-01-04 10:58 s3a://alluxio/tpch/in/orders
drwxrwxrwx   - root root          0 2019-01-04 10:58 s3a://alluxio/tpch/in/part
drwxrwxrwx   - root root          0 2019-01-04 10:58 s3a://alluxio/tpch/in/partsupp
drwxrwxrwx   - root root          0 2019-01-04 10:58 s3a://alluxio/tpch/in/region
drwxrwxrwx   - root root          0 2019-01-04 10:58 s3a://alluxio/tpch/in/supplier
root@neu-5-1:~/papers/KARIZ/scripts/setup_tools# pigmix
root@neu-5-1:~/papers/KARIZ/expriments/benchmark/BenchmarkScripts/pigmix# cd ../
root@neu-5-1:~/papers/KARIZ/expriments/benchmark/BenchmarkScripts# ls
hive_benchmark  new_hive_benchmark  pigmix  README.md  TestDFSIO  tfidf  tpch
root@neu-5-1:~/papers/KARIZ/expriments/benchmark/BenchmarkScripts# cd tpch/
root@neu-5-1:~/papers/KARIZ/expriments/benchmark/BenchmarkScripts/tpch# ls
datagen  hive  pig  README
root@neu-5-1:~/papers/KARIZ/expriments/benchmark/BenchmarkScripts/tpch# history | grep 
datagen/ hive/    pig/     README   
root@neu-5-1:~/papers/KARIZ/expriments/benchmark/BenchmarkScripts/tpch# history | grep pig
 1133  pigmic
 1134  pigmix
 1225  pigmix
 1267  pigmix 
 1273  vim /opt/pig-0.17.0/conf/pig.properties 
 1274  vim /opt/pig-0.17.0/conf/log4j.properties
 1278  cd pig/
 1282  cd pig/
 1288  mv *.sh papers/KARIZ/expriments/benchmark/BenchmarkScripts/tpch/pig/
 1289  cd papers/KARIZ/expriments/benchmark/BenchmarkScripts/tpch/pig/
 1318  pigmix
 1322  cd pig/
 1325  cd /mnt/volume/papers/KARIZ/expriments/benchmark/BenchmarkScripts/tpch/pig
 1332  cd /mnt/volume/papers/KARIZ/expriments/benchmark/BenchmarkScripts/tpch/pig
 1335  cd /mnt/volume/papers/KARIZ/expriments/benchmark/BenchmarkScripts/tpch/pig
 1506  vim /opt/pig-0.17.0/conf/pig.properties 
 1509  hadoop fs -mkdir /tpch/out1; pig $hadoop_opts -param input=/tpch/in -param output=/tpch/out2 -param reducers=100 -f queries/Q8.pig
 1510  pigmix
 1511  cd ../tpch/pig/
 1512  hadoop fs -mkdir /tpch/out1; pig $hadoop_opts -param input=/tpch/in -param output=/tpch/out2 -param reducers=100 -f queries/Q8.pig
 1609  cd pigmix
 1610  pigmix
 1638  cd pig/
 1641  ${PIG_HOME}/bin/pig $hadoop_opts -param input=<input_dir> -param output=<output_dir> -param reducers=<reducers> -f queries/<script_name>
 1642  hadoop fs -mkdir /tpch/out1; pig $hadoop_opts -param input=/tpch/in -param output=/tpch/out1 -param reducers=100 -f queries/Q8.pig 
 1652  pigmix
 1655  cd pig/
 1660  ${PIG_HOME}/bin/pig $hadoop_opts -param input=<input_dir> -param output=<output_dir> -param reducers=<reducers> -f queries/<script_name>
 1661  pig $hadoop_opts -param input=s3a://alluxio/tpch/in -param output=/tpch/out3 -param reducers=100 -f queries/Q8.pig 
 1666  pig $hadoop_opts -param input=s3a://alluxio/tpch/in -param output=/tpch/out3 -param reducers=100 -f queries/Q8.pig 
 1667  tail /local0/pig-err.log 
 1668  tail -n 1000 /local0/pig-err.log 
 1669  tail -n 2000 /local0/pig-err.log 
 1672  vim pig
 1683  vim queries/Q8.pig 
 1684  pigmix
 1693  cd pig/
 1712  pigmix
 1722  cd tpch/pig/
 1739  history | grep Q8.pig
 1753  ps ax | grep pig
 1754  history | grep pig
 1755  pigmix
 1756  cd ../tpch/pig
 1868  pigmix 
 1872  cd pig/
 1874  history | grep Q8.pig
 1878  pig $hadoop_opts -param input=s3a://alluxio/tpch/in -param output=/tpch/out1 -param reducers=100 -f queries/Q8.pig 
 1879  pig $hadoop_opts -param input=s3a://alluxio/tpch/in -param output=/tpch/out1 -param reducers=100 -f queries/Q8.
 1886  pigmix
 1890  cd pig/
 1892  pig $hadoop_opts -param input=s3a://alluxio/tpch/in -param output=/tpch/out1 -param reducers=100 -f queries/Q8.pig
 1909  pigmic
 1910  pigmix
 1913  cd pig/
 1914  pig $hadoop_opts -param input=s3a://alluxio/tpch/in -param output=/tpch/out1 -param reducers=100 -f queries/Q8.pig
 1962  pigmix
 1964  cd ../tpch/pig/
 1965  history | grep pig
 1966  pig $hadoop_opts -param input=s3a://alluxio/tpch/in -param output=/tpch/out1 -param reducers=100 -f queries/Q8.pig
 2043  pigmix
 2048  history | grep pig
root@neu-5-1:~/papers/KARIZ/expriments/benchmark/BenchmarkScripts/tpch# hadoop fs -mkdir /tpch/out1
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/alluxio-1.8.0-hadoop-2.8/client/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
19/01/04 11:01:20 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
mkdir: `/tpch/out1': No such file or directory
root@neu-5-1:~/papers/KARIZ/expriments/benchmark/BenchmarkScripts/tpch# hadoop fs -mkdir /tpch/
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/alluxio-1.8.0-hadoop-2.8/client/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
19/01/04 11:01:26 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
root@neu-5-1:~/papers/KARIZ/expriments/benchmark/BenchmarkScripts/tpch# hadoop fs -mkdir /tpch/out1
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/alluxio-1.8.0-hadoop-2.8/client/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
19/01/04 11:01:38 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
root@neu-5-1:~/papers/KARIZ/expriments/benchmark/BenchmarkScripts/tpch# pig $hadoop_opts -param input=s3a://alluxio/tpch/in -param output=/tpch/out1 -param reducers=100 -f queries/Q8.pig
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/alluxio-1.8.0-hadoop-2.8/client/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
19/01/04 11:02:01 INFO pig.ExecTypeProvider: Trying ExecType : LOCAL
19/01/04 11:02:01 INFO pig.ExecTypeProvider: Trying ExecType : MAPREDUCE
19/01/04 11:02:01 INFO pig.ExecTypeProvider: Picked MAPREDUCE as the ExecType
19/01/04 11:02:01 INFO pig.Main: Loaded log4j properties from file: /opt/pig-0.17.0/conf/log4j.properties
50   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
19/01/04 11:02:01 INFO pig.Main: Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
51   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
19/01/04 11:02:01 INFO pig.Main: Logging error messages to: /local0/pig-err.log
19/01/04 11:02:02 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
830  [main] ERROR org.apache.pig.Main  - ERROR 2997: Encountered IOException. File queries/Q8.pig does not exist
19/01/04 11:02:02 ERROR pig.Main: ERROR 2997: Encountered IOException. File queries/Q8.pig does not exist
Details at logfile: /local0/pig-err.log
849  [main] INFO  org.apache.pig.Main  - Pig script completed in 1 second and 10 milliseconds (1010 ms)
19/01/04 11:02:02 INFO pig.Main: Pig script completed in 1 second and 10 milliseconds (1010 ms)
root@neu-5-1:~/papers/KARIZ/expriments/benchmark/BenchmarkScripts/tpch# ls
datagen  hive  pig  README
root@neu-5-1:~/papers/KARIZ/expriments/benchmark/BenchmarkScripts/tpch# cd pig/
root@neu-5-1:~/papers/KARIZ/expriments/benchmark/BenchmarkScripts/tpch/pig# ls
ALLUXIO_HDFS2.log       ALLUXIO_HDFS_8wrk.log  copy_dataset_to_alluxio_s3.sh  HDFS_HDFS2.log  README   run_full_benchmark.sh
ALLUXIO_HDFS_8wrk2.log  benchmark_tpch.sh      HDFS_HDFS1.log                 queries         results  run_tpch.sh
root@neu-5-1:~/papers/KARIZ/expriments/benchmark/BenchmarkScripts/tpch/pig# pig $hadoop_opts -param input=s3a://alluxio/tpch/in -param output=/tpch/out1 -param reducers=100 -f queries/Q8.pig
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/alluxio-1.8.0-hadoop-2.8/client/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
19/01/04 11:02:19 INFO pig.ExecTypeProvider: Trying ExecType : LOCAL
19/01/04 11:02:19 INFO pig.ExecTypeProvider: Trying ExecType : MAPREDUCE
19/01/04 11:02:19 INFO pig.ExecTypeProvider: Picked MAPREDUCE as the ExecType
19/01/04 11:02:19 INFO pig.Main: Loaded log4j properties from file: /opt/pig-0.17.0/conf/log4j.properties
49   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
19/01/04 11:02:19 INFO pig.Main: Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
50   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
19/01/04 11:02:19 INFO pig.Main: Logging error messages to: /local0/pig-err.log
19/01/04 11:02:19 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
839  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
19/01/04 11:02:20 INFO util.Utils: Default bootup file /root/.pigbootup not found
19/01/04 11:02:20 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
960  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
19/01/04 11:02:20 INFO executionengine.HExecutionEngine: Connecting to hadoop file system at: hdfs://neu-5-1:9000
1576 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q8.pig-331be35f-e5e2-4d10-b0e3-0f17804701d3
19/01/04 11:02:21 INFO pig.PigServer: Pig Script ID for the session: PIG-Q8.pig-331be35f-e5e2-4d10-b0e3-0f17804701d3
1576 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
19/01/04 11:02:21 WARN pig.PigServer: ATS is disabled since yarn.timeline-service.enabled set to false
5923 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 2 time(s).
19/01/04 11:02:25 WARN newplan.BaseOperatorPlan: Encountered Warning IMPLICIT_CAST_TO_DOUBLE 2 time(s).
19/01/04 11:02:25 INFO Configuration.deprecation: mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator
5955 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
19/01/04 11:02:25 INFO pigstats.ScriptState: Pig features used in the script: REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
5988 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
19/01/04 11:02:25 INFO data.SchemaTupleBackend: Key [pig.schematuple] was not set... will not generate code.
6033 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
19/01/04 11:02:25 INFO optimizer.LogicalPlanOptimizer: {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
6133 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
19/01/04 11:02:25 INFO util.SpillableMemoryManager: Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
6223 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $5, $6, $7, $8
19/01/04 11:02:25 INFO rules.ColumnPruneVisitor: Columns pruned for orders: $2, $3, $5, $6, $7, $8
6225 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $4, $5, $6
19/01/04 11:02:25 INFO rules.ColumnPruneVisitor: Columns pruned for supplier: $1, $2, $4, $5, $6
6226 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $3
19/01/04 11:02:25 INFO rules.ColumnPruneVisitor: Columns pruned for nation: $3
6226 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $1, $2, $4, $5, $6, $7
19/01/04 11:02:25 INFO rules.ColumnPruneVisitor: Columns pruned for customer: $1, $2, $4, $5, $6, $7
6226 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for part: $1, $2, $3, $5, $6, $7, $8
19/01/04 11:02:25 INFO rules.ColumnPruneVisitor: Columns pruned for part: $1, $2, $3, $5, $6, $7, $8
6227 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $3, $4, $7, $8, $9, $10, $11, $12, $13, $14, $15
19/01/04 11:02:25 INFO rules.ColumnPruneVisitor: Columns pruned for lineitem: $3, $4, $7, $8, $9, $10, $11, $12, $13, $14, $15
6227 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for region: $2
19/01/04 11:02:25 INFO rules.ColumnPruneVisitor: Columns pruned for region: $2
6339 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
19/01/04 11:02:25 INFO mapReduceLayer.MRCompiler: File concatenation threshold: 100 optimistic? false
6354 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 0
19/01/04 11:02:25 INFO mapReduceLayer.MRCompiler: number of input files: 0
6357 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 100
19/01/04 11:02:25 INFO mapReduceLayer.MRCompiler: number of input files: 100
6359 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - Insert a file-concatenation job
19/01/04 11:02:25 INFO mapReduceLayer.MRCompiler: Insert a file-concatenation job
6364 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 0
19/01/04 11:02:25 INFO mapReduceLayer.MRCompiler: number of input files: 0
6364 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 0
19/01/04 11:02:25 INFO mapReduceLayer.MRCompiler: number of input files: 0
6383 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
19/01/04 11:02:25 INFO util.CombinerOptimizerUtil: Choosing to move algebraic foreach to combiner
6405 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-288
19/01/04 11:02:25 INFO mapReduceLayer.SecondaryKeyOptimizerMR: Using Secondary Key Optimization for MapReduce node scope-288
6409 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
19/01/04 11:02:25 INFO mapReduceLayer.MRCompiler$LastInputStreamingOptimizer: Rewrite: POPackage->POForEach to POPackage(JoinPackager)
6410 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
19/01/04 11:02:25 INFO mapReduceLayer.MRCompiler$LastInputStreamingOptimizer: Rewrite: POPackage->POForEach to POPackage(JoinPackager)
6410 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
19/01/04 11:02:25 INFO mapReduceLayer.MRCompiler$LastInputStreamingOptimizer: Rewrite: POPackage->POForEach to POPackage(JoinPackager)
6410 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
19/01/04 11:02:25 INFO mapReduceLayer.MRCompiler$LastInputStreamingOptimizer: Rewrite: POPackage->POForEach to POPackage(JoinPackager)
6419 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 12
19/01/04 11:02:25 INFO mapReduceLayer.MultiQueryOptimizer: MR plan size before optimization: 12
6420 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 map-only splittees.
19/01/04 11:02:25 INFO mapReduceLayer.MultiQueryOptimizer: Merged 1 map-only splittees.
6420 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 out of total 3 MR operators.
19/01/04 11:02:25 INFO mapReduceLayer.MultiQueryOptimizer: Merged 1 out of total 3 MR operators.
6420 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 11
19/01/04 11:02:25 INFO mapReduceLayer.MultiQueryOptimizer: MR plan size after optimization: 11
19/01/04 11:02:25 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
6679 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
19/01/04 11:02:26 INFO mapreduce.MRScriptState: Pig script settings are added to the job
19/01/04 11:02:26 INFO Configuration.deprecation: mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent
6684 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
19/01/04 11:02:26 INFO mapReduceLayer.JobControlCompiler: mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
19/01/04 11:02:26 INFO Configuration.deprecation: mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress
6687 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
19/01/04 11:02:26 INFO mapReduceLayer.JobControlCompiler: This job cannot be converted run in-process
19/01/04 11:02:26 INFO Configuration.deprecation: mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication
7599 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1067897136/tmp-1112764676/pig-0.17.0-core-h2.jar
19/01/04 11:02:27 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1067897136/tmp-1112764676/pig-0.17.0-core-h2.jar
7633 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1067897136/tmp1079581122/automaton-1.11-8.jar
19/01/04 11:02:27 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1067897136/tmp1079581122/automaton-1.11-8.jar
7684 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1067897136/tmp-1135310461/antlr-runtime-3.4.jar
19/01/04 11:02:27 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1067897136/tmp-1135310461/antlr-runtime-3.4.jar
7716 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1067897136/tmp508999530/joda-time-2.9.4.jar
19/01/04 11:02:27 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1067897136/tmp508999530/joda-time-2.9.4.jar
7727 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
19/01/04 11:02:27 INFO mapReduceLayer.JobControlCompiler: Setting up single store job
7734 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
19/01/04 11:02:27 INFO data.SchemaTupleFrontend: Key [pig.schematuple] is false, will not generate code.
7734 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
19/01/04 11:02:27 INFO data.SchemaTupleFrontend: Starting process to move generated code to distributed cacche
7734 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
19/01/04 11:02:27 INFO data.SchemaTupleFrontend: Setting key [pig.schematuple.classes] with classes to deserialize []
7782 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
19/01/04 11:02:27 INFO mapreduce.MRScriptState: Pig script settings are added to the job
7782 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
19/01/04 11:02:27 INFO mapReduceLayer.JobControlCompiler: mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
7783 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
19/01/04 11:02:27 INFO mapReduceLayer.JobControlCompiler: Reduce phase detected, estimating # of required reducers.
7783 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 100
19/01/04 11:02:27 INFO mapReduceLayer.JobControlCompiler: Setting Parallelism to 100
19/01/04 11:02:27 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
7784 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
19/01/04 11:02:27 INFO mapReduceLayer.JobControlCompiler: This job cannot be converted run in-process
7838 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1067897136/tmp1356386633/pig-0.17.0-core-h2.jar
19/01/04 11:02:27 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1067897136/tmp1356386633/pig-0.17.0-core-h2.jar
7866 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1067897136/tmp768263488/automaton-1.11-8.jar
19/01/04 11:02:27 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1067897136/tmp768263488/automaton-1.11-8.jar
7892 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1067897136/tmp-1295527567/antlr-runtime-3.4.jar
19/01/04 11:02:27 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1067897136/tmp-1295527567/antlr-runtime-3.4.jar
7920 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1067897136/tmp-1787137584/joda-time-2.9.4.jar
19/01/04 11:02:27 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1067897136/tmp-1787137584/joda-time-2.9.4.jar
7922 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
19/01/04 11:02:27 INFO mapReduceLayer.JobControlCompiler: Setting up single store job
7922 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
19/01/04 11:02:27 INFO data.SchemaTupleFrontend: Key [pig.schematuple] is false, will not generate code.
7923 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
19/01/04 11:02:27 INFO data.SchemaTupleFrontend: Starting process to move generated code to distributed cacche
7923 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
19/01/04 11:02:27 INFO data.SchemaTupleFrontend: Setting key [pig.schematuple.classes] with classes to deserialize []
7974 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
19/01/04 11:02:27 INFO mapreduce.MRScriptState: Pig script settings are added to the job
7974 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
19/01/04 11:02:27 INFO mapReduceLayer.JobControlCompiler: mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
7975 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
19/01/04 11:02:27 INFO mapReduceLayer.JobControlCompiler: This job cannot be converted run in-process
8025 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1067897136/tmp-505165290/pig-0.17.0-core-h2.jar
19/01/04 11:02:27 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1067897136/tmp-505165290/pig-0.17.0-core-h2.jar
8050 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1067897136/tmp-1222275055/automaton-1.11-8.jar
19/01/04 11:02:27 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1067897136/tmp-1222275055/automaton-1.11-8.jar
8075 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1067897136/tmp461671019/antlr-runtime-3.4.jar
19/01/04 11:02:27 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1067897136/tmp461671019/antlr-runtime-3.4.jar
8101 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1067897136/tmp1533604797/joda-time-2.9.4.jar
19/01/04 11:02:27 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1067897136/tmp1533604797/joda-time-2.9.4.jar
8103 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up multi store job
19/01/04 11:02:27 INFO mapReduceLayer.JobControlCompiler: Setting up multi store job
8104 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
19/01/04 11:02:27 INFO data.SchemaTupleFrontend: Key [pig.schematuple] is false, will not generate code.
8105 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
19/01/04 11:02:27 INFO data.SchemaTupleFrontend: Starting process to move generated code to distributed cacche
8105 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
19/01/04 11:02:27 INFO data.SchemaTupleFrontend: Setting key [pig.schematuple.classes] with classes to deserialize []
8119 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 3 map-reduce job(s) waiting for submission.
19/01/04 11:02:27 INFO mapReduceLayer.MapReduceLauncher: 3 map-reduce job(s) waiting for submission.
19/01/04 11:02:27 INFO Configuration.deprecation: mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address
19/01/04 11:02:27 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:02:27 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
19/01/04 11:02:27 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
8218 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
19/01/04 11:02:27 INFO builtin.PigStorage: Using PigTextInputFormat
19/01/04 11:02:27 INFO input.FileInputFormat: Total input files to process : 1
8386 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 1
19/01/04 11:02:27 INFO util.MapRedUtil: Total input paths to process : 1
8397 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
19/01/04 11:02:27 INFO util.MapRedUtil: Total input paths (combined) to process : 1
19/01/04 11:02:27 INFO mapreduce.JobSubmitter: number of splits:1
19/01/04 11:02:27 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1546617394535_0001
19/01/04 11:02:28 INFO mapred.YARNRunner: Job jar is not present. Not adding any jar to the list of resources.
19/01/04 11:02:28 INFO impl.YarnClientImpl: Submitted application application_1546617394535_0001
19/01/04 11:02:28 INFO mapreduce.Job: The url to track the job: http://neu-5-1:8088/proxy/application_1546617394535_0001/
9226 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546617394535_0001
19/01/04 11:02:28 INFO mapReduceLayer.MapReduceLauncher: HadoopJobId: job_1546617394535_0001
9226 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fregion,region
19/01/04 11:02:28 INFO mapReduceLayer.MapReduceLauncher: Processing aliases fregion,region
9226 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: region[14,9],region[-1,-1],fregion[17,10],fregion[-1,-1] C:  R: 
19/01/04 11:02:28 INFO mapReduceLayer.MapReduceLauncher: detailed locations: M: region[14,9],region[-1,-1],fregion[17,10],fregion[-1,-1] C:  R: 
19/01/04 11:02:28 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:02:28 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
9254 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
19/01/04 11:02:28 INFO builtin.PigStorage: Using PigTextInputFormat
19/01/04 11:02:28 INFO input.FileInputFormat: Total input files to process : 512
9452 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 512
19/01/04 11:02:28 INFO util.MapRedUtil: Total input paths to process : 512
9488 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 24
19/01/04 11:02:28 INFO util.MapRedUtil: Total input paths (combined) to process : 24
9490 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
19/01/04 11:02:28 INFO builtin.PigStorage: Using PigTextInputFormat
19/01/04 11:02:29 INFO input.FileInputFormat: Total input files to process : 512
9666 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 512
19/01/04 11:02:29 INFO util.MapRedUtil: Total input paths to process : 512
9681 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 768
19/01/04 11:02:29 INFO util.MapRedUtil: Total input paths (combined) to process : 768
19/01/04 11:02:29 INFO mapreduce.JobSubmitter: number of splits:792
19/01/04 11:02:29 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1546617394535_0002
19/01/04 11:02:29 INFO mapred.YARNRunner: Job jar is not present. Not adding any jar to the list of resources.
19/01/04 11:02:29 INFO impl.YarnClientImpl: Submitted application application_1546617394535_0002
19/01/04 11:02:29 INFO mapreduce.Job: The url to track the job: http://neu-5-1:8088/proxy/application_1546617394535_0002/
10078 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546617394535_0002
19/01/04 11:02:29 INFO mapReduceLayer.MapReduceLauncher: HadoopJobId: job_1546617394535_0002
10078 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fpart,lineitem,p1,part
19/01/04 11:02:29 INFO mapReduceLayer.MapReduceLauncher: Processing aliases fpart,lineitem,p1,part
10078 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: lineitem[8,11],lineitem[-1,-1],p1[33,5],part[16,7],part[-1,-1],fpart[19,8],fpart[-1,-1],p1[33,5] C:  R: p1[-1,-1]
19/01/04 11:02:29 INFO mapReduceLayer.MapReduceLauncher: detailed locations: M: lineitem[8,11],lineitem[-1,-1],p1[33,5],part[16,7],part[-1,-1],fpart[19,8],fpart[-1,-1],p1[33,5] C:  R: p1[-1,-1]
19/01/04 11:02:29 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:02:29 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
10105 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
19/01/04 11:02:29 INFO builtin.PigStorage: Using PigTextInputFormat
19/01/04 11:02:29 INFO input.FileInputFormat: Total input files to process : 1
10260 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 1
19/01/04 11:02:29 INFO util.MapRedUtil: Total input paths to process : 1
10260 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
19/01/04 11:02:29 INFO util.MapRedUtil: Total input paths (combined) to process : 1
19/01/04 11:02:29 INFO mapreduce.JobSubmitter: number of splits:1
19/01/04 11:02:29 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1546617394535_0003
19/01/04 11:02:29 INFO mapred.YARNRunner: Job jar is not present. Not adding any jar to the list of resources.
19/01/04 11:02:29 INFO impl.YarnClientImpl: Submitted application application_1546617394535_0003
19/01/04 11:02:30 INFO mapreduce.Job: The url to track the job: http://neu-5-1:8088/proxy/application_1546617394535_0003/
10574 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546617394535_0003
19/01/04 11:02:30 INFO mapReduceLayer.MapReduceLauncher: HadoopJobId: job_1546617394535_0003
10574 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases nation
19/01/04 11:02:30 INFO mapReduceLayer.MapReduceLauncher: Processing aliases nation
10574 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: nation[12,9],nation[-1,-1],nation[-1,-1] C:  R: 
19/01/04 11:02:30 INFO mapReduceLayer.MapReduceLauncher: detailed locations: M: nation[12,9],nation[-1,-1],nation[-1,-1] C:  R: 
10591 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
19/01/04 11:02:30 INFO mapReduceLayer.MapReduceLauncher: 0% complete
10592 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546617394535_0001,job_1546617394535_0002,job_1546617394535_0003]
19/01/04 11:02:30 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546617394535_0001,job_1546617394535_0002,job_1546617394535_0003]
27803 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 9% complete
19/01/04 11:02:47 INFO mapReduceLayer.MapReduceLauncher: 9% complete
27804 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546617394535_0001,job_1546617394535_0002,job_1546617394535_0003]
19/01/04 11:02:47 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546617394535_0001,job_1546617394535_0002,job_1546617394535_0003]
30811 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 18% complete
19/01/04 11:02:50 INFO mapReduceLayer.MapReduceLauncher: 18% complete
30812 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546617394535_0002]
19/01/04 11:02:50 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546617394535_0002]
19/01/04 11:02:50 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:02:50 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:02:50 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:02:50 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:02:50 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:02:50 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:02:50 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:02:50 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:02:51 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:02:51 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:02:51 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:02:51 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
675710 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 22% complete
19/01/04 11:13:35 INFO mapReduceLayer.MapReduceLauncher: 22% complete
675711 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546617394535_0002]
19/01/04 11:13:35 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546617394535_0002]
1189135 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 26% complete
19/01/04 11:22:08 INFO mapReduceLayer.MapReduceLauncher: 26% complete
1189135 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546617394535_0002]
19/01/04 11:22:08 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546617394535_0002]
19/01/04 11:22:16 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:22:16 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:22:17 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:22:17 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:22:17 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:22:17 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
1198496 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
19/01/04 11:22:17 INFO mapreduce.MRScriptState: Pig script settings are added to the job
1198497 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
19/01/04 11:22:17 INFO mapReduceLayer.JobControlCompiler: mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
1198499 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
19/01/04 11:22:17 INFO mapReduceLayer.JobControlCompiler: Reduce phase detected, estimating # of required reducers.
1198499 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 100
19/01/04 11:22:17 INFO mapReduceLayer.JobControlCompiler: Setting Parallelism to 100
1198499 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
19/01/04 11:22:17 INFO mapReduceLayer.JobControlCompiler: This job cannot be converted run in-process
1198541 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1067897136/tmp-1499597111/pig-0.17.0-core-h2.jar
19/01/04 11:22:17 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1067897136/tmp-1499597111/pig-0.17.0-core-h2.jar
1198559 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1067897136/tmp2004204719/automaton-1.11-8.jar
19/01/04 11:22:17 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1067897136/tmp2004204719/automaton-1.11-8.jar
1198575 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1067897136/tmp-1928680851/antlr-runtime-3.4.jar
19/01/04 11:22:18 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1067897136/tmp-1928680851/antlr-runtime-3.4.jar
1198593 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1067897136/tmp143497642/joda-time-2.9.4.jar
19/01/04 11:22:18 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1067897136/tmp143497642/joda-time-2.9.4.jar
1198595 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
19/01/04 11:22:18 INFO mapReduceLayer.JobControlCompiler: Setting up single store job
1198604 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
19/01/04 11:22:18 INFO data.SchemaTupleFrontend: Key [pig.schematuple] is false, will not generate code.
1198604 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
19/01/04 11:22:18 INFO data.SchemaTupleFrontend: Starting process to move generated code to distributed cacche
1198604 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
19/01/04 11:22:18 INFO data.SchemaTupleFrontend: Setting key [pig.schematuple.classes] with classes to deserialize []
1198621 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
19/01/04 11:22:18 INFO mapreduce.MRScriptState: Pig script settings are added to the job
1198621 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
19/01/04 11:22:18 INFO mapReduceLayer.JobControlCompiler: mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
1198622 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
19/01/04 11:22:18 INFO mapReduceLayer.JobControlCompiler: This job cannot be converted run in-process
1198671 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1067897136/tmp1690078621/pig-0.17.0-core-h2.jar
19/01/04 11:22:18 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1067897136/tmp1690078621/pig-0.17.0-core-h2.jar
1198686 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1067897136/tmp1591513804/automaton-1.11-8.jar
19/01/04 11:22:18 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1067897136/tmp1591513804/automaton-1.11-8.jar
1198699 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1067897136/tmp1433005034/antlr-runtime-3.4.jar
19/01/04 11:22:18 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1067897136/tmp1433005034/antlr-runtime-3.4.jar
1198717 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1067897136/tmp-2019802203/joda-time-2.9.4.jar
19/01/04 11:22:18 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1067897136/tmp-2019802203/joda-time-2.9.4.jar
1198718 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
19/01/04 11:22:18 INFO mapReduceLayer.JobControlCompiler: Setting up single store job
1198721 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
19/01/04 11:22:18 INFO data.SchemaTupleFrontend: Key [pig.schematuple] is false, will not generate code.
1198721 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
19/01/04 11:22:18 INFO data.SchemaTupleFrontend: Starting process to move generated code to distributed cacche
1198721 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
19/01/04 11:22:18 INFO data.SchemaTupleFrontend: Setting key [pig.schematuple.classes] with classes to deserialize []
1198732 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 2 map-reduce job(s) waiting for submission.
19/01/04 11:22:18 INFO mapReduceLayer.MapReduceLauncher: 2 map-reduce job(s) waiting for submission.
19/01/04 11:22:18 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:22:18 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
1198757 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
19/01/04 11:22:18 INFO builtin.PigStorage: Using PigTextInputFormat
19/01/04 11:22:38 INFO input.FileInputFormat: Total input files to process : 512
1219097 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 512
19/01/04 11:22:38 INFO util.MapRedUtil: Total input paths to process : 512
1219109 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 2
19/01/04 11:22:38 INFO util.MapRedUtil: Total input paths (combined) to process : 2
19/01/04 11:22:38 INFO input.FileInputFormat: Total input files to process : 100
1219152 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 100
19/01/04 11:22:38 INFO util.MapRedUtil: Total input paths to process : 100
1219153 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
19/01/04 11:22:38 INFO util.MapRedUtil: Total input paths (combined) to process : 1
19/01/04 11:22:38 INFO mapreduce.JobSubmitter: number of splits:3
19/01/04 11:22:38 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1546617394535_0004
19/01/04 11:22:38 INFO mapred.YARNRunner: Job jar is not present. Not adding any jar to the list of resources.
19/01/04 11:22:38 INFO impl.YarnClientImpl: Submitted application application_1546617394535_0004
19/01/04 11:22:38 INFO mapreduce.Job: The url to track the job: http://neu-5-1:8088/proxy/application_1546617394535_0004/
1219243 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546617394535_0004
19/01/04 11:22:38 INFO mapReduceLayer.MapReduceLauncher: HadoopJobId: job_1546617394535_0004
1219243 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases n2,s1,supplier
19/01/04 11:22:38 INFO mapReduceLayer.MapReduceLauncher: Processing aliases n2,s1,supplier
1219243 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: supplier[10,11],supplier[-1,-1],n2[30,5],n2[-1,-1],s1[35,5],s1[35,5] C:  R: s1[-1,-1]
19/01/04 11:22:38 INFO mapReduceLayer.MapReduceLauncher: detailed locations: M: supplier[10,11],supplier[-1,-1],n2[30,5],n2[-1,-1],s1[35,5],s1[35,5] C:  R: s1[-1,-1]
19/01/04 11:22:38 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:22:38 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
19/01/04 11:22:38 INFO input.FileInputFormat: Total input files to process : 1
1219266 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 1
19/01/04 11:22:38 INFO util.MapRedUtil: Total input paths to process : 1
1219266 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
19/01/04 11:22:38 INFO util.MapRedUtil: Total input paths (combined) to process : 1
19/01/04 11:22:38 INFO mapreduce.JobSubmitter: number of splits:1
19/01/04 11:22:38 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1546617394535_0005
19/01/04 11:22:38 INFO mapred.YARNRunner: Job jar is not present. Not adding any jar to the list of resources.
19/01/04 11:22:38 INFO impl.YarnClientImpl: Submitted application application_1546617394535_0005
19/01/04 11:22:38 INFO mapreduce.Job: The url to track the job: http://neu-5-1:8088/proxy/application_1546617394535_0005/
1219355 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546617394535_0005
19/01/04 11:22:38 INFO mapReduceLayer.MapReduceLauncher: HadoopJobId: job_1546617394535_0005
1219355 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases n1,nation,seln1
19/01/04 11:22:38 INFO mapReduceLayer.MapReduceLauncher: Processing aliases n1,nation,seln1
1219355 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: nation[-1,-1],n1[21,5],seln1[22,8] C:  R: 
19/01/04 11:22:38 INFO mapReduceLayer.MapReduceLauncher: detailed locations: M: nation[-1,-1],n1[21,5],seln1[22,8] C:  R: 
1231481 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 31% complete
19/01/04 11:22:50 INFO mapReduceLayer.MapReduceLauncher: 31% complete
1231482 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546617394535_0004,job_1546617394535_0005]
19/01/04 11:22:50 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546617394535_0004,job_1546617394535_0005]
1234486 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 36% complete
19/01/04 11:22:53 INFO mapReduceLayer.MapReduceLauncher: 36% complete
1234487 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546617394535_0004]
19/01/04 11:22:53 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546617394535_0004]
19/01/04 11:22:53 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:22:53 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:22:53 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:22:53 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:22:54 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:22:54 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
1246639 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 40% complete
19/01/04 11:23:06 INFO mapReduceLayer.MapReduceLauncher: 40% complete
1246639 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546617394535_0004]
19/01/04 11:23:06 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546617394535_0004]
1259160 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 45% complete
19/01/04 11:23:18 INFO mapReduceLayer.MapReduceLauncher: 45% complete
1259160 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546617394535_0004]
19/01/04 11:23:18 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546617394535_0004]
19/01/04 11:23:24 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:23:24 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:23:24 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:23:24 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:23:24 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:23:24 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
1264914 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
19/01/04 11:23:24 INFO mapreduce.MRScriptState: Pig script settings are added to the job
1264914 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
19/01/04 11:23:24 INFO mapReduceLayer.JobControlCompiler: mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
1264915 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
19/01/04 11:23:24 INFO mapReduceLayer.JobControlCompiler: This job cannot be converted run in-process
1264950 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1067897136/tmp-394095851/pig-0.17.0-core-h2.jar
19/01/04 11:23:24 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1067897136/tmp-394095851/pig-0.17.0-core-h2.jar
1264966 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1067897136/tmp-224360383/automaton-1.11-8.jar
19/01/04 11:23:24 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1067897136/tmp-224360383/automaton-1.11-8.jar
1264981 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1067897136/tmp1844325093/antlr-runtime-3.4.jar
19/01/04 11:23:24 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1067897136/tmp1844325093/antlr-runtime-3.4.jar
1264998 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1067897136/tmp111939791/joda-time-2.9.4.jar
19/01/04 11:23:24 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1067897136/tmp111939791/joda-time-2.9.4.jar
1264999 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
19/01/04 11:23:24 INFO mapReduceLayer.JobControlCompiler: Setting up single store job
1265000 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
19/01/04 11:23:24 INFO data.SchemaTupleFrontend: Key [pig.schematuple] is false, will not generate code.
1265000 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
19/01/04 11:23:24 INFO data.SchemaTupleFrontend: Starting process to move generated code to distributed cacche
1265000 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
19/01/04 11:23:24 INFO data.SchemaTupleFrontend: Setting key [pig.schematuple.classes] with classes to deserialize []
1265011 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
19/01/04 11:23:24 INFO mapReduceLayer.MapReduceLauncher: 1 map-reduce job(s) waiting for submission.
19/01/04 11:23:24 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:23:24 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
19/01/04 11:23:24 INFO input.FileInputFormat: Total input files to process : 1
1265032 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 1
19/01/04 11:23:24 INFO util.MapRedUtil: Total input paths to process : 1
1265032 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
19/01/04 11:23:24 INFO util.MapRedUtil: Total input paths (combined) to process : 1
19/01/04 11:23:24 INFO mapreduce.JobSubmitter: number of splits:1
19/01/04 11:23:24 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1546617394535_0006
19/01/04 11:23:24 INFO mapred.YARNRunner: Job jar is not present. Not adding any jar to the list of resources.
19/01/04 11:23:24 INFO impl.YarnClientImpl: Submitted application application_1546617394535_0006
19/01/04 11:23:24 INFO mapreduce.Job: The url to track the job: http://neu-5-1:8088/proxy/application_1546617394535_0006/
1265512 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546617394535_0006
19/01/04 11:23:24 INFO mapReduceLayer.MapReduceLauncher: HadoopJobId: job_1546617394535_0006
1265513 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases 
19/01/04 11:23:24 INFO mapReduceLayer.MapReduceLauncher: Processing aliases 
1265513 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M:  C:  R: 
19/01/04 11:23:24 INFO mapReduceLayer.MapReduceLauncher: detailed locations: M:  C:  R: 
1277171 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 50% complete
19/01/04 11:23:36 INFO mapReduceLayer.MapReduceLauncher: 50% complete
1277171 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546617394535_0006]
19/01/04 11:23:36 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546617394535_0006]
1280174 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 54% complete
19/01/04 11:23:39 INFO mapReduceLayer.MapReduceLauncher: 54% complete
19/01/04 11:23:39 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:23:39 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:23:39 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:23:39 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:23:39 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:23:39 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
1280299 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
19/01/04 11:23:39 INFO mapreduce.MRScriptState: Pig script settings are added to the job
1280300 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
19/01/04 11:23:39 INFO mapReduceLayer.JobControlCompiler: mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
1280301 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
19/01/04 11:23:39 INFO mapReduceLayer.JobControlCompiler: Reduce phase detected, estimating # of required reducers.
1280301 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 100
19/01/04 11:23:39 INFO mapReduceLayer.JobControlCompiler: Setting Parallelism to 100
1280301 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
19/01/04 11:23:39 INFO mapReduceLayer.JobControlCompiler: This job cannot be converted run in-process
1280340 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1067897136/tmp523794943/pig-0.17.0-core-h2.jar
19/01/04 11:23:39 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1067897136/tmp523794943/pig-0.17.0-core-h2.jar
1280352 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1067897136/tmp1679908452/automaton-1.11-8.jar
19/01/04 11:23:39 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1067897136/tmp1679908452/automaton-1.11-8.jar
1280364 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1067897136/tmp251007945/antlr-runtime-3.4.jar
19/01/04 11:23:39 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1067897136/tmp251007945/antlr-runtime-3.4.jar
1280380 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1067897136/tmp-401201077/joda-time-2.9.4.jar
19/01/04 11:23:39 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1067897136/tmp-401201077/joda-time-2.9.4.jar
1280381 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
19/01/04 11:23:39 INFO mapReduceLayer.JobControlCompiler: Setting up single store job
1280383 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
19/01/04 11:23:39 INFO data.SchemaTupleFrontend: Key [pig.schematuple] is false, will not generate code.
1280383 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
19/01/04 11:23:39 INFO data.SchemaTupleFrontend: Starting process to move generated code to distributed cacche
1280383 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
19/01/04 11:23:39 INFO data.SchemaTupleFrontend: Setting key [pig.schematuple.classes] with classes to deserialize []
1280398 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
19/01/04 11:23:39 INFO mapReduceLayer.MapReduceLauncher: 1 map-reduce job(s) waiting for submission.
19/01/04 11:23:39 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:23:39 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
1280416 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
19/01/04 11:23:39 INFO builtin.PigStorage: Using PigTextInputFormat
19/01/04 11:24:53 INFO input.FileInputFormat: Total input files to process : 512
1353730 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 512
19/01/04 11:24:53 INFO util.MapRedUtil: Total input paths to process : 512
1353744 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 24
19/01/04 11:24:53 INFO util.MapRedUtil: Total input paths (combined) to process : 24
1353746 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
19/01/04 11:24:53 INFO builtin.PigStorage: Using PigTextInputFormat
19/01/04 11:24:53 INFO input.FileInputFormat: Total input files to process : 512
1353918 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 512
19/01/04 11:24:53 INFO util.MapRedUtil: Total input paths to process : 512
1353928 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 171
19/01/04 11:24:53 INFO util.MapRedUtil: Total input paths (combined) to process : 171
19/01/04 11:24:53 INFO mapreduce.JobSubmitter: number of splits:195
19/01/04 11:24:53 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1546617394535_0007
19/01/04 11:24:53 INFO mapred.YARNRunner: Job jar is not present. Not adding any jar to the list of resources.
19/01/04 11:24:53 INFO impl.YarnClientImpl: Submitted application application_1546617394535_0007
19/01/04 11:24:53 INFO mapreduce.Job: The url to track the job: http://neu-5-1:8088/proxy/application_1546617394535_0007/
1354208 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546617394535_0007
19/01/04 11:24:53 INFO mapReduceLayer.MapReduceLauncher: HadoopJobId: job_1546617394535_0007
1354208 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases c1,customer,forders,o1,orders,selc1
19/01/04 11:24:53 INFO mapReduceLayer.MapReduceLauncher: Processing aliases c1,customer,forders,o1,orders,selc1
1354208 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: orders[6,9],orders[-1,-1],forders[18,10],o1[27,5],customer[4,11],customer[-1,-1],c1[24,5],selc1[25,8],o1[27,5] C:  R: o1[-1,-1]
19/01/04 11:24:53 INFO mapReduceLayer.MapReduceLauncher: detailed locations: M: orders[6,9],orders[-1,-1],forders[18,10],o1[27,5],customer[4,11],customer[-1,-1],c1[24,5],selc1[25,8],o1[27,5] C:  R: o1[-1,-1]
1574493 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 58% complete
19/01/04 11:28:33 INFO mapReduceLayer.MapReduceLauncher: 58% complete
1574493 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546617394535_0007]
19/01/04 11:28:33 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546617394535_0007]
2101585 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 62% complete
19/01/04 11:37:21 INFO mapReduceLayer.MapReduceLauncher: 62% complete
2101585 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546617394535_0007]
19/01/04 11:37:21 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546617394535_0007]
19/01/04 11:37:29 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:37:29 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:37:29 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:37:29 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:37:29 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:37:29 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
2109975 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
19/01/04 11:37:29 INFO mapreduce.MRScriptState: Pig script settings are added to the job
2109975 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
19/01/04 11:37:29 INFO mapReduceLayer.JobControlCompiler: mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
2109976 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
19/01/04 11:37:29 INFO mapReduceLayer.JobControlCompiler: Reduce phase detected, estimating # of required reducers.
2109976 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 100
19/01/04 11:37:29 INFO mapReduceLayer.JobControlCompiler: Setting Parallelism to 100
2109976 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
19/01/04 11:37:29 INFO mapReduceLayer.JobControlCompiler: This job cannot be converted run in-process
2110028 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1067897136/tmp-1740202330/pig-0.17.0-core-h2.jar
19/01/04 11:37:29 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1067897136/tmp-1740202330/pig-0.17.0-core-h2.jar
2110044 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1067897136/tmp-147260539/automaton-1.11-8.jar
19/01/04 11:37:29 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1067897136/tmp-147260539/automaton-1.11-8.jar
2110058 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1067897136/tmp1716381453/antlr-runtime-3.4.jar
19/01/04 11:37:29 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1067897136/tmp1716381453/antlr-runtime-3.4.jar
2110074 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1067897136/tmp-1164533152/joda-time-2.9.4.jar
19/01/04 11:37:29 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1067897136/tmp-1164533152/joda-time-2.9.4.jar
2110076 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
19/01/04 11:37:29 INFO mapReduceLayer.JobControlCompiler: Setting up single store job
2110076 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
19/01/04 11:37:29 INFO data.SchemaTupleFrontend: Key [pig.schematuple] is false, will not generate code.
2110076 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
19/01/04 11:37:29 INFO data.SchemaTupleFrontend: Starting process to move generated code to distributed cacche
2110076 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
19/01/04 11:37:29 INFO data.SchemaTupleFrontend: Setting key [pig.schematuple.classes] with classes to deserialize []
2110094 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
19/01/04 11:37:29 INFO mapReduceLayer.MapReduceLauncher: 1 map-reduce job(s) waiting for submission.
19/01/04 11:37:29 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:37:29 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
19/01/04 11:37:29 INFO input.FileInputFormat: Total input files to process : 100
2110128 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 100
19/01/04 11:37:29 INFO util.MapRedUtil: Total input paths to process : 100
2110129 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
19/01/04 11:37:29 INFO util.MapRedUtil: Total input paths (combined) to process : 1
19/01/04 11:37:29 INFO input.FileInputFormat: Total input files to process : 100
2110146 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 100
19/01/04 11:37:29 INFO util.MapRedUtil: Total input paths to process : 100
2110147 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
19/01/04 11:37:29 INFO util.MapRedUtil: Total input paths (combined) to process : 1
19/01/04 11:37:29 INFO mapreduce.JobSubmitter: number of splits:2
19/01/04 11:37:29 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1546617394535_0008
19/01/04 11:37:29 INFO mapred.YARNRunner: Job jar is not present. Not adding any jar to the list of resources.
19/01/04 11:37:29 INFO impl.YarnClientImpl: Submitted application application_1546617394535_0008
19/01/04 11:37:29 INFO mapreduce.Job: The url to track the job: http://neu-5-1:8088/proxy/application_1546617394535_0008/
2110595 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546617394535_0008
19/01/04 11:37:30 INFO mapReduceLayer.MapReduceLauncher: HadoopJobId: job_1546617394535_0008
2110595 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases l1,sels1
19/01/04 11:37:30 INFO mapReduceLayer.MapReduceLauncher: Processing aliases l1,sels1
2110595 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: l1[37,5],l1[37,5] C:  R: sels1[39,8]
19/01/04 11:37:30 INFO mapReduceLayer.MapReduceLauncher: detailed locations: M: l1[37,5],l1[37,5] C:  R: sels1[39,8]
2132627 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 67% complete
19/01/04 11:37:52 INFO mapReduceLayer.MapReduceLauncher: 67% complete
2132627 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546617394535_0008]
19/01/04 11:37:52 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546617394535_0008]
2147645 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 71% complete
19/01/04 11:38:07 INFO mapReduceLayer.MapReduceLauncher: 71% complete
2147645 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546617394535_0008]
19/01/04 11:38:07 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546617394535_0008]
19/01/04 11:38:15 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:38:15 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:38:15 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:38:15 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:38:15 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:38:15 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
2155875 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
19/01/04 11:38:15 INFO mapreduce.MRScriptState: Pig script settings are added to the job
2155876 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
19/01/04 11:38:15 INFO mapReduceLayer.JobControlCompiler: mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
2155876 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
19/01/04 11:38:15 INFO mapReduceLayer.JobControlCompiler: Reduce phase detected, estimating # of required reducers.
2155876 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 100
19/01/04 11:38:15 INFO mapReduceLayer.JobControlCompiler: Setting Parallelism to 100
2155876 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
19/01/04 11:38:15 INFO mapReduceLayer.JobControlCompiler: This job cannot be converted run in-process
2155914 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1067897136/tmp-1429759165/pig-0.17.0-core-h2.jar
19/01/04 11:38:15 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1067897136/tmp-1429759165/pig-0.17.0-core-h2.jar
2155929 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1067897136/tmp-329672621/automaton-1.11-8.jar
19/01/04 11:38:15 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1067897136/tmp-329672621/automaton-1.11-8.jar
2155942 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1067897136/tmp-218061623/antlr-runtime-3.4.jar
19/01/04 11:38:15 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1067897136/tmp-218061623/antlr-runtime-3.4.jar
2155958 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1067897136/tmp-1024258435/joda-time-2.9.4.jar
19/01/04 11:38:15 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1067897136/tmp-1024258435/joda-time-2.9.4.jar
2155960 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
19/01/04 11:38:15 INFO mapReduceLayer.JobControlCompiler: Setting up single store job
2155961 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
19/01/04 11:38:15 INFO data.SchemaTupleFrontend: Key [pig.schematuple] is false, will not generate code.
2155961 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
19/01/04 11:38:15 INFO data.SchemaTupleFrontend: Starting process to move generated code to distributed cacche
2155961 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
19/01/04 11:38:15 INFO data.SchemaTupleFrontend: Setting key [pig.schematuple.classes] with classes to deserialize []
2155982 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
19/01/04 11:38:15 INFO mapReduceLayer.MapReduceLauncher: 1 map-reduce job(s) waiting for submission.
19/01/04 11:38:15 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:38:15 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
19/01/04 11:38:15 INFO input.FileInputFormat: Total input files to process : 100
2156009 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 100
19/01/04 11:38:15 INFO util.MapRedUtil: Total input paths to process : 100
2156010 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
19/01/04 11:38:15 INFO util.MapRedUtil: Total input paths (combined) to process : 1
19/01/04 11:38:15 INFO mapreduce.JobSubmitter: number of splits:1
19/01/04 11:38:15 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1546617394535_0009
19/01/04 11:38:15 INFO mapred.YARNRunner: Job jar is not present. Not adding any jar to the list of resources.
19/01/04 11:38:15 INFO impl.YarnClientImpl: Submitted application application_1546617394535_0009
19/01/04 11:38:15 INFO mapreduce.Job: The url to track the job: http://neu-5-1:8088/proxy/application_1546617394535_0009/
2156483 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546617394535_0009
19/01/04 11:38:15 INFO mapReduceLayer.MapReduceLauncher: HadoopJobId: job_1546617394535_0009
2156483 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases grResult,sumResult
19/01/04 11:38:15 INFO mapReduceLayer.MapReduceLauncher: Processing aliases grResult,sumResult
2156483 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: sumResult[42,12],grResult[40,11] C: sumResult[42,12],grResult[40,11] R: sumResult[42,12]
19/01/04 11:38:15 INFO mapReduceLayer.MapReduceLauncher: detailed locations: M: sumResult[42,12],grResult[40,11] C: sumResult[42,12],grResult[40,11] R: sumResult[42,12]
2168159 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 77% complete
19/01/04 11:38:27 INFO mapReduceLayer.MapReduceLauncher: 77% complete
2168159 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546617394535_0009]
19/01/04 11:38:27 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546617394535_0009]
2190685 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 81% complete
19/01/04 11:38:50 INFO mapReduceLayer.MapReduceLauncher: 81% complete
2190685 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546617394535_0009]
19/01/04 11:38:50 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546617394535_0009]
19/01/04 11:38:50 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:38:50 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:38:50 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:38:50 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:38:50 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:38:50 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
2191386 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
19/01/04 11:38:50 INFO mapreduce.MRScriptState: Pig script settings are added to the job
2191386 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
19/01/04 11:38:50 INFO mapReduceLayer.JobControlCompiler: mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
2191387 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
19/01/04 11:38:50 INFO mapReduceLayer.JobControlCompiler: Reduce phase detected, estimating # of required reducers.
2191388 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
19/01/04 11:38:50 INFO mapReduceLayer.JobControlCompiler: Setting Parallelism to 1
2191388 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
19/01/04 11:38:50 INFO mapReduceLayer.JobControlCompiler: This job cannot be converted run in-process
2191424 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1067897136/tmp-1316556876/pig-0.17.0-core-h2.jar
19/01/04 11:38:50 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1067897136/tmp-1316556876/pig-0.17.0-core-h2.jar
2191438 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1067897136/tmp-2003378307/automaton-1.11-8.jar
19/01/04 11:38:50 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1067897136/tmp-2003378307/automaton-1.11-8.jar
2191450 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1067897136/tmp-2032673396/antlr-runtime-3.4.jar
19/01/04 11:38:50 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1067897136/tmp-2032673396/antlr-runtime-3.4.jar
2191465 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1067897136/tmp-797649539/joda-time-2.9.4.jar
19/01/04 11:38:50 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1067897136/tmp-797649539/joda-time-2.9.4.jar
2191466 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
19/01/04 11:38:50 INFO mapReduceLayer.JobControlCompiler: Setting up single store job
2191467 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
19/01/04 11:38:50 INFO data.SchemaTupleFrontend: Key [pig.schematuple] is false, will not generate code.
2191467 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
19/01/04 11:38:50 INFO data.SchemaTupleFrontend: Starting process to move generated code to distributed cacche
2191467 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
19/01/04 11:38:50 INFO data.SchemaTupleFrontend: Setting key [pig.schematuple.classes] with classes to deserialize []
2191486 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
19/01/04 11:38:50 INFO mapReduceLayer.MapReduceLauncher: 1 map-reduce job(s) waiting for submission.
19/01/04 11:38:50 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:38:50 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
19/01/04 11:38:50 INFO input.FileInputFormat: Total input files to process : 100
2191507 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 100
19/01/04 11:38:50 INFO util.MapRedUtil: Total input paths to process : 100
2191507 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
19/01/04 11:38:50 INFO util.MapRedUtil: Total input paths (combined) to process : 1
19/01/04 11:38:50 INFO mapreduce.JobSubmitter: number of splits:1
19/01/04 11:38:50 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1546617394535_0010
19/01/04 11:38:50 INFO mapred.YARNRunner: Job jar is not present. Not adding any jar to the list of resources.
19/01/04 11:38:50 INFO impl.YarnClientImpl: Submitted application application_1546617394535_0010
19/01/04 11:38:51 INFO mapreduce.Job: The url to track the job: http://neu-5-1:8088/proxy/application_1546617394535_0010/
2191987 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546617394535_0010
19/01/04 11:38:51 INFO mapReduceLayer.MapReduceLauncher: HadoopJobId: job_1546617394535_0010
2191987 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases sortResult
19/01/04 11:38:51 INFO mapReduceLayer.MapReduceLauncher: Processing aliases sortResult
2191987 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: sortResult[43,13] C:  R: 
19/01/04 11:38:51 INFO mapReduceLayer.MapReduceLauncher: detailed locations: M: sortResult[43,13] C:  R: 
2202000 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 86% complete
19/01/04 11:39:01 INFO mapReduceLayer.MapReduceLauncher: 86% complete
2202000 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546617394535_0010]
19/01/04 11:39:01 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546617394535_0010]
2209008 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 90% complete
19/01/04 11:39:08 INFO mapReduceLayer.MapReduceLauncher: 90% complete
2209009 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546617394535_0010]
19/01/04 11:39:08 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546617394535_0010]
19/01/04 11:39:11 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:11 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:11 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:11 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:11 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:11 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
2212161 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
19/01/04 11:39:11 INFO mapreduce.MRScriptState: Pig script settings are added to the job
2212161 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
19/01/04 11:39:11 INFO mapReduceLayer.JobControlCompiler: mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
2212162 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
19/01/04 11:39:11 INFO mapReduceLayer.JobControlCompiler: Reduce phase detected, estimating # of required reducers.
2212162 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 100
19/01/04 11:39:11 INFO mapReduceLayer.JobControlCompiler: Setting Parallelism to 100
2212162 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
19/01/04 11:39:11 INFO mapReduceLayer.JobControlCompiler: This job cannot be converted run in-process
2212195 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1067897136/tmp102101099/pig-0.17.0-core-h2.jar
19/01/04 11:39:11 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1067897136/tmp102101099/pig-0.17.0-core-h2.jar
2212208 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1067897136/tmp-1389436004/automaton-1.11-8.jar
19/01/04 11:39:11 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1067897136/tmp-1389436004/automaton-1.11-8.jar
2212220 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1067897136/tmp1053244524/antlr-runtime-3.4.jar
19/01/04 11:39:11 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1067897136/tmp1053244524/antlr-runtime-3.4.jar
2212235 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1067897136/tmp1127283755/joda-time-2.9.4.jar
19/01/04 11:39:11 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1067897136/tmp1127283755/joda-time-2.9.4.jar
2212236 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
19/01/04 11:39:11 INFO mapReduceLayer.JobControlCompiler: Setting up single store job
2212237 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
19/01/04 11:39:11 INFO data.SchemaTupleFrontend: Key [pig.schematuple] is false, will not generate code.
2212237 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
19/01/04 11:39:11 INFO data.SchemaTupleFrontend: Starting process to move generated code to distributed cacche
2212237 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
19/01/04 11:39:11 INFO data.SchemaTupleFrontend: Setting key [pig.schematuple.classes] with classes to deserialize []
2212253 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
19/01/04 11:39:11 INFO mapReduceLayer.MapReduceLauncher: 1 map-reduce job(s) waiting for submission.
19/01/04 11:39:11 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:11 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
19/01/04 11:39:11 INFO input.FileInputFormat: Total input files to process : 100
2212279 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 100
19/01/04 11:39:11 INFO util.MapRedUtil: Total input paths to process : 100
2212279 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
19/01/04 11:39:11 INFO util.MapRedUtil: Total input paths (combined) to process : 1
19/01/04 11:39:11 INFO mapreduce.JobSubmitter: number of splits:1
19/01/04 11:39:11 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1546617394535_0011
19/01/04 11:39:11 INFO mapred.YARNRunner: Job jar is not present. Not adding any jar to the list of resources.
19/01/04 11:39:11 INFO impl.YarnClientImpl: Submitted application application_1546617394535_0011
19/01/04 11:39:11 INFO mapreduce.Job: The url to track the job: http://neu-5-1:8088/proxy/application_1546617394535_0011/
2212754 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546617394535_0011
19/01/04 11:39:12 INFO mapReduceLayer.MapReduceLauncher: HadoopJobId: job_1546617394535_0011
2212754 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases sortResult
19/01/04 11:39:12 INFO mapReduceLayer.MapReduceLauncher: Processing aliases sortResult
2212754 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: sortResult[43,13] C:  R: 
19/01/04 11:39:12 INFO mapReduceLayer.MapReduceLauncher: detailed locations: M: sortResult[43,13] C:  R: 
2224820 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 95% complete
19/01/04 11:39:24 INFO mapReduceLayer.MapReduceLauncher: 95% complete
2224821 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546617394535_0011]
19/01/04 11:39:24 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546617394535_0011]
2244843 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 99% complete
19/01/04 11:39:44 INFO mapReduceLayer.MapReduceLauncher: 99% complete
2244843 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546617394535_0011]
19/01/04 11:39:44 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546617394535_0011]
19/01/04 11:39:47 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:47 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:47 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:47 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:47 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:47 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
2248045 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
19/01/04 11:39:47 INFO mapReduceLayer.MapReduceLauncher: 100% complete
2248048 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-04 11:02:26	2019-01-04 11:39:47	REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER

Success!

Job Stats (time in seconds):
JobId	Maps	Reduces	MaxMapTime	MinMapTime	AvgMapTime	MedianMapTime	MaxReduceTime	MinReduceTime	AvgReduceTime	MedianReducetime	Alias	Feature	Outputs
job_1546617394535_0001	1	0	10	10	10	10	0	0	0	0	fregion,region	MAP_ONLY	
job_1546617394535_0002	792	100	642	5	64	19	1099	308	886	900	fpart,lineitem,p1,part	HASH_JOIN	
job_1546617394535_0003	1	0	7	7	7	7	0	0	0	0	nation	MULTI_QUERY,MAP_ONLY	
job_1546617394535_0004	3	100	19	9	13	13	9	3	5	5	n2,s1,supplier	REPLICATED_JOIN,HASH_JOIN	
job_1546617394535_0005	1	0	3	3	3	3	0	0	0	0	n1,nation,seln1	REPLICATED_JOIN,MAP_ONLY	
job_1546617394535_0006	1	0	3	3	3	3	0	0	0	0		MAP_ONLY	
job_1546617394535_0007	195	100	602	5	87	25	720	570	657	658	c1,customer,forders,o1,orders,selc1	REPLICATED_JOIN,HASH_JOIN	
job_1546617394535_0008	2	100	17	9	13	13	8	3	5	5	l1,sels1	HASH_JOIN	
job_1546617394535_0009	1	100	4	4	4	4	4	2	3	3	grResult,sumResult	GROUP_BY,COMBINER	
job_1546617394535_0010	1	1	3	3	3	3	3	3	3	3	sortResult	SAMPLER	
job_1546617394535_0011	1	100	3	3	3	3	4	2	3	3	sortResult	ORDER_BY	/tpch/out1/Q8out,

Input(s):
Successfully read 6400000 records from: "s3a://alluxio/tpch/in/part"
Successfully read 192000551 records from: "s3a://alluxio/tpch/in/lineitem"
Successfully read 25 records (366 bytes) from: "s3a://alluxio/tpch/in/nation"
Successfully read 320000 records from: "s3a://alluxio/tpch/in/supplier"
Successfully read 5 records (366 bytes) from: "s3a://alluxio/tpch/in/region"
Successfully read 4800000 records from: "s3a://alluxio/tpch/in/customer"
Successfully read 48000000 records from: "s3a://alluxio/tpch/in/orders"

Output(s):
Successfully stored 2 records (48 bytes) in: "/tpch/out1/Q8out"

Counters:
Total records written : 2
Total bytes written : 48
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546617394535_0002	->	job_1546617394535_0004,
job_1546617394535_0003	->	job_1546617394535_0004,job_1546617394535_0005,
job_1546617394535_0004	->	job_1546617394535_0008,
job_1546617394535_0001	->	job_1546617394535_0005,
job_1546617394535_0005	->	job_1546617394535_0006,
job_1546617394535_0006	->	job_1546617394535_0007,
job_1546617394535_0007	->	job_1546617394535_0008,
job_1546617394535_0008	->	job_1546617394535_0009,
job_1546617394535_0009	->	job_1546617394535_0010,
job_1546617394535_0010	->	job_1546617394535_0011,
job_1546617394535_0011


19/01/04 11:39:47 INFO mapreduce.SimplePigStats: Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-04 11:02:26	2019-01-04 11:39:47	REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER

Success!

Job Stats (time in seconds):
JobId	Maps	Reduces	MaxMapTime	MinMapTime	AvgMapTime	MedianMapTime	MaxReduceTime	MinReduceTime	AvgReduceTime	MedianReducetime	Alias	Feature	Outputs
job_1546617394535_0001	1	0	10	10	10	10	0	0	0	0	fregion,region	MAP_ONLY	
job_1546617394535_0002	792	100	642	5	64	19	1099	308	886	900	fpart,lineitem,p1,part	HASH_JOIN	
job_1546617394535_0003	1	0	7	7	7	7	0	0	0	0	nation	MULTI_QUERY,MAP_ONLY	
job_1546617394535_0004	3	100	19	9	13	13	9	3	5	5	n2,s1,supplier	REPLICATED_JOIN,HASH_JOIN	
job_1546617394535_0005	1	0	3	3	3	3	0	0	0	0	n1,nation,seln1	REPLICATED_JOIN,MAP_ONLY	
job_1546617394535_0006	1	0	3	3	3	3	0	0	0	0		MAP_ONLY	
job_1546617394535_0007	195	100	602	5	87	25	720	570	657	658	c1,customer,forders,o1,orders,selc1	REPLICATED_JOIN,HASH_JOIN	
job_1546617394535_0008	2	100	17	9	13	13	8	3	5	5	l1,sels1	HASH_JOIN	
job_1546617394535_0009	1	100	4	4	4	4	4	2	3	3	grResult,sumResult	GROUP_BY,COMBINER	
job_1546617394535_0010	1	1	3	3	3	3	3	3	3	3	sortResult	SAMPLER	
job_1546617394535_0011	1	100	3	3	3	3	4	2	3	3	sortResult	ORDER_BY	/tpch/out1/Q8out,

Input(s):
Successfully read 6400000 records from: "s3a://alluxio/tpch/in/part"
Successfully read 192000551 records from: "s3a://alluxio/tpch/in/lineitem"
Successfully read 25 records (366 bytes) from: "s3a://alluxio/tpch/in/nation"
Successfully read 320000 records from: "s3a://alluxio/tpch/in/supplier"
Successfully read 5 records (366 bytes) from: "s3a://alluxio/tpch/in/region"
Successfully read 4800000 records from: "s3a://alluxio/tpch/in/customer"
Successfully read 48000000 records from: "s3a://alluxio/tpch/in/orders"

Output(s):
Successfully stored 2 records (48 bytes) in: "/tpch/out1/Q8out"

Counters:
Total records written : 2
Total bytes written : 48
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546617394535_0002	->	job_1546617394535_0004,
job_1546617394535_0003	->	job_1546617394535_0004,job_1546617394535_0005,
job_1546617394535_0004	->	job_1546617394535_0008,
job_1546617394535_0001	->	job_1546617394535_0005,
job_1546617394535_0005	->	job_1546617394535_0006,
job_1546617394535_0006	->	job_1546617394535_0007,
job_1546617394535_0007	->	job_1546617394535_0008,
job_1546617394535_0008	->	job_1546617394535_0009,
job_1546617394535_0009	->	job_1546617394535_0010,
job_1546617394535_0010	->	job_1546617394535_0011,
job_1546617394535_0011


19/01/04 11:39:47 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:47 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:47 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:47 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:47 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:47 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:47 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:47 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:47 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:47 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:47 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:47 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:47 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:47 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:48 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:48 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:48 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:48 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:48 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:48 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:48 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:48 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:48 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:48 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:48 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:48 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:48 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:48 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:48 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:48 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:48 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:48 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:48 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:48 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:48 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:48 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:48 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:48 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:48 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:48 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:48 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:48 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:48 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:48 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:48 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:48 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:48 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:48 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:48 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:48 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:49 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:49 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:49 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:49 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:49 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:49 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:49 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:49 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:49 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:49 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:49 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:49 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:49 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:49 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/04 11:39:49 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/04 11:39:49 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
2249933 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Success!
19/01/04 11:39:49 INFO mapReduceLayer.MapReduceLauncher: Success!
2249964 [main] INFO  org.apache.pig.Main  - Pig script completed in 37 minutes, 30 seconds and 109 milliseconds (2250109 ms)



root@neu-5-1:~/papers/KARIZ/expriments/benchmark/BenchmarkScripts/tpch/pig# pig $hadoop_opts -param input=alluxio://neu-5-1:19998/tpch/in -param output=/tpch/out2 -param reducers=100 -f queries/Q8.pig
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hadoop-2.8.4/share/hadoop/common/lib/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/alluxio-1.8.0-hadoop-2.8/client/alluxio-1.8.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
19/01/05 11:07:28 INFO pig.ExecTypeProvider: Trying ExecType : LOCAL
19/01/05 11:07:28 INFO pig.ExecTypeProvider: Trying ExecType : MAPREDUCE
19/01/05 11:07:28 INFO pig.ExecTypeProvider: Picked MAPREDUCE as the ExecType
19/01/05 11:07:28 INFO pig.Main: Loaded log4j properties from file: /opt/pig-0.17.0/conf/log4j.properties
48   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
19/01/05 11:07:28 INFO pig.Main: Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
49   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
19/01/05 11:07:28 INFO pig.Main: Logging error messages to: /local0/pig-err.log
19/01/05 11:07:28 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
804  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
19/01/05 11:07:28 INFO util.Utils: Default bootup file /root/.pigbootup not found
19/01/05 11:07:29 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
917  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
19/01/05 11:07:29 INFO executionengine.HExecutionEngine: Connecting to hadoop file system at: hdfs://neu-5-1:9000
1536 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q8.pig-aebbfac9-94ae-4f20-8ea8-85f4cc537dc0
19/01/05 11:07:29 INFO pig.PigServer: Pig Script ID for the session: PIG-Q8.pig-aebbfac9-94ae-4f20-8ea8-85f4cc537dc0
1536 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
19/01/05 11:07:29 WARN pig.PigServer: ATS is disabled since yarn.timeline-service.enabled set to false
19/01/05 11:07:30 INFO hadoop.HadoopConfigurationUtils: Loading Alluxio properties from Hadoop configuration: {pig.home.dir=/opt/pig-0.17.0, pig.log.dir=/opt/pig-0.17.0/logs, line.separator=
, hadoop.id.str=root, pig.log.file=pig.log, os.name=Linux, hadoop.log.dir=/opt/hadoop-2.8.4/logs, os.arch=amd64, user.country=US, os.version=4.15.0-43-generic, hadoop.root.logger=INFO,console, hadoop.home.dir=/opt/hadoop-2.8.4, user.dir=/root/papers/KARIZ/expriments/benchmark/BenchmarkScripts/tpch/pig, file.encoding.pkg=sun.io, hadoop.security.logger=INFO,NullAppender, file.separator=/, path.separator=:, awt.toolkit=sun.awt.X11.XToolkit, user.home=/root, user.timezone=America/New_York, user.language=en, hadoop.log.file=hadoop.log, hadoop.policy.file=hadoop-policy.xml, file.encoding=UTF-8}
19/01/05 11:07:30 INFO metrics.MetricsSystem: Starting sinks with config: {}.
19/01/05 11:07:30 INFO file.FileSystemContext: Created filesystem context with id app-7022016713457303885. This ID will be used for identifying info from the client, such as metrics. It can be set manually through the alluxio.user.app.id property
19/01/05 11:07:30 INFO hadoop.HadoopConfigurationUtils: Loading Alluxio properties from Hadoop configuration: {pig.home.dir=/opt/pig-0.17.0, pig.log.dir=/opt/pig-0.17.0/logs, line.separator=
, hadoop.id.str=root, pig.log.file=pig.log, os.name=Linux, hadoop.log.dir=/opt/hadoop-2.8.4/logs, os.arch=amd64, user.country=US, os.version=4.15.0-43-generic, hadoop.root.logger=INFO,console, hadoop.home.dir=/opt/hadoop-2.8.4, user.dir=/root/papers/KARIZ/expriments/benchmark/BenchmarkScripts/tpch/pig, file.encoding.pkg=sun.io, hadoop.security.logger=INFO,NullAppender, file.separator=/, path.separator=:, awt.toolkit=sun.awt.X11.XToolkit, user.home=/root, user.timezone=America/New_York, user.language=en, hadoop.log.file=hadoop.log, hadoop.policy.file=hadoop-policy.xml, file.encoding=UTF-8}
19/01/05 11:07:30 INFO alluxio.AbstractClient: Alluxio client (version 1.8.0) is trying to bootstrap-connect with master/10.255.5.1:19998
19/01/05 11:07:30 INFO alluxio.AbstractClient: Alluxio client has bootstrap-connected with master/10.255.5.1:19998
19/01/05 11:07:30 INFO alluxio.AbstractClient: Alluxio client (version 1.8.0) is trying to connect with MetricsMasterClient @ master/10.255.5.1:19998
19/01/05 11:07:30 INFO alluxio.AbstractClient: Client registered with MetricsMasterClient @ master/10.255.5.1:19998
19/01/05 11:07:31 INFO heartbeat.HeartbeatThread: Hearbeat Master Metrics Sync is interrupted.
19/01/05 11:07:31 INFO alluxio.AbstractClient: Alluxio client (version 1.8.0) is trying to connect with MetricsMasterClient @ neu-5-1/10.255.5.1:19998
19/01/05 11:07:31 INFO alluxio.AbstractClient: Client registered with MetricsMasterClient @ neu-5-1/10.255.5.1:19998
19/01/05 11:07:31 INFO alluxio.AbstractClient: Alluxio client (version 1.8.0) is trying to connect with FileSystemMasterClient @ neu-5-1/10.255.5.1:19998
19/01/05 11:07:31 INFO alluxio.AbstractClient: Client registered with FileSystemMasterClient @ neu-5-1/10.255.5.1:19998
19/01/05 11:07:31 INFO file.FileSystemContext: Created filesystem context with id app-5237143941429579200. This ID will be used for identifying info from the client, such as metrics. It can be set manually through the alluxio.user.app.id property
19/01/05 11:07:31 INFO alluxio.AbstractClient: Alluxio client (version 1.8.0) is trying to connect with MetricsMasterClient @ neu-5-1/10.255.5.1:19998
19/01/05 11:07:31 INFO alluxio.AbstractClient: Client registered with MetricsMasterClient @ neu-5-1/10.255.5.1:19998
19/01/05 11:07:31 INFO alluxio.AbstractClient: Alluxio client (version 1.8.0) is trying to connect with FileSystemMasterClient @ neu-5-1/10.255.5.1:19998
19/01/05 11:07:31 INFO alluxio.AbstractClient: Client registered with FileSystemMasterClient @ neu-5-1/10.255.5.1:19998
3946 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 2 time(s).
19/01/05 11:07:32 WARN newplan.BaseOperatorPlan: Encountered Warning IMPLICIT_CAST_TO_DOUBLE 2 time(s).
19/01/05 11:07:32 INFO Configuration.deprecation: mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator
3978 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
19/01/05 11:07:32 INFO pigstats.ScriptState: Pig features used in the script: REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
4011 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
19/01/05 11:07:32 INFO data.SchemaTupleBackend: Key [pig.schematuple] was not set... will not generate code.
4042 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
19/01/05 11:07:32 INFO optimizer.LogicalPlanOptimizer: {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
4079 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
19/01/05 11:07:32 INFO util.SpillableMemoryManager: Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
4170 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $5, $6, $7, $8
19/01/05 11:07:32 INFO rules.ColumnPruneVisitor: Columns pruned for orders: $2, $3, $5, $6, $7, $8
4173 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $4, $5, $6
19/01/05 11:07:32 INFO rules.ColumnPruneVisitor: Columns pruned for supplier: $1, $2, $4, $5, $6
4173 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $3
19/01/05 11:07:32 INFO rules.ColumnPruneVisitor: Columns pruned for nation: $3
4174 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $1, $2, $4, $5, $6, $7
19/01/05 11:07:32 INFO rules.ColumnPruneVisitor: Columns pruned for customer: $1, $2, $4, $5, $6, $7
4174 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for part: $1, $2, $3, $5, $6, $7, $8
19/01/05 11:07:32 INFO rules.ColumnPruneVisitor: Columns pruned for part: $1, $2, $3, $5, $6, $7, $8
4175 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $3, $4, $7, $8, $9, $10, $11, $12, $13, $14, $15
19/01/05 11:07:32 INFO rules.ColumnPruneVisitor: Columns pruned for lineitem: $3, $4, $7, $8, $9, $10, $11, $12, $13, $14, $15
4175 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for region: $2
19/01/05 11:07:32 INFO rules.ColumnPruneVisitor: Columns pruned for region: $2
4287 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
19/01/05 11:07:32 INFO mapReduceLayer.MRCompiler: File concatenation threshold: 100 optimistic? false
4302 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 0
19/01/05 11:07:32 INFO mapReduceLayer.MRCompiler: number of input files: 0
4305 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 100
19/01/05 11:07:32 INFO mapReduceLayer.MRCompiler: number of input files: 100
4306 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - Insert a file-concatenation job
19/01/05 11:07:32 INFO mapReduceLayer.MRCompiler: Insert a file-concatenation job
4311 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 0
19/01/05 11:07:32 INFO mapReduceLayer.MRCompiler: number of input files: 0
4311 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 0
19/01/05 11:07:32 INFO mapReduceLayer.MRCompiler: number of input files: 0
4344 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
19/01/05 11:07:32 INFO util.CombinerOptimizerUtil: Choosing to move algebraic foreach to combiner
4373 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-288
19/01/05 11:07:32 INFO mapReduceLayer.SecondaryKeyOptimizerMR: Using Secondary Key Optimization for MapReduce node scope-288
4378 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
19/01/05 11:07:32 INFO mapReduceLayer.MRCompiler$LastInputStreamingOptimizer: Rewrite: POPackage->POForEach to POPackage(JoinPackager)
4378 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
19/01/05 11:07:32 INFO mapReduceLayer.MRCompiler$LastInputStreamingOptimizer: Rewrite: POPackage->POForEach to POPackage(JoinPackager)
4378 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
19/01/05 11:07:32 INFO mapReduceLayer.MRCompiler$LastInputStreamingOptimizer: Rewrite: POPackage->POForEach to POPackage(JoinPackager)
4378 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
19/01/05 11:07:32 INFO mapReduceLayer.MRCompiler$LastInputStreamingOptimizer: Rewrite: POPackage->POForEach to POPackage(JoinPackager)
4387 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 12
19/01/05 11:07:32 INFO mapReduceLayer.MultiQueryOptimizer: MR plan size before optimization: 12
4387 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 map-only splittees.
19/01/05 11:07:32 INFO mapReduceLayer.MultiQueryOptimizer: Merged 1 map-only splittees.
4388 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 out of total 3 MR operators.
19/01/05 11:07:32 INFO mapReduceLayer.MultiQueryOptimizer: Merged 1 out of total 3 MR operators.
4388 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 11
19/01/05 11:07:32 INFO mapReduceLayer.MultiQueryOptimizer: MR plan size after optimization: 11
19/01/05 11:07:32 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
4645 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
19/01/05 11:07:32 INFO mapreduce.MRScriptState: Pig script settings are added to the job
19/01/05 11:07:32 INFO Configuration.deprecation: mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent
4650 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
19/01/05 11:07:32 INFO mapReduceLayer.JobControlCompiler: mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
19/01/05 11:07:32 INFO Configuration.deprecation: mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress
4655 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
19/01/05 11:07:32 INFO mapReduceLayer.JobControlCompiler: This job cannot be converted run in-process
19/01/05 11:07:32 INFO Configuration.deprecation: mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication
4921 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1357975457/tmp1443677398/pig-0.17.0-core-h2.jar
19/01/05 11:07:33 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1357975457/tmp1443677398/pig-0.17.0-core-h2.jar
4936 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1357975457/tmp-1096615291/automaton-1.11-8.jar
19/01/05 11:07:33 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1357975457/tmp-1096615291/automaton-1.11-8.jar
4951 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1357975457/tmp-1434921003/antlr-runtime-3.4.jar
19/01/05 11:07:33 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1357975457/tmp-1434921003/antlr-runtime-3.4.jar
4966 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1357975457/tmp-1040562927/joda-time-2.9.4.jar
19/01/05 11:07:33 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1357975457/tmp-1040562927/joda-time-2.9.4.jar
4979 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
19/01/05 11:07:33 INFO mapReduceLayer.JobControlCompiler: Setting up single store job
4986 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
19/01/05 11:07:33 INFO data.SchemaTupleFrontend: Key [pig.schematuple] is false, will not generate code.
4986 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
19/01/05 11:07:33 INFO data.SchemaTupleFrontend: Starting process to move generated code to distributed cacche
4986 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
19/01/05 11:07:33 INFO data.SchemaTupleFrontend: Setting key [pig.schematuple.classes] with classes to deserialize []
5033 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
19/01/05 11:07:33 INFO mapreduce.MRScriptState: Pig script settings are added to the job
5034 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
19/01/05 11:07:33 INFO mapReduceLayer.JobControlCompiler: mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
5035 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
19/01/05 11:07:33 INFO mapReduceLayer.JobControlCompiler: Reduce phase detected, estimating # of required reducers.
5035 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 100
19/01/05 11:07:33 INFO mapReduceLayer.JobControlCompiler: Setting Parallelism to 100
19/01/05 11:07:33 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
5035 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
19/01/05 11:07:33 INFO mapReduceLayer.JobControlCompiler: This job cannot be converted run in-process
5068 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1357975457/tmp-969269907/pig-0.17.0-core-h2.jar
19/01/05 11:07:33 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1357975457/tmp-969269907/pig-0.17.0-core-h2.jar
5080 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1357975457/tmp556890431/automaton-1.11-8.jar
19/01/05 11:07:33 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1357975457/tmp556890431/automaton-1.11-8.jar
5093 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1357975457/tmp-1835491453/antlr-runtime-3.4.jar
19/01/05 11:07:33 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1357975457/tmp-1835491453/antlr-runtime-3.4.jar
5109 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1357975457/tmp66259699/joda-time-2.9.4.jar
19/01/05 11:07:33 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1357975457/tmp66259699/joda-time-2.9.4.jar
5112 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
19/01/05 11:07:33 INFO mapReduceLayer.JobControlCompiler: Setting up single store job
5113 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
19/01/05 11:07:33 INFO data.SchemaTupleFrontend: Key [pig.schematuple] is false, will not generate code.
5113 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
19/01/05 11:07:33 INFO data.SchemaTupleFrontend: Starting process to move generated code to distributed cacche
5113 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
19/01/05 11:07:33 INFO data.SchemaTupleFrontend: Setting key [pig.schematuple.classes] with classes to deserialize []
5172 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
19/01/05 11:07:33 INFO mapreduce.MRScriptState: Pig script settings are added to the job
5173 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
19/01/05 11:07:33 INFO mapReduceLayer.JobControlCompiler: mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
5174 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
19/01/05 11:07:33 INFO mapReduceLayer.JobControlCompiler: This job cannot be converted run in-process
5206 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1357975457/tmp-1791543126/pig-0.17.0-core-h2.jar
19/01/05 11:07:33 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1357975457/tmp-1791543126/pig-0.17.0-core-h2.jar
5219 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1357975457/tmp468496350/automaton-1.11-8.jar
19/01/05 11:07:33 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1357975457/tmp468496350/automaton-1.11-8.jar
5233 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1357975457/tmp-1046950391/antlr-runtime-3.4.jar
19/01/05 11:07:33 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1357975457/tmp-1046950391/antlr-runtime-3.4.jar
5249 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1357975457/tmp-210801300/joda-time-2.9.4.jar
19/01/05 11:07:33 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1357975457/tmp-210801300/joda-time-2.9.4.jar
5251 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up multi store job
19/01/05 11:07:33 INFO mapReduceLayer.JobControlCompiler: Setting up multi store job
5252 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
19/01/05 11:07:33 INFO data.SchemaTupleFrontend: Key [pig.schematuple] is false, will not generate code.
5252 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
19/01/05 11:07:33 INFO data.SchemaTupleFrontend: Starting process to move generated code to distributed cacche
5253 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
19/01/05 11:07:33 INFO data.SchemaTupleFrontend: Setting key [pig.schematuple.classes] with classes to deserialize []
5266 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 3 map-reduce job(s) waiting for submission.
19/01/05 11:07:33 INFO mapReduceLayer.MapReduceLauncher: 3 map-reduce job(s) waiting for submission.
19/01/05 11:07:33 INFO Configuration.deprecation: mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address
19/01/05 11:07:33 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:07:33 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
19/01/05 11:07:33 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
5355 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
19/01/05 11:07:33 INFO builtin.PigStorage: Using PigTextInputFormat
19/01/05 11:07:33 INFO input.FileInputFormat: Total input files to process : 1
5421 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 1
19/01/05 11:07:33 INFO util.MapRedUtil: Total input paths to process : 1
5433 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
19/01/05 11:07:33 INFO util.MapRedUtil: Total input paths (combined) to process : 1
19/01/05 11:07:33 INFO mapreduce.JobSubmitter: number of splits:1
19/01/05 11:07:33 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1546632509115_0012
19/01/05 11:07:33 INFO mapred.YARNRunner: Job jar is not present. Not adding any jar to the list of resources.
19/01/05 11:07:33 INFO impl.YarnClientImpl: Submitted application application_1546632509115_0012
19/01/05 11:07:33 INFO mapreduce.Job: The url to track the job: http://neu-5-1:8088/proxy/application_1546632509115_0012/
5809 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546632509115_0012
19/01/05 11:07:33 INFO mapReduceLayer.MapReduceLauncher: HadoopJobId: job_1546632509115_0012
5809 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fregion,region
19/01/05 11:07:33 INFO mapReduceLayer.MapReduceLauncher: Processing aliases fregion,region
5809 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: region[14,9],region[-1,-1],fregion[17,10],fregion[-1,-1] C:  R: 
19/01/05 11:07:33 INFO mapReduceLayer.MapReduceLauncher: detailed locations: M: region[14,9],region[-1,-1],fregion[17,10],fregion[-1,-1] C:  R: 
19/01/05 11:07:33 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:07:33 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
5831 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
19/01/05 11:07:33 INFO builtin.PigStorage: Using PigTextInputFormat
19/01/05 11:07:34 INFO input.FileInputFormat: Total input files to process : 512
6120 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 512
19/01/05 11:07:34 INFO util.MapRedUtil: Total input paths to process : 512
6158 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 2
19/01/05 11:07:34 INFO util.MapRedUtil: Total input paths (combined) to process : 2
6160 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
19/01/05 11:07:34 INFO builtin.PigStorage: Using PigTextInputFormat
19/01/05 11:07:34 INFO input.FileInputFormat: Total input files to process : 512
6325 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 512
19/01/05 11:07:34 INFO util.MapRedUtil: Total input paths to process : 512
6345 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 49
19/01/05 11:07:34 INFO util.MapRedUtil: Total input paths (combined) to process : 49
19/01/05 11:07:34 INFO mapreduce.JobSubmitter: number of splits:51
19/01/05 11:07:34 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1546632509115_0013
19/01/05 11:07:34 INFO mapred.YARNRunner: Job jar is not present. Not adding any jar to the list of resources.
19/01/05 11:07:34 INFO impl.YarnClientImpl: Submitted application application_1546632509115_0013
19/01/05 11:07:34 INFO mapreduce.Job: The url to track the job: http://neu-5-1:8088/proxy/application_1546632509115_0013/
6459 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546632509115_0013
19/01/05 11:07:34 INFO mapReduceLayer.MapReduceLauncher: HadoopJobId: job_1546632509115_0013
6460 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fpart,lineitem,p1,part
19/01/05 11:07:34 INFO mapReduceLayer.MapReduceLauncher: Processing aliases fpart,lineitem,p1,part
6460 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: lineitem[8,11],lineitem[-1,-1],p1[33,5],part[16,7],part[-1,-1],fpart[19,8],fpart[-1,-1],p1[33,5] C:  R: p1[-1,-1]
19/01/05 11:07:34 INFO mapReduceLayer.MapReduceLauncher: detailed locations: M: lineitem[8,11],lineitem[-1,-1],p1[33,5],part[16,7],part[-1,-1],fpart[19,8],fpart[-1,-1],p1[33,5] C:  R: p1[-1,-1]
19/01/05 11:07:34 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:07:34 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
6482 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
19/01/05 11:07:34 INFO builtin.PigStorage: Using PigTextInputFormat
19/01/05 11:07:34 INFO input.FileInputFormat: Total input files to process : 1
6485 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 1
19/01/05 11:07:34 INFO util.MapRedUtil: Total input paths to process : 1
6486 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
19/01/05 11:07:34 INFO util.MapRedUtil: Total input paths (combined) to process : 1
19/01/05 11:07:34 INFO mapreduce.JobSubmitter: number of splits:1
19/01/05 11:07:34 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1546632509115_0014
19/01/05 11:07:34 INFO mapred.YARNRunner: Job jar is not present. Not adding any jar to the list of resources.
19/01/05 11:07:34 INFO impl.YarnClientImpl: Submitted application application_1546632509115_0014
19/01/05 11:07:34 INFO mapreduce.Job: The url to track the job: http://neu-5-1:8088/proxy/application_1546632509115_0014/
6553 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546632509115_0014
19/01/05 11:07:34 INFO mapReduceLayer.MapReduceLauncher: HadoopJobId: job_1546632509115_0014
6553 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases nation
19/01/05 11:07:34 INFO mapReduceLayer.MapReduceLauncher: Processing aliases nation
6553 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: nation[12,9],nation[-1,-1],nation[-1,-1] C:  R: 
19/01/05 11:07:34 INFO mapReduceLayer.MapReduceLauncher: detailed locations: M: nation[12,9],nation[-1,-1],nation[-1,-1] C:  R: 
6564 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
19/01/05 11:07:34 INFO mapReduceLayer.MapReduceLauncher: 0% complete
6565 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0012,job_1546632509115_0013,job_1546632509115_0014]
19/01/05 11:07:34 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546632509115_0012,job_1546632509115_0013,job_1546632509115_0014]
20750 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 4% complete
19/01/05 11:07:48 INFO mapReduceLayer.MapReduceLauncher: 4% complete
20753 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0012,job_1546632509115_0013,job_1546632509115_0014]
19/01/05 11:07:48 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546632509115_0012,job_1546632509115_0013,job_1546632509115_0014]
25825 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 9% complete
19/01/05 11:07:53 INFO mapReduceLayer.MapReduceLauncher: 9% complete
25825 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0012,job_1546632509115_0013,job_1546632509115_0014]
19/01/05 11:07:53 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546632509115_0012,job_1546632509115_0013,job_1546632509115_0014]
26827 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 13% complete
19/01/05 11:07:54 INFO mapReduceLayer.MapReduceLauncher: 13% complete
26827 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0013,job_1546632509115_0014]
19/01/05 11:07:54 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546632509115_0013,job_1546632509115_0014]
19/01/05 11:07:54 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:07:54 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:07:55 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:07:55 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:07:55 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:07:55 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
31807 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 18% complete
19/01/05 11:07:59 INFO mapReduceLayer.MapReduceLauncher: 18% complete
31808 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0013]
19/01/05 11:07:59 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546632509115_0013]
19/01/05 11:07:59 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:07:59 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:08:00 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:08:00 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:08:00 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:08:00 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
115837 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 22% complete
19/01/05 11:09:23 INFO mapReduceLayer.MapReduceLauncher: 22% complete
115837 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0013]
19/01/05 11:09:23 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546632509115_0013]
158901 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 26% complete
19/01/05 11:10:06 INFO mapReduceLayer.MapReduceLauncher: 26% complete
158901 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0013]
19/01/05 11:10:06 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546632509115_0013]
19/01/05 11:30:15 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:30:15 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:30:15 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:30:15 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:30:15 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:30:15 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
1367624 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
19/01/05 11:30:15 INFO mapreduce.MRScriptState: Pig script settings are added to the job
1367625 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
19/01/05 11:30:15 INFO mapReduceLayer.JobControlCompiler: mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
1367626 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
19/01/05 11:30:15 INFO mapReduceLayer.JobControlCompiler: Reduce phase detected, estimating # of required reducers.
1367627 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 100
19/01/05 11:30:15 INFO mapReduceLayer.JobControlCompiler: Setting Parallelism to 100
1367627 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
19/01/05 11:30:15 INFO mapReduceLayer.JobControlCompiler: This job cannot be converted run in-process
1367662 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1357975457/tmp1825372776/pig-0.17.0-core-h2.jar
19/01/05 11:30:15 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1357975457/tmp1825372776/pig-0.17.0-core-h2.jar
1367674 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1357975457/tmp277112817/automaton-1.11-8.jar
19/01/05 11:30:15 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1357975457/tmp277112817/automaton-1.11-8.jar
1367688 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1357975457/tmp109109568/antlr-runtime-3.4.jar
19/01/05 11:30:15 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1357975457/tmp109109568/antlr-runtime-3.4.jar
1367703 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1357975457/tmp-1532522232/joda-time-2.9.4.jar
19/01/05 11:30:15 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1357975457/tmp-1532522232/joda-time-2.9.4.jar
1367705 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
19/01/05 11:30:15 INFO mapReduceLayer.JobControlCompiler: Setting up single store job
1367714 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
19/01/05 11:30:15 INFO data.SchemaTupleFrontend: Key [pig.schematuple] is false, will not generate code.
1367715 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
19/01/05 11:30:15 INFO data.SchemaTupleFrontend: Starting process to move generated code to distributed cacche
1367715 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
19/01/05 11:30:15 INFO data.SchemaTupleFrontend: Setting key [pig.schematuple.classes] with classes to deserialize []
1367732 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
19/01/05 11:30:15 INFO mapreduce.MRScriptState: Pig script settings are added to the job
1367732 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
19/01/05 11:30:15 INFO mapReduceLayer.JobControlCompiler: mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
1367733 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
19/01/05 11:30:15 INFO mapReduceLayer.JobControlCompiler: This job cannot be converted run in-process
1367763 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1357975457/tmp-1319998650/pig-0.17.0-core-h2.jar
19/01/05 11:30:15 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1357975457/tmp-1319998650/pig-0.17.0-core-h2.jar
1367795 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1357975457/tmp-401914487/automaton-1.11-8.jar
19/01/05 11:30:15 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1357975457/tmp-401914487/automaton-1.11-8.jar
1367807 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1357975457/tmp-583366039/antlr-runtime-3.4.jar
19/01/05 11:30:15 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1357975457/tmp-583366039/antlr-runtime-3.4.jar
1367820 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1357975457/tmp698534060/joda-time-2.9.4.jar
19/01/05 11:30:15 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1357975457/tmp698534060/joda-time-2.9.4.jar
1367822 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
19/01/05 11:30:15 INFO mapReduceLayer.JobControlCompiler: Setting up single store job
1367823 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
19/01/05 11:30:15 INFO data.SchemaTupleFrontend: Key [pig.schematuple] is false, will not generate code.
1367823 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
19/01/05 11:30:15 INFO data.SchemaTupleFrontend: Starting process to move generated code to distributed cacche
1367824 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
19/01/05 11:30:15 INFO data.SchemaTupleFrontend: Setting key [pig.schematuple.classes] with classes to deserialize []
1367836 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 2 map-reduce job(s) waiting for submission.
19/01/05 11:30:15 INFO mapReduceLayer.MapReduceLauncher: 2 map-reduce job(s) waiting for submission.
19/01/05 11:30:15 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:30:15 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
1367868 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
19/01/05 11:30:15 INFO builtin.PigStorage: Using PigTextInputFormat
19/01/05 11:30:16 INFO input.FileInputFormat: Total input files to process : 512
1368026 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 512
19/01/05 11:30:16 INFO util.MapRedUtil: Total input paths to process : 512
1368041 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
19/01/05 11:30:16 INFO util.MapRedUtil: Total input paths (combined) to process : 1
19/01/05 11:30:16 INFO input.FileInputFormat: Total input files to process : 100
1368085 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 100
19/01/05 11:30:16 INFO util.MapRedUtil: Total input paths to process : 100
1368087 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
19/01/05 11:30:16 INFO util.MapRedUtil: Total input paths (combined) to process : 1
19/01/05 11:30:16 INFO mapreduce.JobSubmitter: number of splits:2
19/01/05 11:30:16 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1546632509115_0015
19/01/05 11:30:16 INFO mapred.YARNRunner: Job jar is not present. Not adding any jar to the list of resources.
19/01/05 11:30:16 INFO impl.YarnClientImpl: Submitted application application_1546632509115_0015
19/01/05 11:30:16 INFO mapreduce.Job: The url to track the job: http://neu-5-1:8088/proxy/application_1546632509115_0015/
19/01/05 11:30:16 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:30:16 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
19/01/05 11:30:16 INFO input.FileInputFormat: Total input files to process : 1
1368186 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 1
19/01/05 11:30:16 INFO util.MapRedUtil: Total input paths to process : 1
1368186 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
19/01/05 11:30:16 INFO util.MapRedUtil: Total input paths (combined) to process : 1
19/01/05 11:30:16 INFO mapreduce.JobSubmitter: number of splits:1
19/01/05 11:30:16 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1546632509115_0016
19/01/05 11:30:16 INFO mapred.YARNRunner: Job jar is not present. Not adding any jar to the list of resources.
19/01/05 11:30:16 INFO impl.YarnClientImpl: Submitted application application_1546632509115_0016
19/01/05 11:30:16 INFO mapreduce.Job: The url to track the job: http://neu-5-1:8088/proxy/application_1546632509115_0016/
1368339 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546632509115_0015
19/01/05 11:30:16 INFO mapReduceLayer.MapReduceLauncher: HadoopJobId: job_1546632509115_0015
1368340 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases n2,s1,supplier
19/01/05 11:30:16 INFO mapReduceLayer.MapReduceLauncher: Processing aliases n2,s1,supplier
1368340 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: supplier[10,11],supplier[-1,-1],n2[30,5],n2[-1,-1],s1[35,5],s1[35,5] C:  R: s1[-1,-1]
19/01/05 11:30:16 INFO mapReduceLayer.MapReduceLauncher: detailed locations: M: supplier[10,11],supplier[-1,-1],n2[30,5],n2[-1,-1],s1[35,5],s1[35,5] C:  R: s1[-1,-1]
1368342 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546632509115_0016
19/01/05 11:30:16 INFO mapReduceLayer.MapReduceLauncher: HadoopJobId: job_1546632509115_0016
1368342 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases n1,nation,seln1
19/01/05 11:30:16 INFO mapReduceLayer.MapReduceLauncher: Processing aliases n1,nation,seln1
1368342 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: nation[-1,-1],n1[21,5],seln1[22,8] C:  R: 
19/01/05 11:30:16 INFO mapReduceLayer.MapReduceLauncher: detailed locations: M: nation[-1,-1],n1[21,5],seln1[22,8] C:  R: 
1380473 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 31% complete
19/01/05 11:30:28 INFO mapReduceLayer.MapReduceLauncher: 31% complete
1380473 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0015,job_1546632509115_0016]
19/01/05 11:30:28 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546632509115_0015,job_1546632509115_0016]
1383479 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 36% complete
19/01/05 11:30:31 INFO mapReduceLayer.MapReduceLauncher: 36% complete
1383479 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0015]
19/01/05 11:30:31 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546632509115_0015]
19/01/05 11:30:31 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:30:31 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:30:31 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:30:31 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:30:31 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:30:31 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
1422647 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 41% complete
19/01/05 11:31:10 INFO mapReduceLayer.MapReduceLauncher: 41% complete
1422647 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0015]
19/01/05 11:31:10 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546632509115_0015]
^[[B19/01/05 11:40:11 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:40:11 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:40:11 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:40:11 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:40:11 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:40:11 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
1963755 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
19/01/05 11:40:11 INFO mapreduce.MRScriptState: Pig script settings are added to the job
1963756 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
19/01/05 11:40:11 INFO mapReduceLayer.JobControlCompiler: mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
1963757 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
19/01/05 11:40:11 INFO mapReduceLayer.JobControlCompiler: This job cannot be converted run in-process
1963790 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1357975457/tmp-142735817/pig-0.17.0-core-h2.jar
19/01/05 11:40:11 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1357975457/tmp-142735817/pig-0.17.0-core-h2.jar
1963804 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1357975457/tmp-695769919/automaton-1.11-8.jar
19/01/05 11:40:11 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1357975457/tmp-695769919/automaton-1.11-8.jar
1963815 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1357975457/tmp532148778/antlr-runtime-3.4.jar
19/01/05 11:40:11 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1357975457/tmp532148778/antlr-runtime-3.4.jar
1963829 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1357975457/tmp-2037410622/joda-time-2.9.4.jar
19/01/05 11:40:11 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1357975457/tmp-2037410622/joda-time-2.9.4.jar
1963830 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
19/01/05 11:40:11 INFO mapReduceLayer.JobControlCompiler: Setting up single store job
1963831 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
19/01/05 11:40:11 INFO data.SchemaTupleFrontend: Key [pig.schematuple] is false, will not generate code.
1963831 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
19/01/05 11:40:11 INFO data.SchemaTupleFrontend: Starting process to move generated code to distributed cacche
1963831 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
19/01/05 11:40:11 INFO data.SchemaTupleFrontend: Setting key [pig.schematuple.classes] with classes to deserialize []
1963839 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
19/01/05 11:40:11 INFO mapReduceLayer.MapReduceLauncher: 1 map-reduce job(s) waiting for submission.
19/01/05 11:40:11 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:40:11 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
19/01/05 11:40:11 INFO input.FileInputFormat: Total input files to process : 1
1963858 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 1
19/01/05 11:40:11 INFO util.MapRedUtil: Total input paths to process : 1
1963858 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
19/01/05 11:40:11 INFO util.MapRedUtil: Total input paths (combined) to process : 1
19/01/05 11:40:11 INFO mapreduce.JobSubmitter: number of splits:1
19/01/05 11:40:11 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1546632509115_0017
19/01/05 11:40:11 INFO mapred.YARNRunner: Job jar is not present. Not adding any jar to the list of resources.
19/01/05 11:40:12 INFO impl.YarnClientImpl: Submitted application application_1546632509115_0017
19/01/05 11:40:12 INFO mapreduce.Job: The url to track the job: http://neu-5-1:8088/proxy/application_1546632509115_0017/
1964340 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546632509115_0017
19/01/05 11:40:12 INFO mapReduceLayer.MapReduceLauncher: HadoopJobId: job_1546632509115_0017
1964341 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases 
19/01/05 11:40:12 INFO mapReduceLayer.MapReduceLauncher: Processing aliases 
1964341 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M:  C:  R: 
19/01/05 11:40:12 INFO mapReduceLayer.MapReduceLauncher: detailed locations: M:  C:  R: 
1974357 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 50% complete
19/01/05 11:40:22 INFO mapReduceLayer.MapReduceLauncher: 50% complete
1974357 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0017]
19/01/05 11:40:22 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546632509115_0017]
1979362 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 54% complete
19/01/05 11:40:27 INFO mapReduceLayer.MapReduceLauncher: 54% complete
19/01/05 11:40:27 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:40:27 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:40:27 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:40:27 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:40:27 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:40:27 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
1979490 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
19/01/05 11:40:27 INFO mapreduce.MRScriptState: Pig script settings are added to the job
1979491 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
19/01/05 11:40:27 INFO mapReduceLayer.JobControlCompiler: mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
1979492 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
19/01/05 11:40:27 INFO mapReduceLayer.JobControlCompiler: Reduce phase detected, estimating # of required reducers.
1979492 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 100
19/01/05 11:40:27 INFO mapReduceLayer.JobControlCompiler: Setting Parallelism to 100
1979492 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
19/01/05 11:40:27 INFO mapReduceLayer.JobControlCompiler: This job cannot be converted run in-process
1979525 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1357975457/tmp1764701832/pig-0.17.0-core-h2.jar
19/01/05 11:40:27 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1357975457/tmp1764701832/pig-0.17.0-core-h2.jar
1979539 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1357975457/tmp-1897204391/automaton-1.11-8.jar
19/01/05 11:40:27 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1357975457/tmp-1897204391/automaton-1.11-8.jar
1979550 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1357975457/tmp1368427108/antlr-runtime-3.4.jar
19/01/05 11:40:27 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1357975457/tmp1368427108/antlr-runtime-3.4.jar
1979564 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1357975457/tmp-86086330/joda-time-2.9.4.jar
19/01/05 11:40:27 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1357975457/tmp-86086330/joda-time-2.9.4.jar
1979566 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
19/01/05 11:40:27 INFO mapReduceLayer.JobControlCompiler: Setting up single store job
1979568 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
19/01/05 11:40:27 INFO data.SchemaTupleFrontend: Key [pig.schematuple] is false, will not generate code.
1979568 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
19/01/05 11:40:27 INFO data.SchemaTupleFrontend: Starting process to move generated code to distributed cacche
1979568 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
19/01/05 11:40:27 INFO data.SchemaTupleFrontend: Setting key [pig.schematuple.classes] with classes to deserialize []
1979584 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
19/01/05 11:40:27 INFO mapReduceLayer.MapReduceLauncher: 1 map-reduce job(s) waiting for submission.
19/01/05 11:40:27 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:40:27 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
1979606 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
19/01/05 11:40:27 INFO builtin.PigStorage: Using PigTextInputFormat
19/01/05 11:40:27 INFO input.FileInputFormat: Total input files to process : 512
1979755 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 512
19/01/05 11:40:27 INFO util.MapRedUtil: Total input paths to process : 512
1979772 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 2
19/01/05 11:40:27 INFO util.MapRedUtil: Total input paths (combined) to process : 2
1979774 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
19/01/05 11:40:27 INFO builtin.PigStorage: Using PigTextInputFormat
19/01/05 11:40:27 INFO input.FileInputFormat: Total input files to process : 512
1979900 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 512
19/01/05 11:40:27 INFO util.MapRedUtil: Total input paths to process : 512
1979911 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 12
19/01/05 11:40:28 INFO util.MapRedUtil: Total input paths (combined) to process : 12
19/01/05 11:40:28 INFO mapreduce.JobSubmitter: number of splits:14
19/01/05 11:40:28 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1546632509115_0018
19/01/05 11:40:28 INFO mapred.YARNRunner: Job jar is not present. Not adding any jar to the list of resources.
19/01/05 11:40:28 INFO impl.YarnClientImpl: Submitted application application_1546632509115_0018
19/01/05 11:40:28 INFO mapreduce.Job: The url to track the job: http://neu-5-1:8088/proxy/application_1546632509115_0018/
1980085 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546632509115_0018
19/01/05 11:40:28 INFO mapReduceLayer.MapReduceLauncher: HadoopJobId: job_1546632509115_0018
1980086 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases c1,customer,forders,o1,orders,selc1
19/01/05 11:40:28 INFO mapReduceLayer.MapReduceLauncher: Processing aliases c1,customer,forders,o1,orders,selc1
1980086 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: orders[6,9],orders[-1,-1],forders[18,10],o1[27,5],customer[4,11],customer[-1,-1],c1[24,5],selc1[25,8],o1[27,5] C:  R: o1[-1,-1]
19/01/05 11:40:28 INFO mapReduceLayer.MapReduceLauncher: detailed locations: M: orders[6,9],orders[-1,-1],forders[18,10],o1[27,5],customer[4,11],customer[-1,-1],c1[24,5],selc1[25,8],o1[27,5] C:  R: o1[-1,-1]
2019670 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 58% complete
19/01/05 11:41:07 INFO mapReduceLayer.MapReduceLauncher: 58% complete
2019670 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0018]
19/01/05 11:41:07 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546632509115_0018]
2059714 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 63% complete
19/01/05 11:41:47 INFO mapReduceLayer.MapReduceLauncher: 63% complete
2059714 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0018]
19/01/05 11:41:47 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546632509115_0018]
19/01/05 11:41:53 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:41:53 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:41:53 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:41:53 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:41:53 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:41:53 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
2065460 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
19/01/05 11:41:53 INFO mapreduce.MRScriptState: Pig script settings are added to the job
2065461 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
19/01/05 11:41:53 INFO mapReduceLayer.JobControlCompiler: mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
2065461 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
19/01/05 11:41:53 INFO mapReduceLayer.JobControlCompiler: Reduce phase detected, estimating # of required reducers.
2065461 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 100
19/01/05 11:41:53 INFO mapReduceLayer.JobControlCompiler: Setting Parallelism to 100
2065461 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
19/01/05 11:41:53 INFO mapReduceLayer.JobControlCompiler: This job cannot be converted run in-process
2065498 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1357975457/tmp-651823998/pig-0.17.0-core-h2.jar
19/01/05 11:41:53 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1357975457/tmp-651823998/pig-0.17.0-core-h2.jar
2065510 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1357975457/tmp-12549317/automaton-1.11-8.jar
19/01/05 11:41:53 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1357975457/tmp-12549317/automaton-1.11-8.jar
2065522 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1357975457/tmp1487901223/antlr-runtime-3.4.jar
19/01/05 11:41:53 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1357975457/tmp1487901223/antlr-runtime-3.4.jar
2065538 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1357975457/tmp217016235/joda-time-2.9.4.jar
19/01/05 11:41:53 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1357975457/tmp217016235/joda-time-2.9.4.jar
2065540 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
19/01/05 11:41:53 INFO mapReduceLayer.JobControlCompiler: Setting up single store job
2065540 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
19/01/05 11:41:53 INFO data.SchemaTupleFrontend: Key [pig.schematuple] is false, will not generate code.
2065540 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
19/01/05 11:41:53 INFO data.SchemaTupleFrontend: Starting process to move generated code to distributed cacche
2065540 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
19/01/05 11:41:53 INFO data.SchemaTupleFrontend: Setting key [pig.schematuple.classes] with classes to deserialize []
2065557 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
19/01/05 11:41:53 INFO mapReduceLayer.MapReduceLauncher: 1 map-reduce job(s) waiting for submission.
19/01/05 11:41:53 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:41:53 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
19/01/05 11:41:53 INFO input.FileInputFormat: Total input files to process : 100
2065587 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 100
19/01/05 11:41:53 INFO util.MapRedUtil: Total input paths to process : 100
2065588 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
19/01/05 11:41:53 INFO util.MapRedUtil: Total input paths (combined) to process : 1
19/01/05 11:41:53 INFO input.FileInputFormat: Total input files to process : 100
2065601 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 100
19/01/05 11:41:53 INFO util.MapRedUtil: Total input paths to process : 100
2065603 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
19/01/05 11:41:53 INFO util.MapRedUtil: Total input paths (combined) to process : 1
19/01/05 11:41:53 INFO mapreduce.JobSubmitter: number of splits:2
19/01/05 11:41:53 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1546632509115_0019
19/01/05 11:41:53 INFO mapred.YARNRunner: Job jar is not present. Not adding any jar to the list of resources.
19/01/05 11:41:53 INFO impl.YarnClientImpl: Submitted application application_1546632509115_0019
19/01/05 11:41:53 INFO mapreduce.Job: The url to track the job: http://neu-5-1:8088/proxy/application_1546632509115_0019/
2066058 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546632509115_0019
19/01/05 11:41:54 INFO mapReduceLayer.MapReduceLauncher: HadoopJobId: job_1546632509115_0019
2066058 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases l1,sels1
19/01/05 11:41:54 INFO mapReduceLayer.MapReduceLauncher: Processing aliases l1,sels1
2066058 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: l1[37,5],l1[37,5] C:  R: sels1[39,8]
19/01/05 11:41:54 INFO mapReduceLayer.MapReduceLauncher: detailed locations: M: l1[37,5],l1[37,5] C:  R: sels1[39,8]
2090644 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 68% complete
19/01/05 11:42:18 INFO mapReduceLayer.MapReduceLauncher: 68% complete
2090644 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0019]
19/01/05 11:42:18 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546632509115_0019]
2105665 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 72% complete
19/01/05 11:42:33 INFO mapReduceLayer.MapReduceLauncher: 72% complete
2105665 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0019]
19/01/05 11:42:33 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546632509115_0019]
19/01/05 11:42:39 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:42:39 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:42:39 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:42:39 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:42:39 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:42:39 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
2111376 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
19/01/05 11:42:39 INFO mapreduce.MRScriptState: Pig script settings are added to the job
2111376 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
19/01/05 11:42:39 INFO mapReduceLayer.JobControlCompiler: mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
2111377 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
19/01/05 11:42:39 INFO mapReduceLayer.JobControlCompiler: Reduce phase detected, estimating # of required reducers.
2111377 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 100
19/01/05 11:42:39 INFO mapReduceLayer.JobControlCompiler: Setting Parallelism to 100
2111377 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
19/01/05 11:42:39 INFO mapReduceLayer.JobControlCompiler: This job cannot be converted run in-process
2111411 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1357975457/tmp1207782946/pig-0.17.0-core-h2.jar
19/01/05 11:42:39 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1357975457/tmp1207782946/pig-0.17.0-core-h2.jar
2111423 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1357975457/tmp605610789/automaton-1.11-8.jar
19/01/05 11:42:39 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1357975457/tmp605610789/automaton-1.11-8.jar
2111435 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1357975457/tmp-1527959668/antlr-runtime-3.4.jar
19/01/05 11:42:39 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1357975457/tmp-1527959668/antlr-runtime-3.4.jar
2111448 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1357975457/tmp-1696158172/joda-time-2.9.4.jar
19/01/05 11:42:39 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1357975457/tmp-1696158172/joda-time-2.9.4.jar
2111450 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
19/01/05 11:42:39 INFO mapReduceLayer.JobControlCompiler: Setting up single store job
2111450 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
19/01/05 11:42:39 INFO data.SchemaTupleFrontend: Key [pig.schematuple] is false, will not generate code.
2111451 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
19/01/05 11:42:39 INFO data.SchemaTupleFrontend: Starting process to move generated code to distributed cacche
2111451 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
19/01/05 11:42:39 INFO data.SchemaTupleFrontend: Setting key [pig.schematuple.classes] with classes to deserialize []
2111472 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
19/01/05 11:42:39 INFO mapReduceLayer.MapReduceLauncher: 1 map-reduce job(s) waiting for submission.
19/01/05 11:42:39 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:42:39 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
19/01/05 11:42:39 INFO input.FileInputFormat: Total input files to process : 100
2111500 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 100
19/01/05 11:42:39 INFO util.MapRedUtil: Total input paths to process : 100
2111501 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
19/01/05 11:42:39 INFO util.MapRedUtil: Total input paths (combined) to process : 1
19/01/05 11:42:39 INFO mapreduce.JobSubmitter: number of splits:1
19/01/05 11:42:39 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1546632509115_0020
19/01/05 11:42:39 INFO mapred.YARNRunner: Job jar is not present. Not adding any jar to the list of resources.
19/01/05 11:42:39 INFO impl.YarnClientImpl: Submitted application application_1546632509115_0020
19/01/05 11:42:39 INFO mapreduce.Job: The url to track the job: http://neu-5-1:8088/proxy/application_1546632509115_0020/
2111973 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546632509115_0020
19/01/05 11:42:40 INFO mapReduceLayer.MapReduceLauncher: HadoopJobId: job_1546632509115_0020
2111973 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases grResult,sumResult
19/01/05 11:42:40 INFO mapReduceLayer.MapReduceLauncher: Processing aliases grResult,sumResult
2111973 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: sumResult[42,12],grResult[40,11] C: sumResult[42,12],grResult[40,11] R: sumResult[42,12]
19/01/05 11:42:40 INFO mapReduceLayer.MapReduceLauncher: detailed locations: M: sumResult[42,12],grResult[40,11] C: sumResult[42,12],grResult[40,11] R: sumResult[42,12]
2124050 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 77% complete
19/01/05 11:42:52 INFO mapReduceLayer.MapReduceLauncher: 77% complete
2124050 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0020]
19/01/05 11:42:52 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546632509115_0020]
2144073 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 81% complete
19/01/05 11:43:12 INFO mapReduceLayer.MapReduceLauncher: 81% complete
2144073 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0020]
19/01/05 11:43:12 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546632509115_0020]
19/01/05 11:43:15 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:43:15 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:43:15 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:43:15 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:43:15 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:43:15 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
2147256 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
19/01/05 11:43:15 INFO mapreduce.MRScriptState: Pig script settings are added to the job
2147256 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
19/01/05 11:43:15 INFO mapReduceLayer.JobControlCompiler: mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
2147257 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
19/01/05 11:43:15 INFO mapReduceLayer.JobControlCompiler: Reduce phase detected, estimating # of required reducers.
2147258 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
19/01/05 11:43:15 INFO mapReduceLayer.JobControlCompiler: Setting Parallelism to 1
2147258 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
19/01/05 11:43:15 INFO mapReduceLayer.JobControlCompiler: This job cannot be converted run in-process
2147290 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1357975457/tmp-596031729/pig-0.17.0-core-h2.jar
19/01/05 11:43:15 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1357975457/tmp-596031729/pig-0.17.0-core-h2.jar
2147303 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1357975457/tmp-975649398/automaton-1.11-8.jar
19/01/05 11:43:15 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1357975457/tmp-975649398/automaton-1.11-8.jar
2147313 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1357975457/tmp-1640049983/antlr-runtime-3.4.jar
19/01/05 11:43:15 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1357975457/tmp-1640049983/antlr-runtime-3.4.jar
2147327 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1357975457/tmp-323311841/joda-time-2.9.4.jar
19/01/05 11:43:15 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1357975457/tmp-323311841/joda-time-2.9.4.jar
2147328 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
19/01/05 11:43:15 INFO mapReduceLayer.JobControlCompiler: Setting up single store job
2147329 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
19/01/05 11:43:15 INFO data.SchemaTupleFrontend: Key [pig.schematuple] is false, will not generate code.
2147329 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
19/01/05 11:43:15 INFO data.SchemaTupleFrontend: Starting process to move generated code to distributed cacche
2147329 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
19/01/05 11:43:15 INFO data.SchemaTupleFrontend: Setting key [pig.schematuple.classes] with classes to deserialize []
2147344 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
19/01/05 11:43:15 INFO mapReduceLayer.MapReduceLauncher: 1 map-reduce job(s) waiting for submission.
19/01/05 11:43:15 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:43:15 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
19/01/05 11:43:15 INFO input.FileInputFormat: Total input files to process : 100
2147363 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 100
19/01/05 11:43:15 INFO util.MapRedUtil: Total input paths to process : 100
2147363 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
19/01/05 11:43:15 INFO util.MapRedUtil: Total input paths (combined) to process : 1
19/01/05 11:43:15 INFO mapreduce.JobSubmitter: number of splits:1
19/01/05 11:43:15 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1546632509115_0021
19/01/05 11:43:15 INFO mapred.YARNRunner: Job jar is not present. Not adding any jar to the list of resources.
19/01/05 11:43:15 INFO impl.YarnClientImpl: Submitted application application_1546632509115_0021
19/01/05 11:43:15 INFO mapreduce.Job: The url to track the job: http://neu-5-1:8088/proxy/application_1546632509115_0021/
2147846 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546632509115_0021
19/01/05 11:43:15 INFO mapReduceLayer.MapReduceLauncher: HadoopJobId: job_1546632509115_0021
2147846 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases sortResult
19/01/05 11:43:15 INFO mapReduceLayer.MapReduceLauncher: Processing aliases sortResult
2147846 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: sortResult[43,13] C:  R: 
19/01/05 11:43:15 INFO mapReduceLayer.MapReduceLauncher: detailed locations: M: sortResult[43,13] C:  R: 
2159909 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 86% complete
19/01/05 11:43:28 INFO mapReduceLayer.MapReduceLauncher: 86% complete
2159909 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0021]
19/01/05 11:43:28 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546632509115_0021]
2164913 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 90% complete
19/01/05 11:43:33 INFO mapReduceLayer.MapReduceLauncher: 90% complete
2164913 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0021]
19/01/05 11:43:33 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546632509115_0021]
19/01/05 11:43:36 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:43:36 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:43:36 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:43:36 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:43:36 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:43:36 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
2168021 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
19/01/05 11:43:36 INFO mapreduce.MRScriptState: Pig script settings are added to the job
2168021 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
19/01/05 11:43:36 INFO mapReduceLayer.JobControlCompiler: mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
2168022 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
19/01/05 11:43:36 INFO mapReduceLayer.JobControlCompiler: Reduce phase detected, estimating # of required reducers.
2168022 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 100
19/01/05 11:43:36 INFO mapReduceLayer.JobControlCompiler: Setting Parallelism to 100
2168022 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
19/01/05 11:43:36 INFO mapReduceLayer.JobControlCompiler: This job cannot be converted run in-process
2168053 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1357975457/tmp817775560/pig-0.17.0-core-h2.jar
19/01/05 11:43:36 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1357975457/tmp817775560/pig-0.17.0-core-h2.jar
2168066 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1357975457/tmp261231546/automaton-1.11-8.jar
19/01/05 11:43:36 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1357975457/tmp261231546/automaton-1.11-8.jar
2168077 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1357975457/tmp1042429540/antlr-runtime-3.4.jar
19/01/05 11:43:36 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1357975457/tmp1042429540/antlr-runtime-3.4.jar
2168091 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1357975457/tmp1316917521/joda-time-2.9.4.jar
19/01/05 11:43:36 INFO mapReduceLayer.JobControlCompiler: Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1357975457/tmp1316917521/joda-time-2.9.4.jar
2168092 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
19/01/05 11:43:36 INFO mapReduceLayer.JobControlCompiler: Setting up single store job
2168093 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
19/01/05 11:43:36 INFO data.SchemaTupleFrontend: Key [pig.schematuple] is false, will not generate code.
2168093 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
19/01/05 11:43:36 INFO data.SchemaTupleFrontend: Starting process to move generated code to distributed cacche
2168093 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
19/01/05 11:43:36 INFO data.SchemaTupleFrontend: Setting key [pig.schematuple.classes] with classes to deserialize []
2168109 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
19/01/05 11:43:36 INFO mapReduceLayer.MapReduceLauncher: 1 map-reduce job(s) waiting for submission.
19/01/05 11:43:36 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:43:36 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
19/01/05 11:43:36 INFO input.FileInputFormat: Total input files to process : 100
2168145 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 100
19/01/05 11:43:36 INFO util.MapRedUtil: Total input paths to process : 100
2168145 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
19/01/05 11:43:36 INFO util.MapRedUtil: Total input paths (combined) to process : 1
19/01/05 11:43:36 INFO mapreduce.JobSubmitter: number of splits:1
19/01/05 11:43:36 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1546632509115_0022
19/01/05 11:43:36 INFO mapred.YARNRunner: Job jar is not present. Not adding any jar to the list of resources.
19/01/05 11:43:36 INFO impl.YarnClientImpl: Submitted application application_1546632509115_0022
19/01/05 11:43:36 INFO mapreduce.Job: The url to track the job: http://neu-5-1:8088/proxy/application_1546632509115_0022/
2168610 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546632509115_0022
19/01/05 11:43:36 INFO mapReduceLayer.MapReduceLauncher: HadoopJobId: job_1546632509115_0022
2168610 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases sortResult
19/01/05 11:43:36 INFO mapReduceLayer.MapReduceLauncher: Processing aliases sortResult
2168610 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: sortResult[43,13] C:  R: 
19/01/05 11:43:36 INFO mapReduceLayer.MapReduceLauncher: detailed locations: M: sortResult[43,13] C:  R: 
2180221 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 95% complete
19/01/05 11:43:48 INFO mapReduceLayer.MapReduceLauncher: 95% complete
2180221 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0022]
19/01/05 11:43:48 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546632509115_0022]
2198241 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 99% complete
19/01/05 11:44:06 INFO mapReduceLayer.MapReduceLauncher: 99% complete
2198241 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0022]
19/01/05 11:44:06 INFO mapReduceLayer.MapReduceLauncher: Running jobs are [job_1546632509115_0022]
19/01/05 11:44:11 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:11 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:44:11 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:11 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:44:11 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:11 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
2203418 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
19/01/05 11:44:11 INFO mapReduceLayer.MapReduceLauncher: 100% complete
2203420 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-05 11:07:32	2019-01-05 11:44:11	REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER

Success!

Job Stats (time in seconds):
JobId	Maps	Reduces	MaxMapTime	MinMapTime	AvgMapTime	MedianMapTime	MaxReduceTime	MinReduceTime	AvgReduceTime	MedianReducetime	Alias	Feature	Outputs
job_1546632509115_0012	1	0	8	8	8	8	0	0	0	0	fregion,region	MAP_ONLY	
job_1546632509115_0013	51	100	1344	21	108	102	1298	50	149	71	fpart,lineitem,p1,part	HASH_JOIN	
job_1546632509115_0014	1	0	10	10	10	10	0	0	0	0	nation	MULTI_QUERY,MAP_ONLY	
job_1546632509115_0015	2	100	46	8	27	27	553	15	117	31	n2,s1,supplier	REPLICATED_JOIN,HASH_JOIN	
job_1546632509115_0016	1	0	3	3	3	3	0	0	0	0	n1,nation,seln1	REPLICATED_JOIN,MAP_ONLY	
job_1546632509115_0017	1	0	3	3	3	3	0	0	0	0		MAP_ONLY	
job_1546632509115_0018	14	100	64	12	29	26	58	34	46	46	c1,customer,forders,o1,orders,selc1	REPLICATED_JOIN,HASH_JOIN	
job_1546632509115_0019	2	100	17	9	13	13	8	3	5	4	l1,sels1	HASH_JOIN	
job_1546632509115_0020	1	100	4	4	4	4	4	2	3	3	grResult,sumResult	GROUP_BY,COMBINER	
job_1546632509115_0021	1	1	2	2	2	2	2	2	2	2	sortResult	SAMPLER	
job_1546632509115_0022	1	100	3	3	3	3	4	2	3	3	sortResult	ORDER_BY	/tpch/out2/Q8out,

Input(s):
Successfully read 6400000 records from: "alluxio://neu-5-1:19998/tpch/in/part"
Successfully read 192000551 records from: "alluxio://neu-5-1:19998/tpch/in/lineitem"
Successfully read 25 records (376 bytes) from: "alluxio://neu-5-1:19998/tpch/in/nation"
Successfully read 320000 records from: "alluxio://neu-5-1:19998/tpch/in/supplier"
Successfully read 5 records (376 bytes) from: "alluxio://neu-5-1:19998/tpch/in/region"
Successfully read 4800000 records from: "alluxio://neu-5-1:19998/tpch/in/customer"
Successfully read 48000000 records from: "alluxio://neu-5-1:19998/tpch/in/orders"

Output(s):
Successfully stored 2 records (50 bytes) in: "/tpch/out2/Q8out"

Counters:
Total records written : 2
Total bytes written : 50
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546632509115_0013	->	job_1546632509115_0015,
job_1546632509115_0014	->	job_1546632509115_0015,job_1546632509115_0016,
job_1546632509115_0015	->	job_1546632509115_0019,
job_1546632509115_0012	->	job_1546632509115_0016,
job_1546632509115_0016	->	job_1546632509115_0017,
job_1546632509115_0017	->	job_1546632509115_0018,
job_1546632509115_0018	->	job_1546632509115_0019,
job_1546632509115_0019	->	job_1546632509115_0020,
job_1546632509115_0020	->	job_1546632509115_0021,
job_1546632509115_0021	->	job_1546632509115_0022,
job_1546632509115_0022


19/01/05 11:44:11 INFO mapreduce.SimplePigStats: Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-05 11:07:32	2019-01-05 11:44:11	REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER

Success!

Job Stats (time in seconds):
JobId	Maps	Reduces	MaxMapTime	MinMapTime	AvgMapTime	MedianMapTime	MaxReduceTime	MinReduceTime	AvgReduceTime	MedianReducetime	Alias	Feature	Outputs
job_1546632509115_0012	1	0	8	8	8	8	0	0	0	0	fregion,region	MAP_ONLY	
job_1546632509115_0013	51	100	1344	21	108	102	1298	50	149	71	fpart,lineitem,p1,part	HASH_JOIN	
job_1546632509115_0014	1	0	10	10	10	10	0	0	0	0	nation	MULTI_QUERY,MAP_ONLY	
job_1546632509115_0015	2	100	46	8	27	27	553	15	117	31	n2,s1,supplier	REPLICATED_JOIN,HASH_JOIN	
job_1546632509115_0016	1	0	3	3	3	3	0	0	0	0	n1,nation,seln1	REPLICATED_JOIN,MAP_ONLY	
job_1546632509115_0017	1	0	3	3	3	3	0	0	0	0		MAP_ONLY	
job_1546632509115_0018	14	100	64	12	29	26	58	34	46	46	c1,customer,forders,o1,orders,selc1	REPLICATED_JOIN,HASH_JOIN	
job_1546632509115_0019	2	100	17	9	13	13	8	3	5	4	l1,sels1	HASH_JOIN	
job_1546632509115_0020	1	100	4	4	4	4	4	2	3	3	grResult,sumResult	GROUP_BY,COMBINER	
job_1546632509115_0021	1	1	2	2	2	2	2	2	2	2	sortResult	SAMPLER	
job_1546632509115_0022	1	100	3	3	3	3	4	2	3	3	sortResult	ORDER_BY	/tpch/out2/Q8out,

Input(s):
Successfully read 6400000 records from: "alluxio://neu-5-1:19998/tpch/in/part"
Successfully read 192000551 records from: "alluxio://neu-5-1:19998/tpch/in/lineitem"
Successfully read 25 records (376 bytes) from: "alluxio://neu-5-1:19998/tpch/in/nation"
Successfully read 320000 records from: "alluxio://neu-5-1:19998/tpch/in/supplier"
Successfully read 5 records (376 bytes) from: "alluxio://neu-5-1:19998/tpch/in/region"
Successfully read 4800000 records from: "alluxio://neu-5-1:19998/tpch/in/customer"
Successfully read 48000000 records from: "alluxio://neu-5-1:19998/tpch/in/orders"

Output(s):
Successfully stored 2 records (50 bytes) in: "/tpch/out2/Q8out"

Counters:
Total records written : 2
Total bytes written : 50
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546632509115_0013	->	job_1546632509115_0015,
job_1546632509115_0014	->	job_1546632509115_0015,job_1546632509115_0016,
job_1546632509115_0015	->	job_1546632509115_0019,
job_1546632509115_0012	->	job_1546632509115_0016,
job_1546632509115_0016	->	job_1546632509115_0017,
job_1546632509115_0017	->	job_1546632509115_0018,
job_1546632509115_0018	->	job_1546632509115_0019,
job_1546632509115_0019	->	job_1546632509115_0020,
job_1546632509115_0020	->	job_1546632509115_0021,
job_1546632509115_0021	->	job_1546632509115_0022,
job_1546632509115_0022


19/01/05 11:44:11 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:11 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:44:11 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:11 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:44:11 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:11 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:44:11 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:11 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:44:11 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:11 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:44:11 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:11 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:44:11 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:11 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:44:11 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:11 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:44:11 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:11 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:44:11 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:11 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:44:11 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:11 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:44:11 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:11 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:44:11 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:11 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:44:12 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:12 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:44:12 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:12 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:44:12 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:12 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:44:12 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:12 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:44:12 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:12 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:44:12 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:12 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:44:12 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:12 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:44:12 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:12 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:44:12 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:12 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:44:12 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:12 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:44:12 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:12 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:44:12 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:12 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:44:12 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:12 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:44:12 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:12 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:44:12 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:12 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:44:12 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:12 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:44:12 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:12 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:44:12 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:12 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:44:12 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:12 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
19/01/05 11:44:12 INFO client.RMProxy: Connecting to ResourceManager at neu-5-1/10.255.5.1:8032
19/01/05 11:44:12 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
2204832 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Success!
19/01/05 11:44:12 INFO mapReduceLayer.MapReduceLauncher: Success!
2204853 [main] INFO  org.apache.pig.Main  - Pig script completed in 36 minutes, 45 seconds and 3 milliseconds (2205003 ms)
19/01/05 11:44:12 INFO pig.Main: Pig script completed in 36 minutes, 45 seconds and 3 milliseconds (2205003 ms)
19/01/05 11:44:13 INFO heartbeat.HeartbeatThread: Hearbeat Master Metrics Sync is interrupted.

49   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
50   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
809  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
924  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1558 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q8.pig-7fa2fc6d-295b-40c6-bb67-c0dfc73e7852
1558 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
3977 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 2 time(s).
4001 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6000: <file queries/Q8.pig, line 45, column 0> Output Location Validation Failed for: '/tpch/out2/Q8out More info to follow:
Output directory hdfs://neu-5-1:9000/tpch/out2/Q8out already exists
4020 [main] INFO  org.apache.pig.Main  - Pig script completed in 4 seconds and 170 milliseconds (4170 ms)
51   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
51   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
815  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
929  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1520 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q8.pig-5d80dac8-2d29-425b-99c2-69e3e378b25d
1520 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
3972 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 2 time(s).
4004 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
4038 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
4068 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
4104 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
4195 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $5, $6, $7, $8
4197 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $4, $5, $6
4198 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $3
4198 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $1, $2, $4, $5, $6, $7
4199 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for part: $1, $2, $3, $5, $6, $7, $8
4200 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $3, $4, $7, $8, $9, $10, $11, $12, $13, $14, $15
4200 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for region: $2
4314 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
4329 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 0
4332 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 100
4334 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - Insert a file-concatenation job
4338 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 0
4339 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 0
4369 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
4399 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-288
4403 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
4404 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
4404 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
4404 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
4413 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 12
4413 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 map-only splittees.
4413 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 out of total 3 MR operators.
4414 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 11
4672 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
4677 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
4681 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4929 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1905762358/tmp-1162915304/pig-0.17.0-core-h2.jar
4946 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1905762358/tmp916930750/automaton-1.11-8.jar
4960 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1905762358/tmp830257092/antlr-runtime-3.4.jar
4976 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1905762358/tmp1807076415/joda-time-2.9.4.jar
4988 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4995 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4995 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4995 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
5039 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
5040 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
5040 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
5041 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 100
5041 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
5091 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1905762358/tmp1875044692/pig-0.17.0-core-h2.jar
5104 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1905762358/tmp-111034003/automaton-1.11-8.jar
5117 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1905762358/tmp-930195689/antlr-runtime-3.4.jar
5133 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1905762358/tmp20373597/joda-time-2.9.4.jar
5135 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
5135 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
5135 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
5135 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
5187 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
5187 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
5188 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
5221 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1905762358/tmp1950275242/pig-0.17.0-core-h2.jar
5234 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1905762358/tmp-726877457/automaton-1.11-8.jar
5247 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1905762358/tmp-1420473075/antlr-runtime-3.4.jar
5262 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1905762358/tmp2139573712/joda-time-2.9.4.jar
5264 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up multi store job
5265 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
5265 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
5265 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
5279 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 3 map-reduce job(s) waiting for submission.
5365 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
5422 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 1
5434 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
5826 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546632509115_0023
5826 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fregion,region
5826 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: region[14,9],region[-1,-1],fregion[17,10],fregion[-1,-1] C:  R: 
5848 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
6098 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 512
6135 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 2
6137 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
6279 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 512
6294 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 49
6396 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546632509115_0024
6396 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fpart,lineitem,p1,part
6396 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: lineitem[8,11],lineitem[-1,-1],p1[33,5],part[16,7],part[-1,-1],fpart[19,8],fpart[-1,-1],p1[33,5] C:  R: p1[-1,-1]
6419 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
6422 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 1
6422 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
6496 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546632509115_0025
6496 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases nation
6496 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: nation[12,9],nation[-1,-1],nation[-1,-1] C:  R: 
6514 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
6515 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0023,job_1546632509115_0024,job_1546632509115_0025]
21690 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 4% complete
21691 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0023,job_1546632509115_0024,job_1546632509115_0025]
23699 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 9% complete
23699 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0023,job_1546632509115_0024,job_1546632509115_0025]
26707 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 18% complete
26707 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0024]
75681 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 22% complete
75682 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0024]
105734 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 26% complete
105734 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0024]
707525 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
707527 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
707528 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
707528 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 100
707528 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
707565 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1905762358/tmp-1509164020/pig-0.17.0-core-h2.jar
707579 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1905762358/tmp1810122873/automaton-1.11-8.jar
707593 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1905762358/tmp1485590222/antlr-runtime-3.4.jar
707607 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1905762358/tmp-639239427/joda-time-2.9.4.jar
707609 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
707622 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
707622 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
707622 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
707640 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
707641 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
707641 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
707671 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1905762358/tmp-416803019/pig-0.17.0-core-h2.jar
707683 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1905762358/tmp715511451/automaton-1.11-8.jar
707697 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1905762358/tmp1400620656/antlr-runtime-3.4.jar
707712 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1905762358/tmp-1371104615/joda-time-2.9.4.jar
707715 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
707717 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
707717 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
707717 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
707730 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 2 map-reduce job(s) waiting for submission.
707755 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
707926 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 512
707944 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
707983 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 100
707984 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
708086 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 1
708087 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
708231 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546632509115_0026
708232 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases n2,s1,supplier
708232 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: supplier[10,11],supplier[-1,-1],n2[30,5],n2[-1,-1],s1[35,5],s1[35,5] C:  R: s1[-1,-1]
708235 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546632509115_0027
708235 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases n1,nation,seln1
708235 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: nation[-1,-1],n1[21,5],seln1[22,8] C:  R: 
720317 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 31% complete
720317 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0026,job_1546632509115_0027]
723322 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 36% complete
723322 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0026]
1457899 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 41% complete
1457900 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0026]
1933930 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
1933930 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
1933931 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
1933963 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1905762358/tmp-827355007/pig-0.17.0-core-h2.jar
1933975 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1905762358/tmp-918252839/automaton-1.11-8.jar
1933990 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1905762358/tmp-427538354/antlr-runtime-3.4.jar
1934003 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1905762358/tmp-1216320007/joda-time-2.9.4.jar
1934005 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
1934006 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
1934006 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
1934006 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
1934018 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
1934039 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 1
1934040 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
1934520 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546632509115_0028
1934520 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases 
1934520 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M:  C:  R: 
1944035 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 50% complete
1944035 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0028]
1949541 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 54% complete
1949676 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
1949677 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
1949678 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
1949678 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 100
1949678 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
1949711 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1905762358/tmp-737253391/pig-0.17.0-core-h2.jar
1949724 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1905762358/tmp1421483438/automaton-1.11-8.jar
1949736 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1905762358/tmp301692518/antlr-runtime-3.4.jar
1949751 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1905762358/tmp-565796998/joda-time-2.9.4.jar
1949753 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
1949755 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
1949755 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
1949755 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
1949775 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
1949793 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
1949950 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 512
1949967 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 2
1949968 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
1950093 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 512
1950104 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 12
1950276 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546632509115_0029
1950276 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases c1,customer,forders,o1,orders,selc1
1950276 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: orders[6,9],orders[-1,-1],forders[18,10],o1[27,5],customer[4,11],customer[-1,-1],c1[24,5],selc1[25,8],o1[27,5] C:  R: o1[-1,-1]
1992324 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 58% complete
1992325 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0029]
2054398 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 62% complete
2054398 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0029]
2535971 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
2535972 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
2535973 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
2535973 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 100
2535973 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
2536006 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1905762358/tmp-358775813/pig-0.17.0-core-h2.jar
2536019 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1905762358/tmp2078412514/automaton-1.11-8.jar
2536029 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1905762358/tmp1115281729/antlr-runtime-3.4.jar
2536042 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1905762358/tmp-371476519/joda-time-2.9.4.jar
2536044 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
2536045 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
2536045 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
2536045 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
2536060 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
2536098 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 100
2536100 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
2536121 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 100
2536123 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
2536561 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546632509115_0030
2536561 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases l1,sels1
2536561 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: l1[37,5],l1[37,5] C:  R: sels1[39,8]
2558642 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 67% complete
2558642 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0030]
2573662 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 71% complete
2573662 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0030]
2581863 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
2581864 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
2581864 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
2581864 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 100
2581864 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
2581898 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1905762358/tmp-1291861946/pig-0.17.0-core-h2.jar
2581909 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1905762358/tmp-1005758725/automaton-1.11-8.jar
2581919 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1905762358/tmp-1944480168/antlr-runtime-3.4.jar
2581933 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1905762358/tmp-304931132/joda-time-2.9.4.jar
2581934 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
2581935 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
2581935 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
2581935 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
2581954 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
2581979 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 100
2581980 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
2582456 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546632509115_0031
2582456 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases grResult,sumResult
2582456 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: sumResult[42,12],grResult[40,11] C: sumResult[42,12],grResult[40,11] R: sumResult[42,12]
2594097 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 77% complete
2594097 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0031]
2614119 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 81% complete
2614119 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0031]
2617304 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
2617304 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
2617305 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
2617306 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
2617306 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
2617337 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1905762358/tmp-260397903/pig-0.17.0-core-h2.jar
2617350 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1905762358/tmp1676002291/automaton-1.11-8.jar
2617361 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1905762358/tmp-1266702157/antlr-runtime-3.4.jar
2617375 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1905762358/tmp1209110702/joda-time-2.9.4.jar
2617377 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
2617377 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
2617377 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
2617377 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
2617392 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
2617420 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 100
2617420 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
2617893 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546632509115_0032
2617893 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases sortResult
2617893 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: sortResult[43,13] C:  R: 
2629959 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 86% complete
2629960 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0032]
2634965 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 90% complete
2634965 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0032]
2638096 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
2638097 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
2638097 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
2638097 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 100
2638097 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
2638128 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1905762358/tmp-1871378279/pig-0.17.0-core-h2.jar
2638139 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1905762358/tmp-1246192342/automaton-1.11-8.jar
2638150 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1905762358/tmp1101889490/antlr-runtime-3.4.jar
2638163 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1905762358/tmp1996398050/joda-time-2.9.4.jar
2638164 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
2638165 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
2638165 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
2638165 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
2638182 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
2638205 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 100
2638205 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
2638683 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546632509115_0033
2638683 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases sortResult
2638684 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: sortResult[43,13] C:  R: 
2650323 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 95% complete
2650324 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0033]
2695531 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 99% complete
2695531 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546632509115_0033]
2758772 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
2758775 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-05 13:20:54	2019-01-05 14:06:48	REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER

Success!

Job Stats (time in seconds):
JobId	Maps	Reduces	MaxMapTime	MinMapTime	AvgMapTime	MedianMapTime	MaxReduceTime	MinReduceTime	AvgReduceTime	MedianReducetime	Alias	Feature	Outputs
job_1546632509115_0023	1	0	8	8	8	8	0	0	0	0	fregion,region	MAP_ONLY	
job_1546632509115_0024	51	100	78	34	55	56	633	29	106	43	fpart,lineitem,p1,part	HASH_JOIN	
job_1546632509115_0025	1	0	6	6	6	6	0	0	0	0	nation	MULTI_QUERY,MAP_ONLY	
job_1546632509115_0026	2	100	502	10	256	256	496	5	229	254	n2,s1,supplier	REPLICATED_JOIN,HASH_JOIN	
job_1546632509115_0027	1	0	3	3	3	3	0	0	0	0	n1,nation,seln1	REPLICATED_JOIN,MAP_ONLY	
job_1546632509115_0028	1	0	2	2	2	2	0	0	0	0		MAP_ONLY	
job_1546632509115_0029	14	100	88	15	32	24	540	54	150	70	c1,customer,forders,o1,orders,selc1	REPLICATED_JOIN,HASH_JOIN	
job_1546632509115_0030	2	100	17	9	13	13	8	3	5	4	l1,sels1	HASH_JOIN	
job_1546632509115_0031	1	100	3	3	3	3	4	2	3	3	grResult,sumResult	GROUP_BY,COMBINER	
job_1546632509115_0032	1	1	3	3	3	3	3	3	3	3	sortResult	SAMPLER	
job_1546632509115_0033	1	100	2	2	2	2	4	2	3	3	sortResult	ORDER_BY	/tpch/out3/Q8out,

Input(s):
Successfully read 6400000 records from: "alluxio://neu-5-1:19998/tpch/in/part"
Successfully read 192000551 records from: "alluxio://neu-5-1:19998/tpch/in/lineitem"
Successfully read 25 records (376 bytes) from: "alluxio://neu-5-1:19998/tpch/in/nation"
Successfully read 320000 records from: "alluxio://neu-5-1:19998/tpch/in/supplier"
Successfully read 5 records (376 bytes) from: "alluxio://neu-5-1:19998/tpch/in/region"
Successfully read 4800000 records from: "alluxio://neu-5-1:19998/tpch/in/customer"
Successfully read 48000000 records from: "alluxio://neu-5-1:19998/tpch/in/orders"

Output(s):
Successfully stored 2 records (50 bytes) in: "/tpch/out3/Q8out"

Counters:
Total records written : 2
Total bytes written : 50
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546632509115_0024	->	job_1546632509115_0026,
job_1546632509115_0025	->	job_1546632509115_0026,job_1546632509115_0027,
job_1546632509115_0026	->	job_1546632509115_0030,
job_1546632509115_0023	->	job_1546632509115_0027,
job_1546632509115_0027	->	job_1546632509115_0028,
job_1546632509115_0028	->	job_1546632509115_0029,
job_1546632509115_0029	->	job_1546632509115_0030,
job_1546632509115_0030	->	job_1546632509115_0031,
job_1546632509115_0031	->	job_1546632509115_0032,
job_1546632509115_0032	->	job_1546632509115_0033,
job_1546632509115_0033


2763133 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Success!
2763154 [main] INFO  org.apache.pig.Main  - Pig script completed in 46 minutes, 3 seconds and 314 milliseconds (2763314 ms)
49   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
50   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
803  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
916  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1510 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q8.pig-0539d2e2-bb5f-4a05-99d2-9896a3a7f7c1
1510 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
5983 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 2 time(s).
6013 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
6061 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
6094 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
6180 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
6269 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $5, $6, $7, $8
6271 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $4, $5, $6
6271 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $3
6272 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $1, $2, $4, $5, $6, $7
6272 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for part: $1, $2, $3, $5, $6, $7, $8
6273 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $3, $4, $7, $8, $9, $10, $11, $12, $13, $14, $15
6273 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for region: $2
6383 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
6403 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 0
6407 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 100
6409 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - Insert a file-concatenation job
6415 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 0
6415 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 0
6441 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
6464 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-288
6469 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
6469 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
6470 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
6470 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
6479 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 12
6480 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 map-only splittees.
6480 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 out of total 3 MR operators.
6480 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 11
6739 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
6744 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
6748 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
6936 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp2120434007/tmp652435622/pig-0.17.0-core-h2.jar
6953 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp2120434007/tmp-824732128/automaton-1.11-8.jar
6969 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp2120434007/tmp1261893327/antlr-runtime-3.4.jar
6990 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp2120434007/tmp2090438479/joda-time-2.9.4.jar
7001 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
7008 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
7008 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
7008 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
7051 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
7051 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
7052 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
7052 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 100
7052 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
7085 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp2120434007/tmp-1294655671/pig-0.17.0-core-h2.jar
7102 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp2120434007/tmp-821054212/automaton-1.11-8.jar
7117 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp2120434007/tmp241085796/antlr-runtime-3.4.jar
7145 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp2120434007/tmp836150431/joda-time-2.9.4.jar
7147 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
7148 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
7148 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
7149 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
7201 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
7202 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
7203 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
7237 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp2120434007/tmp1176111262/pig-0.17.0-core-h2.jar
7252 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp2120434007/tmp-189627656/automaton-1.11-8.jar
7265 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp2120434007/tmp-707209780/antlr-runtime-3.4.jar
7280 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp2120434007/tmp665344895/joda-time-2.9.4.jar
7282 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up multi store job
7283 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
7283 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
7283 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
7297 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 3 map-reduce job(s) waiting for submission.
7397 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
7563 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 1
7576 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
8335 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_0001
8335 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fregion,region
8336 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: region[14,9],region[-1,-1],fregion[17,10],fregion[-1,-1] C:  R: 
8359 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
8556 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 512
8589 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 24
8592 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
8769 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 512
8784 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 768
8947 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_0002
8947 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fpart,lineitem,p1,part
8947 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: lineitem[8,11],lineitem[-1,-1],p1[33,5],part[16,7],part[-1,-1],fpart[19,8],fpart[-1,-1],p1[33,5] C:  R: p1[-1,-1]
8970 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
9129 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 1
9130 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
9206 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_0003
9207 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases nation
9207 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: nation[12,9],nation[-1,-1],nation[-1,-1] C:  R: 
9221 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9221 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0001,job_1546715600715_0002,job_1546715600715_0003]
21460 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 4% complete
21460 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0001,job_1546715600715_0002,job_1546715600715_0003]
24468 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 9% complete
24468 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0002,job_1546715600715_0003]
26846 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 13% complete
26846 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0002,job_1546715600715_0003]
29854 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 18% complete
29854 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0002]
669103 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 22% complete
669104 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0002]
993354 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 26% complete
993355 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0002]
1002768 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
1002769 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
1002770 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
1002770 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 100
1002770 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
1002809 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp2120434007/tmp-1128493922/pig-0.17.0-core-h2.jar
1002823 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp2120434007/tmp-527937530/automaton-1.11-8.jar
1002836 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp2120434007/tmp-868004783/antlr-runtime-3.4.jar
1002851 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp2120434007/tmp-460513127/joda-time-2.9.4.jar
1002853 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
1002863 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
1002863 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
1002863 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
1002880 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
1002880 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
1002881 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
1002914 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp2120434007/tmp1517395246/pig-0.17.0-core-h2.jar
1002926 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp2120434007/tmp1772527696/automaton-1.11-8.jar
1002938 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp2120434007/tmp1512034786/antlr-runtime-3.4.jar
1002964 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp2120434007/tmp311022873/joda-time-2.9.4.jar
1002965 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
1002967 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
1002967 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
1002967 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
1002977 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 2 map-reduce job(s) waiting for submission.
1002999 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
1003178 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 512
1003189 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 2
1003227 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 100
1003228 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
1003329 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 1
1003330 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
1003479 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_0004
1003479 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases n2,s1,supplier
1003479 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: supplier[10,11],supplier[-1,-1],n2[30,5],n2[-1,-1],s1[35,5],s1[35,5] C:  R: s1[-1,-1]
1003481 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_0005
1003481 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases n1,nation,seln1
1003481 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: nation[-1,-1],n1[21,5],seln1[22,8] C:  R: 
1015706 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 31% complete
1015706 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0004,job_1546715600715_0005]
1018711 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 36% complete
1018711 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0004]
1025866 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 40% complete
1025866 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0004]
1043387 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 45% complete
1043388 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0004]
1049140 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
1049140 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
1049141 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
1049179 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp2120434007/tmp-590312032/pig-0.17.0-core-h2.jar
1049192 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp2120434007/tmp-155145251/automaton-1.11-8.jar
1049204 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp2120434007/tmp739252758/antlr-runtime-3.4.jar
1049218 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp2120434007/tmp-1338431898/joda-time-2.9.4.jar
1049219 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
1049220 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
1049220 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
1049220 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
1049229 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
1049247 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 1
1049247 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
1049730 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_0006
1049730 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases 
1049730 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M:  C:  R: 
1061793 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 50% complete
1061793 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0006]
1064796 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 54% complete
1064928 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
1064929 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
1064929 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
1064929 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 100
1064930 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
1064965 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp2120434007/tmp365330409/pig-0.17.0-core-h2.jar
1064980 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp2120434007/tmp1786121413/automaton-1.11-8.jar
1064993 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp2120434007/tmp-1693180732/antlr-runtime-3.4.jar
1065008 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp2120434007/tmp-1040072122/joda-time-2.9.4.jar
1065009 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
1065011 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
1065011 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
1065011 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
1065030 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
1065049 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
1065221 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 512
1065232 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 24
1065234 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
1065404 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 512
1065415 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 171
1065687 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_0007
1065687 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases c1,customer,forders,o1,orders,selc1
1065687 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: orders[6,9],orders[-1,-1],forders[18,10],o1[27,5],customer[4,11],customer[-1,-1],c1[24,5],selc1[25,8],o1[27,5] C:  R: o1[-1,-1]
1277976 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 58% complete
1277977 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0007]
1358054 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 62% complete
1358055 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0007]
1366435 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
1366436 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
1366437 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
1366437 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 100
1366437 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
1366470 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp2120434007/tmp-1018951043/pig-0.17.0-core-h2.jar
1366483 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp2120434007/tmp491073853/automaton-1.11-8.jar
1366495 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp2120434007/tmp-851731233/antlr-runtime-3.4.jar
1366509 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp2120434007/tmp204498474/joda-time-2.9.4.jar
1366511 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
1366511 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
1366511 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
1366511 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
1366528 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
1366576 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 100
1366577 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
1366592 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 100
1366593 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
1367044 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_0008
1367044 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases l1,sels1
1367044 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: l1[37,5],l1[37,5] C:  R: sels1[39,8]
1389166 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 68% complete
1389166 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0008]
1404204 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 72% complete
1404205 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0008]
1411945 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
1411945 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
1411946 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
1411946 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 100
1411946 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
1411981 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp2120434007/tmp-75818987/pig-0.17.0-core-h2.jar
1411994 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp2120434007/tmp-878855673/automaton-1.11-8.jar
1412008 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp2120434007/tmp1061459925/antlr-runtime-3.4.jar
1412025 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp2120434007/tmp1806771395/joda-time-2.9.4.jar
1412026 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
1412027 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
1412027 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
1412027 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
1412045 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
1412079 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 100
1412081 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
1412546 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_0009
1412546 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases grResult,sumResult
1412546 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: sumResult[42,12],grResult[40,11] C: sumResult[42,12],grResult[40,11] R: sumResult[42,12]
1424566 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 77% complete
1424566 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0009]
1444589 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 81% complete
1444589 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0009]
1447785 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
1447786 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
1447787 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
1447788 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
1447788 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
1447823 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp2120434007/tmp-457932879/pig-0.17.0-core-h2.jar
1447836 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp2120434007/tmp1578486827/automaton-1.11-8.jar
1447848 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp2120434007/tmp1420216123/antlr-runtime-3.4.jar
1447863 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp2120434007/tmp1017049306/joda-time-2.9.4.jar
1447864 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
1447864 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
1447864 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
1447864 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
1447880 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
1447902 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 100
1447903 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
1448381 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_0010
1448381 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases sortResult
1448381 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: sortResult[43,13] C:  R: 
1460048 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 86% complete
1460048 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0010]
1465053 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 90% complete
1465053 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0010]
1468205 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
1468206 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
1468207 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
1468207 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 100
1468207 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
1468239 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp2120434007/tmp714643680/pig-0.17.0-core-h2.jar
1468253 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp2120434007/tmp-1254733337/automaton-1.11-8.jar
1468265 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp2120434007/tmp-1314711383/antlr-runtime-3.4.jar
1468281 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp2120434007/tmp-692027039/joda-time-2.9.4.jar
1468282 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
1468283 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
1468283 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
1468283 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
1468305 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
1468327 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 100
1468328 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
1468806 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_0011
1468806 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases sortResult
1468806 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: sortResult[43,13] C:  R: 
1478860 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 95% complete
1478860 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0011]
1500894 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0011]
1504088 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
1504091 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-05 15:05:31	2019-01-05 15:30:28	REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER

Success!

Job Stats (time in seconds):
JobId	Maps	Reduces	MaxMapTime	MinMapTime	AvgMapTime	MedianMapTime	MaxReduceTime	MinReduceTime	AvgReduceTime	MedianReducetime	Alias	Feature	Outputs
job_1546715600715_0001	1	0	4	4	4	4	0	0	0	0	fregion,region	MAP_ONLY	
job_1546715600715_0002	792	100	14	4	6	6	930	122	714	717	fpart,lineitem,p1,part	HASH_JOIN	
job_1546715600715_0003	1	0	7	7	7	7	0	0	0	0	nation	MULTI_QUERY,MAP_ONLY	
job_1546715600715_0004	3	100	14	8	11	10	5	2	4	4	n2,s1,supplier	REPLICATED_JOIN,HASH_JOIN	
job_1546715600715_0005	1	0	3	3	3	3	0	0	0	0	n1,nation,seln1	REPLICATED_JOIN,MAP_ONLY	
job_1546715600715_0006	1	0	3	3	3	3	0	0	0	0		MAP_ONLY	
job_1546715600715_0007	195	100	14	4	5	5	268	124	202	204	c1,customer,forders,o1,orders,selc1	REPLICATED_JOIN,HASH_JOIN	
job_1546715600715_0008	2	100	14	8	11	11	6	3	4	4	l1,sels1	HASH_JOIN	
job_1546715600715_0009	1	100	4	4	4	4	4	2	3	3	grResult,sumResult	GROUP_BY,COMBINER	
job_1546715600715_0010	1	1	3	3	3	3	3	3	3	3	sortResult	SAMPLER	
job_1546715600715_0011	1	100	3	3	3	3	4	2	3	3	sortResult	ORDER_BY	/tpch/out3/Q8out,

Input(s):
Successfully read 6400000 records from: "s3a://alluxio/tpch/in/part"
Successfully read 192000551 records from: "s3a://alluxio/tpch/in/lineitem"
Successfully read 25 records (366 bytes) from: "s3a://alluxio/tpch/in/nation"
Successfully read 320000 records from: "s3a://alluxio/tpch/in/supplier"
Successfully read 5 records (366 bytes) from: "s3a://alluxio/tpch/in/region"
Successfully read 4800000 records from: "s3a://alluxio/tpch/in/customer"
Successfully read 48000000 records from: "s3a://alluxio/tpch/in/orders"

Output(s):
Successfully stored 2 records (51 bytes) in: "/tpch/out3/Q8out"

Counters:
Total records written : 2
Total bytes written : 51
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_0002	->	job_1546715600715_0004,
job_1546715600715_0003	->	job_1546715600715_0004,job_1546715600715_0005,
job_1546715600715_0004	->	job_1546715600715_0008,
job_1546715600715_0001	->	job_1546715600715_0005,
job_1546715600715_0005	->	job_1546715600715_0006,
job_1546715600715_0006	->	job_1546715600715_0007,
job_1546715600715_0007	->	job_1546715600715_0008,
job_1546715600715_0008	->	job_1546715600715_0009,
job_1546715600715_0009	->	job_1546715600715_0010,
job_1546715600715_0010	->	job_1546715600715_0011,
job_1546715600715_0011


1506075 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Success!
1506096 [main] INFO  org.apache.pig.Main  - Pig script completed in 25 minutes, 6 seconds and 265 milliseconds (1506265 ms)
48   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
49   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
807  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
920  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1503 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q8.pig-25e4677a-cff4-46ef-966e-afe7d81f8961
1503 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
3907 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 2 time(s).
3938 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
3972 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
4003 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
4039 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
4130 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $5, $6, $7, $8
4132 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $4, $5, $6
4133 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $3
4133 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $1, $2, $4, $5, $6, $7
4133 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for part: $1, $2, $3, $5, $6, $7, $8
4134 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $3, $4, $7, $8, $9, $10, $11, $12, $13, $14, $15
4134 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for region: $2
4247 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
4262 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 0
4266 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 100
4267 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - Insert a file-concatenation job
4272 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 0
4272 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 0
4302 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
4328 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-288
4332 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
4333 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
4333 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
4333 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
4342 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 12
4343 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 map-only splittees.
4343 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 out of total 3 MR operators.
4343 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 11
4602 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
4607 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
4611 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4870 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp359224828/tmp-618565035/pig-0.17.0-core-h2.jar
4888 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp359224828/tmp1777262858/automaton-1.11-8.jar
4902 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp359224828/tmp1186508812/antlr-runtime-3.4.jar
4920 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp359224828/tmp-605581842/joda-time-2.9.4.jar
4932 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4939 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4939 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4939 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4984 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
4984 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
4986 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
4986 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 100
4986 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
5019 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp359224828/tmp1797366822/pig-0.17.0-core-h2.jar
5033 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp359224828/tmp-1795003358/automaton-1.11-8.jar
5048 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp359224828/tmp1445125364/antlr-runtime-3.4.jar
5063 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp359224828/tmp-998734443/joda-time-2.9.4.jar
5065 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
5066 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
5066 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
5067 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
5125 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
5126 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
5126 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
5157 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp359224828/tmp1156894523/pig-0.17.0-core-h2.jar
5172 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp359224828/tmp871391846/automaton-1.11-8.jar
5184 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp359224828/tmp906592946/antlr-runtime-3.4.jar
5201 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp359224828/tmp-754264022/joda-time-2.9.4.jar
5203 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up multi store job
5204 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
5204 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
5204 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
5218 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 3 map-reduce job(s) waiting for submission.
5304 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
5365 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 1
5378 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
5758 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_0012
5758 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fregion,region
5758 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: region[14,9],region[-1,-1],fregion[17,10],fregion[-1,-1] C:  R: 
5781 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
6086 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 512
6126 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 2
6128 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
6307 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 512
6323 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 49
6436 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_0013
6436 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fpart,lineitem,p1,part
6436 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: lineitem[8,11],lineitem[-1,-1],p1[33,5],part[16,7],part[-1,-1],fpart[19,8],fpart[-1,-1],p1[33,5] C:  R: p1[-1,-1]
6458 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
6460 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 1
6461 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
6530 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_0014
6530 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases nation
6530 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: nation[12,9],nation[-1,-1],nation[-1,-1] C:  R: 
6543 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
6543 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0012,job_1546715600715_0013,job_1546715600715_0014]
23743 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 4% complete
23743 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0012,job_1546715600715_0013,job_1546715600715_0014]
25750 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 9% complete
25750 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0012,job_1546715600715_0013,job_1546715600715_0014]
26751 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 13% complete
26752 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0013,job_1546715600715_0014]
32047 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 18% complete
32048 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0013]
68745 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 22% complete
68745 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0013]
86770 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 26% complete
86770 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0013]
92103 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
92104 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
92105 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
92105 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 100
92105 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
92308 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp359224828/tmp631794998/pig-0.17.0-core-h2.jar
92322 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp359224828/tmp-1722219423/automaton-1.11-8.jar
92334 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp359224828/tmp831277716/antlr-runtime-3.4.jar
92349 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp359224828/tmp-2022303398/joda-time-2.9.4.jar
92351 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
92361 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
92361 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
92361 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
92381 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
92382 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
92383 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
92419 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp359224828/tmp802213459/pig-0.17.0-core-h2.jar
92433 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp359224828/tmp-856606423/automaton-1.11-8.jar
92446 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp359224828/tmp-377824950/antlr-runtime-3.4.jar
92461 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp359224828/tmp-561919024/joda-time-2.9.4.jar
92464 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
92466 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
92466 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
92466 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
92480 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 2 map-reduce job(s) waiting for submission.
92506 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
92665 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 512
92679 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
92713 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 100
92714 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
92993 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_0015
92993 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases n2,s1,supplier
92993 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: supplier[10,11],supplier[-1,-1],n2[30,5],n2[-1,-1],s1[35,5],s1[35,5] C:  R: s1[-1,-1]
93020 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 1
93020 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
93097 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_0016
93097 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases n1,nation,seln1
93097 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: nation[-1,-1],n1[21,5],seln1[22,8] C:  R: 
103216 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 31% complete
103216 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0015,job_1546715600715_0016]
108227 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 38% complete
108227 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0015]
122887 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 43% complete
122887 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0015]
133611 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
133611 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
133612 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
133649 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp359224828/tmp1675247248/pig-0.17.0-core-h2.jar
133662 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp359224828/tmp18937576/automaton-1.11-8.jar
133674 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp359224828/tmp859707434/antlr-runtime-3.4.jar
133688 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp359224828/tmp-1882448727/joda-time-2.9.4.jar
133690 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
133690 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
133690 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
133690 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
133700 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
133720 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 1
133720 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
134202 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_0017
134202 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases 
134202 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M:  C:  R: 
143770 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 50% complete
143770 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0017]
149276 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 54% complete
149403 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
149403 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
149404 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
149404 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 100
149404 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
149438 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp359224828/tmp669418440/pig-0.17.0-core-h2.jar
149453 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp359224828/tmp326968078/automaton-1.11-8.jar
149465 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp359224828/tmp-367641719/antlr-runtime-3.4.jar
149481 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp359224828/tmp-312272252/joda-time-2.9.4.jar
149482 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
149484 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
149484 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
149484 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
149501 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
149519 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
149671 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 512
149686 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 2
149687 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
149825 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 512
149836 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 12
150002 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_0018
150002 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases c1,customer,forders,o1,orders,selc1
150002 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: orders[6,9],orders[-1,-1],forders[18,10],o1[27,5],customer[4,11],customer[-1,-1],c1[24,5],selc1[25,8],o1[27,5] C:  R: o1[-1,-1]
184649 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 58% complete
184649 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0018]
199178 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 63% complete
199178 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0018]
205375 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
205376 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
205376 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
205376 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 100
205376 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
205412 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp359224828/tmp-1850871278/pig-0.17.0-core-h2.jar
205423 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp359224828/tmp-1466077752/automaton-1.11-8.jar
205436 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp359224828/tmp-825614710/antlr-runtime-3.4.jar
205450 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp359224828/tmp4014307/joda-time-2.9.4.jar
205451 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
205451 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
205452 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
205452 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
205468 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
205498 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 100
205500 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
205512 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 100
205513 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
205969 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_0019
205969 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases l1,sels1
205969 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: l1[37,5],l1[37,5] C:  R: sels1[39,8]
227587 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 68% complete
227588 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0019]
244609 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 72% complete
244609 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0019]
250817 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
250817 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
250818 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
250818 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 100
250818 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
250852 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp359224828/tmp-73446349/pig-0.17.0-core-h2.jar
250864 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp359224828/tmp-783869088/automaton-1.11-8.jar
250876 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp359224828/tmp-1409361229/antlr-runtime-3.4.jar
250892 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp359224828/tmp-937166287/joda-time-2.9.4.jar
250894 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
250894 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
250894 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
250894 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
250914 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
250940 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 100
250941 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
251415 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_0020
251415 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases grResult,sumResult
251415 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: sumResult[42,12],grResult[40,11] C: sumResult[42,12],grResult[40,11] R: sumResult[42,12]
263436 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 77% complete
263436 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0020]
283458 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 81% complete
283458 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0020]
286647 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
286647 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
286648 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
286649 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
286649 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
286683 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp359224828/tmp1077458772/pig-0.17.0-core-h2.jar
286695 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp359224828/tmp-63930397/automaton-1.11-8.jar
286706 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp359224828/tmp448316605/antlr-runtime-3.4.jar
286719 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp359224828/tmp-1254769145/joda-time-2.9.4.jar
286720 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
286721 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
286721 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
286721 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
286738 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
286756 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 100
286757 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
287239 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_0021
287240 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases sortResult
287240 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: sortResult[43,13] C:  R: 
299305 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 86% complete
299305 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0021]
304312 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 90% complete
304312 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0021]
307426 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
307426 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
307427 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
307427 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 100
307427 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
307469 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp359224828/tmp1011856884/pig-0.17.0-core-h2.jar
307481 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp359224828/tmp185471235/automaton-1.11-8.jar
307492 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp359224828/tmp1831789226/antlr-runtime-3.4.jar
307505 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp359224828/tmp-764063830/joda-time-2.9.4.jar
307507 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
307507 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
307507 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
307507 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
307523 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
307542 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 100
307542 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
308024 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_0022
308024 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases sortResult
308024 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: sortResult[43,13] C:  R: 
319692 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 95% complete
319692 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0022]
339719 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 99% complete
339719 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0022]
342900 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
342903 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-05 15:38:18	2019-01-05 15:43:57	REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER

Success!

Job Stats (time in seconds):
JobId	Maps	Reduces	MaxMapTime	MinMapTime	AvgMapTime	MedianMapTime	MaxReduceTime	MinReduceTime	AvgReduceTime	MedianReducetime	Alias	Feature	Outputs
job_1546715600715_0012	1	0	8	8	8	8	0	0	0	0	fregion,region	MAP_ONLY	
job_1546715600715_0013	51	100	55	20	48	49	18	8	13	13	fpart,lineitem,p1,part	HASH_JOIN	
job_1546715600715_0014	1	0	11	11	11	11	0	0	0	0	nation	MULTI_QUERY,MAP_ONLY	
job_1546715600715_0015	2	100	9	7	8	8	7	2	4	4	n2,s1,supplier	REPLICATED_JOIN,HASH_JOIN	
job_1546715600715_0016	1	0	3	3	3	3	0	0	0	0	n1,nation,seln1	REPLICATED_JOIN,MAP_ONLY	
job_1546715600715_0017	1	0	3	3	3	3	0	0	0	0		MAP_ONLY	
job_1546715600715_0018	14	100	30	12	23	24	20	4	10	9	c1,customer,forders,o1,orders,selc1	REPLICATED_JOIN,HASH_JOIN	
job_1546715600715_0019	2	100	14	8	11	11	6	3	4	4	l1,sels1	HASH_JOIN	
job_1546715600715_0020	1	100	3	3	3	3	4	2	3	3	grResult,sumResult	GROUP_BY,COMBINER	
job_1546715600715_0021	1	1	2	2	2	2	2	2	2	2	sortResult	SAMPLER	
job_1546715600715_0022	1	100	3	3	3	3	4	2	3	3	sortResult	ORDER_BY	/tpch/out1/Q8out,

Input(s):
Successfully read 6400000 records from: "alluxio://neu-5-1:19998/tpch/in/part"
Successfully read 192000551 records from: "alluxio://neu-5-1:19998/tpch/in/lineitem"
Successfully read 25 records (376 bytes) from: "alluxio://neu-5-1:19998/tpch/in/nation"
Successfully read 320000 records from: "alluxio://neu-5-1:19998/tpch/in/supplier"
Successfully read 5 records (376 bytes) from: "alluxio://neu-5-1:19998/tpch/in/region"
Successfully read 4800000 records from: "alluxio://neu-5-1:19998/tpch/in/customer"
Successfully read 48000000 records from: "alluxio://neu-5-1:19998/tpch/in/orders"

Output(s):
Successfully stored 2 records (50 bytes) in: "/tpch/out1/Q8out"

Counters:
Total records written : 2
Total bytes written : 50
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_0013	->	job_1546715600715_0015,
job_1546715600715_0014	->	job_1546715600715_0015,job_1546715600715_0016,
job_1546715600715_0015	->	job_1546715600715_0019,
job_1546715600715_0012	->	job_1546715600715_0016,
job_1546715600715_0016	->	job_1546715600715_0017,
job_1546715600715_0017	->	job_1546715600715_0018,
job_1546715600715_0018	->	job_1546715600715_0019,
job_1546715600715_0019	->	job_1546715600715_0020,
job_1546715600715_0020	->	job_1546715600715_0021,
job_1546715600715_0021	->	job_1546715600715_0022,
job_1546715600715_0022


344259 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Success!
344279 [main] INFO  org.apache.pig.Main  - Pig script completed in 5 minutes, 44 seconds and 431 milliseconds (344431 ms)
49   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
50   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
48   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
49   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
809  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
922  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1469 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q8.pig-c93e5a38-f2d3-4edf-82a0-229339da87e5
1469 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
3849 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 2 time(s).
49   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
50   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
808  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
922  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1554 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q8.pig-7a2ac879-ae33-43da-a01d-8b2d30868f4a
1554 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
3937 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 2 time(s).
4570 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
4604 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
4634 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
4672 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
4762 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $5, $6, $7, $8
4764 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $4, $5, $6
4764 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $3
4765 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $1, $2, $4, $5, $6, $7
4765 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for part: $1, $2, $3, $5, $6, $7, $8
4766 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $3, $4, $7, $8, $9, $10, $11, $12, $13, $14, $15
4766 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for region: $2
4817 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 0: java.lang.IllegalArgumentException: Wrong FS: alluxio://neu-5-1:19998/tmp/temp860728235, expected: hdfs://neu-5-1:9000
4836 [main] INFO  org.apache.pig.Main  - Pig script completed in 4 seconds and 986 milliseconds (4986 ms)
50   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
50   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
809  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
923  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1545 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q8.pig-8ac3d4dd-9f25-4cd8-9769-c05ed54a9853
1545 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
3912 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 2 time(s).
3943 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
3977 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
4008 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
4042 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
4133 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $5, $6, $7, $8
4135 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $4, $5, $6
4136 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $3
4136 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $1, $2, $4, $5, $6, $7
4137 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for part: $1, $2, $3, $5, $6, $7, $8
4137 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $3, $4, $7, $8, $9, $10, $11, $12, $13, $14, $15
4137 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for region: $2
4188 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 0: java.lang.IllegalArgumentException: Wrong FS: alluxio://neu-5-1:19998/tmp/temp1137940662, expected: hdfs://neu-5-1:9000
4207 [main] INFO  org.apache.pig.Main  - Pig script completed in 4 seconds and 358 milliseconds (4358 ms)
49   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
50   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
810  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
924  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1495 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q8.pig-13d71438-6d5a-477f-87a2-1099c9c85f64
1495 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
3884 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 2 time(s).
3914 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
3949 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
3979 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
4016 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
4106 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $5, $6, $7, $8
4108 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $4, $5, $6
4108 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $3
4109 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $1, $2, $4, $5, $6, $7
4109 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for part: $1, $2, $3, $5, $6, $7, $8
4110 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $3, $4, $7, $8, $9, $10, $11, $12, $13, $14, $15
4110 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for region: $2
4160 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 0: java.lang.IllegalArgumentException: Wrong FS: alluxio://neu-5-1:19998/tmp/temp1078730042, expected: hdfs://neu-5-1:9000
4179 [main] INFO  org.apache.pig.Main  - Pig script completed in 4 seconds and 332 milliseconds (4332 ms)
49   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
50   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
812  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
926  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1553 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q8.pig-5104a6aa-007a-4fc3-83b8-039da6803152
1554 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
3924 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 2 time(s).
3954 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
3989 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
4019 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
4055 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
4146 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $5, $6, $7, $8
4148 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $4, $5, $6
4149 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $3
4149 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $1, $2, $4, $5, $6, $7
4150 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for part: $1, $2, $3, $5, $6, $7, $8
4150 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $3, $4, $7, $8, $9, $10, $11, $12, $13, $14, $15
4151 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for region: $2
4201 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 0: java.lang.IllegalArgumentException: Wrong FS: alluxio://neu-5-1:19998/tmp/temp1281368047, expected: hdfs://neu-5-1:9000
4219 [main] INFO  org.apache.pig.Main  - Pig script completed in 4 seconds and 374 milliseconds (4374 ms)
51   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
52   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
811  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
925  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1471 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q8.pig-82d22643-bd5f-461f-bcc3-5cb1c477e35e
1471 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
3820 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 2 time(s).
3850 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
3884 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
3915 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
3953 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
4045 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $5, $6, $7, $8
4047 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $4, $5, $6
4048 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $3
4048 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $1, $2, $4, $5, $6, $7
4049 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for part: $1, $2, $3, $5, $6, $7, $8
4049 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $3, $4, $7, $8, $9, $10, $11, $12, $13, $14, $15
4050 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for region: $2
4100 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 0: java.lang.IllegalArgumentException: Wrong FS: alluxio://neu-5-1:19998/temp93723410, expected: hdfs://neu-5-1:9000
4119 [main] INFO  org.apache.pig.Main  - Pig script completed in 4 seconds and 267 milliseconds (4267 ms)
49   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
49   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
806  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
920  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1478 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q8.pig-f56b13c5-3369-4d41-a355-54249a3c3e0a
1478 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
3822 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 2 time(s).
3853 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
3887 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
3917 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
3953 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
4044 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $5, $6, $7, $8
4046 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $4, $5, $6
4047 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $3
4047 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $1, $2, $4, $5, $6, $7
4048 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for part: $1, $2, $3, $5, $6, $7, $8
4048 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $3, $4, $7, $8, $9, $10, $11, $12, $13, $14, $15
4049 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for region: $2
4099 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 0: java.lang.IllegalArgumentException: Wrong FS: alluxio://neu-5-1:19998/tmp/temp1349712660, expected: hdfs://neu-5-1:9000
4117 [main] INFO  org.apache.pig.Main  - Pig script completed in 4 seconds and 268 milliseconds (4268 ms)
48   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
49   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
807  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
921  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1550 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q8.pig-96716ad8-6a5d-4356-9f61-042b969f9c7b
1550 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
3907 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 2 time(s).
3938 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
3972 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
4003 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
4041 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
4133 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $5, $6, $7, $8
4136 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $4, $5, $6
4136 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $3
4137 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $1, $2, $4, $5, $6, $7
4137 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for part: $1, $2, $3, $5, $6, $7, $8
4138 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $3, $4, $7, $8, $9, $10, $11, $12, $13, $14, $15
4138 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for region: $2
4190 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 0: java.lang.IllegalArgumentException: Wrong FS: alluxio://neu-5-1:19998/temp-1205448387, expected: hdfs://neu-5-1:9000
4209 [main] INFO  org.apache.pig.Main  - Pig script completed in 4 seconds and 358 milliseconds (4358 ms)
48   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
49   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
806  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
920  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1522 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q8.pig-5739a74d-9c4c-48fb-8c75-5f6f8557c345
1522 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
3878 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 2 time(s).
3908 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
3943 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
3974 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
4011 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
4106 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $5, $6, $7, $8
4108 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $4, $5, $6
4109 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $3
4109 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $1, $2, $4, $5, $6, $7
4110 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for part: $1, $2, $3, $5, $6, $7, $8
4110 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $3, $4, $7, $8, $9, $10, $11, $12, $13, $14, $15
4111 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for region: $2
4162 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 0: java.lang.IllegalArgumentException: Wrong FS: alluxio://neu-5-1:19998/tmp/temp1112796655, expected: hdfs://neu-5-1:9000
4182 [main] INFO  org.apache.pig.Main  - Pig script completed in 4 seconds and 337 milliseconds (4337 ms)
53   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
54   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
849  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
970  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1574 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q8.pig-7c106c66-dd8c-47f8-8a90-3f056905b8d6
1574 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
4007 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 2 time(s).
4038 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
4072 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
4101 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
4138 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
4229 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $5, $6, $7, $8
4231 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $4, $5, $6
4232 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $3
4232 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $1, $2, $4, $5, $6, $7
4233 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for part: $1, $2, $3, $5, $6, $7, $8
4234 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $3, $4, $7, $8, $9, $10, $11, $12, $13, $14, $15
4234 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for region: $2
4346 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
4360 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 0
4363 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 100
4365 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - Insert a file-concatenation job
4369 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 0
4369 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 0
4387 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
4434 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-288
4438 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
4439 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
4439 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
4439 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
4448 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 12
4448 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 map-only splittees.
4448 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 out of total 3 MR operators.
4448 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 11
4720 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
4725 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
4729 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
5007 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1761456997/tmp-411095873/pig-0.17.0-core-h2.jar
5023 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1761456997/tmp1229755966/automaton-1.11-8.jar
5040 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1761456997/tmp1183356811/antlr-runtime-3.4.jar
5058 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1761456997/tmp-1620790637/joda-time-2.9.4.jar
5070 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
5077 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
5077 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
5077 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
5121 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
5122 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
5123 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
5123 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 100
5123 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
5156 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1761456997/tmp-1025311986/pig-0.17.0-core-h2.jar
5171 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1761456997/tmp719212233/automaton-1.11-8.jar
5185 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1761456997/tmp545005413/antlr-runtime-3.4.jar
5201 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1761456997/tmp2127889787/joda-time-2.9.4.jar
5203 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
5204 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
5205 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
5205 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
5258 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
5258 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
5259 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
5291 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1761456997/tmp2125278673/pig-0.17.0-core-h2.jar
5304 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1761456997/tmp-1565818993/automaton-1.11-8.jar
5317 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1761456997/tmp-546897950/antlr-runtime-3.4.jar
5331 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1761456997/tmp500934752/joda-time-2.9.4.jar
5333 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up multi store job
5334 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
5334 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
5335 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
5348 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 3 map-reduce job(s) waiting for submission.
5434 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
5490 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 1
5503 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
5885 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_0023
5885 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fregion,region
5885 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: region[14,9],region[-1,-1],fregion[17,10],fregion[-1,-1] C:  R: 
5907 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
6174 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 512
6211 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 2
6213 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
6388 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 512
6404 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 49
6511 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_0024
6511 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fpart,lineitem,p1,part
6511 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: lineitem[8,11],lineitem[-1,-1],p1[33,5],part[16,7],part[-1,-1],fpart[19,8],fpart[-1,-1],p1[33,5] C:  R: p1[-1,-1]
6532 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
6534 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 1
6535 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
6603 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_0025
6603 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases nation
6603 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: nation[12,9],nation[-1,-1],nation[-1,-1] C:  R: 
6615 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
6615 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0023,job_1546715600715_0024,job_1546715600715_0025]
20784 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 4% complete
20784 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0023,job_1546715600715_0024,job_1546715600715_0025]
21785 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 13% complete
21785 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0024,job_1546715600715_0025]
26949 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 18% complete
26949 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0024]
51   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
51   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
810  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
924  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1488 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q8.pig-dbecf450-c28b-4393-ab72-3c4743e3fc3a
1488 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
3928 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 2 time(s).
3961 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
3995 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
4026 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
4064 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
4161 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $5, $6, $7, $8
4163 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $4, $5, $6
4164 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $3
4164 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $1, $2, $4, $5, $6, $7
4165 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for part: $1, $2, $3, $5, $6, $7, $8
4166 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $3, $4, $7, $8, $9, $10, $11, $12, $13, $14, $15
4166 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for region: $2
4224 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 0: java.lang.IllegalArgumentException: Wrong FS: alluxio://neu-5-1:19998/tmp/temp1690545275, expected: hdfs://neu-5-1:9000
4244 [main] INFO  org.apache.pig.Main  - Pig script completed in 4 seconds and 392 milliseconds (4392 ms)
49   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
49   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
816  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
931  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1550 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q8.pig-ba40fad7-4aa1-4c6f-bccd-81cd4346bee1
1550 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
4003 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 2 time(s).
4042 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
4076 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
4106 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
4142 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
4235 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $5, $6, $7, $8
4237 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $4, $5, $6
4237 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $3
4238 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $1, $2, $4, $5, $6, $7
4238 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for part: $1, $2, $3, $5, $6, $7, $8
4239 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $3, $4, $7, $8, $9, $10, $11, $12, $13, $14, $15
4239 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for region: $2
4349 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
4364 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 0
4367 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 100
4368 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - Insert a file-concatenation job
4373 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 0
4373 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 0
4403 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
4430 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-288
4435 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
4436 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
4436 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
4436 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
4445 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 12
4446 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 map-only splittees.
4446 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 out of total 3 MR operators.
4446 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 11
4703 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
4708 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
4712 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4962 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-333083482/tmp1001078282/pig-0.17.0-core-h2.jar
4978 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-333083482/tmp328564542/automaton-1.11-8.jar
4992 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-333083482/tmp1761702271/antlr-runtime-3.4.jar
5009 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-333083482/tmp1334448589/joda-time-2.9.4.jar
5021 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
5028 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
5028 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
5028 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
5072 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
5073 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
5074 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
5074 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 100
5074 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
5113 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-333083482/tmp-436767022/pig-0.17.0-core-h2.jar
5127 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-333083482/tmp1403906068/automaton-1.11-8.jar
5140 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-333083482/tmp1389674290/antlr-runtime-3.4.jar
5154 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-333083482/tmp1007799330/joda-time-2.9.4.jar
5156 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
5157 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
5157 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
5157 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
5213 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
5214 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
5215 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
5245 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-333083482/tmp-1164117862/pig-0.17.0-core-h2.jar
5258 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-333083482/tmp986632223/automaton-1.11-8.jar
5270 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-333083482/tmp-2004463875/antlr-runtime-3.4.jar
5285 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-333083482/tmp138690439/joda-time-2.9.4.jar
5286 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up multi store job
5287 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
5288 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
5288 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
5306 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 3 map-reduce job(s) waiting for submission.
5398 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
5454 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 1
5466 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
5860 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_0026
5860 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fregion,region
5860 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: region[14,9],region[-1,-1],fregion[17,10],fregion[-1,-1] C:  R: 
5882 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
6154 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 512
6201 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 2
6204 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
6375 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 512
6393 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 49
6504 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_0027
6504 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fpart,lineitem,p1,part
6505 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: lineitem[8,11],lineitem[-1,-1],p1[33,5],part[16,7],part[-1,-1],fpart[19,8],fpart[-1,-1],p1[33,5] C:  R: p1[-1,-1]
6528 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
6531 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths to process : 1
6531 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil  - Total input paths (combined) to process : 1
6620 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_0028
6620 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases nation
6620 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: nation[12,9],nation[-1,-1],nation[-1,-1] C:  R: 
6633 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
6634 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Running jobs are [job_1546715600715_0026,job_1546715600715_0027,job_1546715600715_0028]
51   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
52   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
815  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
929  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1571 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q8.pig-71506fa9-f2a2-4f22-a2a8-e74356341302
1571 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
4019 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 2 time(s).
4050 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
4084 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
4114 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
4150 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
4239 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $5, $6, $7, $8
4242 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $4, $5, $6
4242 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $3
4243 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $1, $2, $4, $5, $6, $7
4243 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for part: $1, $2, $3, $5, $6, $7, $8
4244 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $3, $4, $7, $8, $9, $10, $11, $12, $13, $14, $15
4244 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for region: $2
4295 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 0: java.lang.IllegalArgumentException: Wrong FS: alluxio://neu-5-1:19998/tmp/temp-169049830, expected: hdfs://neu-5-1:9000
4314 [main] INFO  org.apache.pig.Main  - Pig script completed in 4 seconds and 478 milliseconds (4478 ms)
50   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
50   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
807  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
921  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1493 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q8.pig-a6aa7719-e287-423d-af73-ac25dc5ba69c
1493 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
1512 [main] DEBUG org.apache.pig.PigServer  - Create a new graph.
1741 [main] DEBUG org.apache.pig.parser.QueryParserDriver  - Original macro AST:
(QUERY (STATEMENT customer (load 'alluxio://neu-5-1:19998/tpch/in/customer' (FUNC PigStorage '|') (as (FIELD_DEF c_custkey long) (FIELD_DEF c_name chararray) (FIELD_DEF c_address chararray) (FIELD_DEF c_nationkey int) (FIELD_DEF c_phone chararray) (FIELD_DEF c_acctbal double) (FIELD_DEF c_mktsegment chararray) (FIELD_DEF c_comment chararray)))) (STATEMENT orders (load 'alluxio://neu-5-1:19998/tpch/in/orders' (FUNC PigStorage '|') (as (FIELD_DEF o_orderkey long) (FIELD_DEF o_custkey long) (FIELD_DEF o_orderstatus chararray) (FIELD_DEF o_totalprice double) (FIELD_DEF o_orderdate chararray) (FIELD_DEF o_orderpriority chararray) (FIELD_DEF o_clerk chararray) (FIELD_DEF o_shippriority long) (FIELD_DEF o_comment chararray)))) (STATEMENT lineitem (load 'alluxio://neu-5-1:19998/tpch/in/lineitem' (FUNC PigStorage '|') (as (FIELD_DEF l_orderkey long) (FIELD_DEF l_partkey long) (FIELD_DEF l_suppkey long) (FIELD_DEF l_linenumber long) (FIELD_DEF l_quantity double) (FIELD_DEF l_extendedprice double) (FIELD_DEF l_discount double) (FIELD_DEF l_tax double) (FIELD_DEF l_returnflag chararray) (FIELD_DEF l_linestatus chararray) (FIELD_DEF l_shipdate chararray) (FIELD_DEF l_commitdate chararray) (FIELD_DEF l_receiptdate chararray) (FIELD_DEF l_shippingstruct chararray) (FIELD_DEF l_shipmode chararray) (FIELD_DEF l_comment chararray)))) (STATEMENT supplier (load 'alluxio://neu-5-1:19998/tpch/in/supplier' (FUNC PigStorage '|') (as (FIELD_DEF s_suppkey long) (FIELD_DEF s_name chararray) (FIELD_DEF s_address chararray) (FIELD_DEF s_nationkey int) (FIELD_DEF s_phone chararray) (FIELD_DEF s_acctbal double) (FIELD_DEF s_comment chararray)))) (STATEMENT nation (load 'alluxio://neu-5-1:19998/tpch/in/nation' (FUNC PigStorage '|') (as (FIELD_DEF n_nationkey int) (FIELD_DEF n_name chararray) (FIELD_DEF n_regionkey int) (FIELD_DEF n_comment chararray)))) (STATEMENT region (load 'alluxio://neu-5-1:19998/tpch/in/region' (FUNC PigStorage '|') (as (FIELD_DEF r_regionkey int) (FIELD_DEF r_name chararray) (FIELD_DEF r_comment chararray)))) (STATEMENT part (load 'alluxio://neu-5-1:19998/tpch/in/part' (FUNC PigStorage '|') (as (FIELD_DEF p_partkey long) (FIELD_DEF p_name chararray) (FIELD_DEF p_mfgr chararray) (FIELD_DEF p_brand chararray) (FIELD_DEF p_type chararray) (FIELD_DEF p_size long) (FIELD_DEF p_container chararray) (FIELD_DEF p_retailprice double) (FIELD_DEF p_comment chararray)))) (STATEMENT fregion (filter region (== r_name 'AMERICA'))) (STATEMENT forders (filter orders (and (<= o_orderdate '1996-12-31') (>= o_orderdate '1995-01-01')))) (STATEMENT fpart (filter part (== p_type 'ECONOMY ANODIZED STEEL'))) (STATEMENT n1 (join (JOIN_ITEM nation (by n_regionkey)) (JOIN_ITEM fregion (by r_regionkey)) 'replicated')) (STATEMENT seln1 (foreach n1 (FOREACH_PLAN_SIMPLE (generate n_nationkey)))) (STATEMENT c1 (join (JOIN_ITEM customer (by c_nationkey)) (JOIN_ITEM seln1 (by n_nationkey)) 'replicated')) (STATEMENT selc1 (foreach c1 (FOREACH_PLAN_SIMPLE (generate c_custkey)))) (STATEMENT o1 (join (JOIN_ITEM forders (by o_custkey)) (JOIN_ITEM selc1 (by c_custkey)))) (STATEMENT selo1 (foreach o1 (FOREACH_PLAN_SIMPLE (generate o_orderkey o_orderdate)))) (STATEMENT n2 (join (JOIN_ITEM supplier (by s_nationkey)) (JOIN_ITEM nation (by n_nationkey)) 'replicated')) (STATEMENT lineitem (foreach lineitem (FOREACH_PLAN_SIMPLE (generate l_partkey l_suppkey l_orderkey (* l_extendedprice (EXPR_IN_PAREN (- 1 l_discount))) (FIELD_DEF volume))))) (STATEMENT p1 (join (JOIN_ITEM fpart (by p_partkey)) (JOIN_ITEM lineitem (by l_partkey)))) (STATEMENT s1 (join (JOIN_ITEM n2 (by s_suppkey)) (JOIN_ITEM p1 (by l_suppkey)))) (STATEMENT l1 (join (JOIN_ITEM o1 (by o_orderkey)) (JOIN_ITEM s1 (by l_orderkey)))) (STATEMENT sels1 (foreach l1 (FOREACH_PLAN_SIMPLE (generate (FUNC_EVAL SUBSTRING o_orderdate 0 4) (FIELD_DEF o_year) volume (BIN_EXPR (== n_name 'BRAZIL') volume 0) (FIELD_DEF case_volume))))) (STATEMENT grResult (GROUP sels1 (by o_year))) (STATEMENT sumResult (foreach grResult (FOREACH_PLAN_SIMPLE (generate group (/ (FUNC_EVAL SUM $1 (. case_volume)) (FUNC_EVAL SUM $1 (. volume))))))) (STATEMENT sortResult (order sumResult group)) (STATEMENT (store sortResult 'alluxio://neu-5-1:19998/tpch/out5/Q8out' (FUNC PigStorage '|'))))

1743 [main] DEBUG org.apache.pig.parser.QueryParserDriver  - macro AST after import:
(QUERY (STATEMENT customer (load 'alluxio://neu-5-1:19998/tpch/in/customer' (FUNC PigStorage '|') (as (FIELD_DEF c_custkey long) (FIELD_DEF c_name chararray) (FIELD_DEF c_address chararray) (FIELD_DEF c_nationkey int) (FIELD_DEF c_phone chararray) (FIELD_DEF c_acctbal double) (FIELD_DEF c_mktsegment chararray) (FIELD_DEF c_comment chararray)))) (STATEMENT orders (load 'alluxio://neu-5-1:19998/tpch/in/orders' (FUNC PigStorage '|') (as (FIELD_DEF o_orderkey long) (FIELD_DEF o_custkey long) (FIELD_DEF o_orderstatus chararray) (FIELD_DEF o_totalprice double) (FIELD_DEF o_orderdate chararray) (FIELD_DEF o_orderpriority chararray) (FIELD_DEF o_clerk chararray) (FIELD_DEF o_shippriority long) (FIELD_DEF o_comment chararray)))) (STATEMENT lineitem (load 'alluxio://neu-5-1:19998/tpch/in/lineitem' (FUNC PigStorage '|') (as (FIELD_DEF l_orderkey long) (FIELD_DEF l_partkey long) (FIELD_DEF l_suppkey long) (FIELD_DEF l_linenumber long) (FIELD_DEF l_quantity double) (FIELD_DEF l_extendedprice double) (FIELD_DEF l_discount double) (FIELD_DEF l_tax double) (FIELD_DEF l_returnflag chararray) (FIELD_DEF l_linestatus chararray) (FIELD_DEF l_shipdate chararray) (FIELD_DEF l_commitdate chararray) (FIELD_DEF l_receiptdate chararray) (FIELD_DEF l_shippingstruct chararray) (FIELD_DEF l_shipmode chararray) (FIELD_DEF l_comment chararray)))) (STATEMENT supplier (load 'alluxio://neu-5-1:19998/tpch/in/supplier' (FUNC PigStorage '|') (as (FIELD_DEF s_suppkey long) (FIELD_DEF s_name chararray) (FIELD_DEF s_address chararray) (FIELD_DEF s_nationkey int) (FIELD_DEF s_phone chararray) (FIELD_DEF s_acctbal double) (FIELD_DEF s_comment chararray)))) (STATEMENT nation (load 'alluxio://neu-5-1:19998/tpch/in/nation' (FUNC PigStorage '|') (as (FIELD_DEF n_nationkey int) (FIELD_DEF n_name chararray) (FIELD_DEF n_regionkey int) (FIELD_DEF n_comment chararray)))) (STATEMENT region (load 'alluxio://neu-5-1:19998/tpch/in/region' (FUNC PigStorage '|') (as (FIELD_DEF r_regionkey int) (FIELD_DEF r_name chararray) (FIELD_DEF r_comment chararray)))) (STATEMENT part (load 'alluxio://neu-5-1:19998/tpch/in/part' (FUNC PigStorage '|') (as (FIELD_DEF p_partkey long) (FIELD_DEF p_name chararray) (FIELD_DEF p_mfgr chararray) (FIELD_DEF p_brand chararray) (FIELD_DEF p_type chararray) (FIELD_DEF p_size long) (FIELD_DEF p_container chararray) (FIELD_DEF p_retailprice double) (FIELD_DEF p_comment chararray)))) (STATEMENT fregion (filter region (== r_name 'AMERICA'))) (STATEMENT forders (filter orders (and (<= o_orderdate '1996-12-31') (>= o_orderdate '1995-01-01')))) (STATEMENT fpart (filter part (== p_type 'ECONOMY ANODIZED STEEL'))) (STATEMENT n1 (join (JOIN_ITEM nation (by n_regionkey)) (JOIN_ITEM fregion (by r_regionkey)) 'replicated')) (STATEMENT seln1 (foreach n1 (FOREACH_PLAN_SIMPLE (generate n_nationkey)))) (STATEMENT c1 (join (JOIN_ITEM customer (by c_nationkey)) (JOIN_ITEM seln1 (by n_nationkey)) 'replicated')) (STATEMENT selc1 (foreach c1 (FOREACH_PLAN_SIMPLE (generate c_custkey)))) (STATEMENT o1 (join (JOIN_ITEM forders (by o_custkey)) (JOIN_ITEM selc1 (by c_custkey)))) (STATEMENT selo1 (foreach o1 (FOREACH_PLAN_SIMPLE (generate o_orderkey o_orderdate)))) (STATEMENT n2 (join (JOIN_ITEM supplier (by s_nationkey)) (JOIN_ITEM nation (by n_nationkey)) 'replicated')) (STATEMENT lineitem (foreach lineitem (FOREACH_PLAN_SIMPLE (generate l_partkey l_suppkey l_orderkey (* l_extendedprice (EXPR_IN_PAREN (- 1 l_discount))) (FIELD_DEF volume))))) (STATEMENT p1 (join (JOIN_ITEM fpart (by p_partkey)) (JOIN_ITEM lineitem (by l_partkey)))) (STATEMENT s1 (join (JOIN_ITEM n2 (by s_suppkey)) (JOIN_ITEM p1 (by l_suppkey)))) (STATEMENT l1 (join (JOIN_ITEM o1 (by o_orderkey)) (JOIN_ITEM s1 (by l_orderkey)))) (STATEMENT sels1 (foreach l1 (FOREACH_PLAN_SIMPLE (generate (FUNC_EVAL SUBSTRING o_orderdate 0 4) (FIELD_DEF o_year) volume (BIN_EXPR (== n_name 'BRAZIL') volume 0) (FIELD_DEF case_volume))))) (STATEMENT grResult (GROUP sels1 (by o_year))) (STATEMENT sumResult (foreach grResult (FOREACH_PLAN_SIMPLE (generate group (/ (FUNC_EVAL SUM $1 (. case_volume)) (FUNC_EVAL SUM $1 (. volume))))))) (STATEMENT sortResult (order sumResult group)) (STATEMENT (store sortResult 'alluxio://neu-5-1:19998/tpch/out5/Q8out' (FUNC PigStorage '|'))))

1744 [main] DEBUG org.apache.pig.parser.QueryParserDriver  - Resulting macro AST:
(QUERY (STATEMENT customer (load 'alluxio://neu-5-1:19998/tpch/in/customer' (FUNC PigStorage '|') (as (FIELD_DEF c_custkey long) (FIELD_DEF c_name chararray) (FIELD_DEF c_address chararray) (FIELD_DEF c_nationkey int) (FIELD_DEF c_phone chararray) (FIELD_DEF c_acctbal double) (FIELD_DEF c_mktsegment chararray) (FIELD_DEF c_comment chararray)))) (STATEMENT orders (load 'alluxio://neu-5-1:19998/tpch/in/orders' (FUNC PigStorage '|') (as (FIELD_DEF o_orderkey long) (FIELD_DEF o_custkey long) (FIELD_DEF o_orderstatus chararray) (FIELD_DEF o_totalprice double) (FIELD_DEF o_orderdate chararray) (FIELD_DEF o_orderpriority chararray) (FIELD_DEF o_clerk chararray) (FIELD_DEF o_shippriority long) (FIELD_DEF o_comment chararray)))) (STATEMENT lineitem (load 'alluxio://neu-5-1:19998/tpch/in/lineitem' (FUNC PigStorage '|') (as (FIELD_DEF l_orderkey long) (FIELD_DEF l_partkey long) (FIELD_DEF l_suppkey long) (FIELD_DEF l_linenumber long) (FIELD_DEF l_quantity double) (FIELD_DEF l_extendedprice double) (FIELD_DEF l_discount double) (FIELD_DEF l_tax double) (FIELD_DEF l_returnflag chararray) (FIELD_DEF l_linestatus chararray) (FIELD_DEF l_shipdate chararray) (FIELD_DEF l_commitdate chararray) (FIELD_DEF l_receiptdate chararray) (FIELD_DEF l_shippingstruct chararray) (FIELD_DEF l_shipmode chararray) (FIELD_DEF l_comment chararray)))) (STATEMENT supplier (load 'alluxio://neu-5-1:19998/tpch/in/supplier' (FUNC PigStorage '|') (as (FIELD_DEF s_suppkey long) (FIELD_DEF s_name chararray) (FIELD_DEF s_address chararray) (FIELD_DEF s_nationkey int) (FIELD_DEF s_phone chararray) (FIELD_DEF s_acctbal double) (FIELD_DEF s_comment chararray)))) (STATEMENT nation (load 'alluxio://neu-5-1:19998/tpch/in/nation' (FUNC PigStorage '|') (as (FIELD_DEF n_nationkey int) (FIELD_DEF n_name chararray) (FIELD_DEF n_regionkey int) (FIELD_DEF n_comment chararray)))) (STATEMENT region (load 'alluxio://neu-5-1:19998/tpch/in/region' (FUNC PigStorage '|') (as (FIELD_DEF r_regionkey int) (FIELD_DEF r_name chararray) (FIELD_DEF r_comment chararray)))) (STATEMENT part (load 'alluxio://neu-5-1:19998/tpch/in/part' (FUNC PigStorage '|') (as (FIELD_DEF p_partkey long) (FIELD_DEF p_name chararray) (FIELD_DEF p_mfgr chararray) (FIELD_DEF p_brand chararray) (FIELD_DEF p_type chararray) (FIELD_DEF p_size long) (FIELD_DEF p_container chararray) (FIELD_DEF p_retailprice double) (FIELD_DEF p_comment chararray)))) (STATEMENT fregion (filter region (== r_name 'AMERICA'))) (STATEMENT forders (filter orders (and (<= o_orderdate '1996-12-31') (>= o_orderdate '1995-01-01')))) (STATEMENT fpart (filter part (== p_type 'ECONOMY ANODIZED STEEL'))) (STATEMENT n1 (join (JOIN_ITEM nation (by n_regionkey)) (JOIN_ITEM fregion (by r_regionkey)) 'replicated')) (STATEMENT seln1 (foreach n1 (FOREACH_PLAN_SIMPLE (generate n_nationkey)))) (STATEMENT c1 (join (JOIN_ITEM customer (by c_nationkey)) (JOIN_ITEM seln1 (by n_nationkey)) 'replicated')) (STATEMENT selc1 (foreach c1 (FOREACH_PLAN_SIMPLE (generate c_custkey)))) (STATEMENT o1 (join (JOIN_ITEM forders (by o_custkey)) (JOIN_ITEM selc1 (by c_custkey)))) (STATEMENT selo1 (foreach o1 (FOREACH_PLAN_SIMPLE (generate o_orderkey o_orderdate)))) (STATEMENT n2 (join (JOIN_ITEM supplier (by s_nationkey)) (JOIN_ITEM nation (by n_nationkey)) 'replicated')) (STATEMENT lineitem (foreach lineitem (FOREACH_PLAN_SIMPLE (generate l_partkey l_suppkey l_orderkey (* l_extendedprice (EXPR_IN_PAREN (- 1 l_discount))) (FIELD_DEF volume))))) (STATEMENT p1 (join (JOIN_ITEM fpart (by p_partkey)) (JOIN_ITEM lineitem (by l_partkey)))) (STATEMENT s1 (join (JOIN_ITEM n2 (by s_suppkey)) (JOIN_ITEM p1 (by l_suppkey)))) (STATEMENT l1 (join (JOIN_ITEM o1 (by o_orderkey)) (JOIN_ITEM s1 (by l_orderkey)))) (STATEMENT sels1 (foreach l1 (FOREACH_PLAN_SIMPLE (generate (FUNC_EVAL SUBSTRING o_orderdate 0 4) (FIELD_DEF o_year) volume (BIN_EXPR (== n_name 'BRAZIL') volume 0) (FIELD_DEF case_volume))))) (STATEMENT grResult (GROUP sels1 (by o_year))) (STATEMENT sumResult (foreach grResult (FOREACH_PLAN_SIMPLE (generate group (/ (FUNC_EVAL SUM $1 (. case_volume)) (FUNC_EVAL SUM $1 (. volume))))))) (STATEMENT sortResult (order sumResult group)) (STATEMENT (store sortResult 'alluxio://neu-5-1:19998/tpch/out5/Q8out' (FUNC PigStorage '|'))))

2167 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 15 Bag: 120 tuple: 110
2168 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
2168 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
2168 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
2168 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
2169 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
2169 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
2169 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3485 [main] DEBUG org.apache.pig.builtin.JsonMetadata  - Could not find schema file for alluxio://neu-5-1:19998/tpch/in/customer
3533 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 15 Bag: 120 tuple: 110
3534 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 15 Bag: 120 tuple: 110
3534 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3534 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3534 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3534 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3534 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3534 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 15 Bag: 120 tuple: 110
3534 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3545 [main] DEBUG org.apache.pig.builtin.JsonMetadata  - Could not find schema file for alluxio://neu-5-1:19998/tpch/in/orders
3577 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 15 Bag: 120 tuple: 110
3577 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 15 Bag: 120 tuple: 110
3577 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 15 Bag: 120 tuple: 110
3577 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 15 Bag: 120 tuple: 110
3577 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3577 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3577 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3577 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3577 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3577 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3578 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3578 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3578 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3578 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3578 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3578 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3586 [main] DEBUG org.apache.pig.builtin.JsonMetadata  - Could not find schema file for alluxio://neu-5-1:19998/tpch/in/lineitem
3614 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 15 Bag: 120 tuple: 110
3614 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3614 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3614 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
3614 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3615 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3615 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3622 [main] DEBUG org.apache.pig.builtin.JsonMetadata  - Could not find schema file for alluxio://neu-5-1:19998/tpch/in/supplier
3649 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
3649 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3649 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
3649 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3657 [main] DEBUG org.apache.pig.builtin.JsonMetadata  - Could not find schema file for alluxio://neu-5-1:19998/tpch/in/nation
3684 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
3684 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3684 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3691 [main] DEBUG org.apache.pig.builtin.JsonMetadata  - Could not find schema file for alluxio://neu-5-1:19998/tpch/in/region
3717 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 15 Bag: 120 tuple: 110
3717 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3717 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3717 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3717 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3717 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 15 Bag: 120 tuple: 110
3717 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3718 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3718 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3725 [main] DEBUG org.apache.pig.builtin.JsonMetadata  - Could not find schema file for alluxio://neu-5-1:19998/tpch/in/part
3775 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3775 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
3775 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
3781 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3781 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
3782 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
3784 [main] DEBUG org.apache.pig.data.SchemaTupleFrontend  - Registering Schema for generation [{chararray,int,int}] with id [0] and context: UDF
3784 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3784 [main] DEBUG org.apache.pig.data.SchemaTupleFrontend  - Registering Schema for generation [{chararray}] with id [1] and context: UDF
3799 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3799 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3799 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3799 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3799 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3800 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3800 [main] DEBUG org.apache.pig.data.SchemaTupleFrontend  - Registering Schema for generation [{{(double)}}] with id [2] and context: UDF
3800 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3800 [main] DEBUG org.apache.pig.data.SchemaTupleFrontend  - Registering Schema for generation [{double}] with id [3] and context: UDF
3800 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3800 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3801 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3801 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3801 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3801 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3801 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3847 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3847 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
3847 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
3847 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3847 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
3847 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
3848 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3848 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3848 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3848 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3848 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3849 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3849 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3849 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3849 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3849 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3849 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3849 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3850 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3850 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3850 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3862 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3863 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
3863 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
3863 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3863 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
3863 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
3864 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3864 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
3864 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
3864 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3864 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
3864 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
3865 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3865 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
3865 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
3865 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3865 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3865 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3865 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3866 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3867 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3867 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3868 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3868 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3869 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3870 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3870 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 50 Bag: 120 tuple: 110
3870 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3870 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3870 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3870 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3870 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3870 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 20 Bag: 120 tuple: 110
3870 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3871 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3871 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
3871 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3871 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3871 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 15 Bag: 120 tuple: 110
3871 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3871 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3871 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 70 Bag: 120 tuple: 110
3871 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3871 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3871 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 65 Bag: 120 tuple: 110
3871 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3871 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3872 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 50 Bag: 120 tuple: 110
3872 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3872 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3872 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3872 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3872 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3872 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 20 Bag: 120 tuple: 110
3872 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3872 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3872 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
3872 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3872 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3873 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 15 Bag: 120 tuple: 110
3873 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3873 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3873 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 70 Bag: 120 tuple: 110
3873 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3873 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3873 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 65 Bag: 120 tuple: 110
3873 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3873 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3877 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3877 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3877 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3877 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3877 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3877 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3878 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3878 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3878 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3878 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3878 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 50 Bag: 120 tuple: 110
3878 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3878 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3878 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3878 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3878 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3878 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 20 Bag: 120 tuple: 110
3878 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3878 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3878 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
3878 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3879 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3879 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 15 Bag: 120 tuple: 110
3879 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3879 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3879 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 70 Bag: 120 tuple: 110
3879 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3879 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3879 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 65 Bag: 120 tuple: 110
3879 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3879 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3879 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 50 Bag: 120 tuple: 110
3879 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3879 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3879 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3879 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3879 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3880 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 20 Bag: 120 tuple: 110
3880 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3880 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3880 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
3880 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3880 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3880 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 15 Bag: 120 tuple: 110
3880 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3880 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3880 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 70 Bag: 120 tuple: 110
3880 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3880 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3880 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 65 Bag: 120 tuple: 110
3881 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3881 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3881 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3881 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3881 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3881 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3881 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3881 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3882 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3882 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3882 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3882 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3882 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3882 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3882 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3882 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3895 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 2 time(s).
3907 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3907 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
3907 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
3908 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3908 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
3908 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
3908 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
3908 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3908 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3908 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3909 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3909 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3909 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3909 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3909 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3909 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3909 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3910 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3910 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
3910 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
3910 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
3934 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
3968 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
3999 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
4035 [main] DEBUG org.apache.pig.impl.util.SpillableMemoryManager  - Found heap (Code Cache) of type Non-heap memory
4035 [main] DEBUG org.apache.pig.impl.util.SpillableMemoryManager  - Found heap (Metaspace) of type Non-heap memory
4035 [main] DEBUG org.apache.pig.impl.util.SpillableMemoryManager  - Found heap (Compressed Class Space) of type Non-heap memory
4035 [main] DEBUG org.apache.pig.impl.util.SpillableMemoryManager  - Found heap (PS Eden Space) of type Heap memory
4036 [main] DEBUG org.apache.pig.impl.util.SpillableMemoryManager  - Found heap (PS Survivor Space) of type Heap memory
4036 [main] DEBUG org.apache.pig.impl.util.SpillableMemoryManager  - Found heap (PS Old Gen) of type Heap memory
4036 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
4090 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4090 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4090 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4090 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4090 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4090 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4090 [main] DEBUG org.apache.pig.data.SchemaTupleFrontend  - Registering Schema for generation [{chararray,int,int}] with id [0] and context: UDF
4091 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4091 [main] DEBUG org.apache.pig.data.SchemaTupleFrontend  - Registering Schema for generation [{chararray}] with id [1] and context: UDF
4091 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4091 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4091 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4091 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4091 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4091 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4091 [main] DEBUG org.apache.pig.data.SchemaTupleFrontend  - Registering Schema for generation [{{(double)}}] with id [2] and context: UDF
4091 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4092 [main] DEBUG org.apache.pig.data.SchemaTupleFrontend  - Registering Schema for generation [{double}] with id [3] and context: UDF
4092 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4092 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4092 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4092 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4092 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4092 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4092 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4096 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4096 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4096 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4096 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4096 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4096 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4096 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4097 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4097 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4097 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4097 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4097 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4097 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4097 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4097 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4097 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4097 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4097 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4098 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4098 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4098 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4099 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4099 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4100 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4100 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4100 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4100 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4100 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4100 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4100 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4100 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4100 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4100 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4100 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4100 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4100 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4100 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4100 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4101 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4101 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4101 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4101 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4102 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4102 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4102 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4102 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4103 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4103 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4103 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4103 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4103 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4103 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4103 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4103 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4103 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4103 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4103 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4103 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4103 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4104 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4104 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4104 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4104 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4106 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4106 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4106 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4106 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4106 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4106 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4106 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4106 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4106 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4106 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4107 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4107 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4108 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4108 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4108 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4108 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4108 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4108 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4108 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4108 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4108 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4110 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4110 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4110 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4110 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4110 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4110 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4111 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4111 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4111 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4111 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4111 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4111 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4111 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4111 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4111 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4111 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4111 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4111 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4111 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4111 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4112 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4113 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4113 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4113 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4113 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4113 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4113 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4113 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4114 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4114 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4114 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4114 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4114 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4114 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4114 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4114 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4114 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4114 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4114 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4114 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4114 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4114 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4132 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $5, $6, $7, $8
4134 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $4, $5, $6
4135 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $3
4135 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $1, $2, $4, $5, $6, $7
4135 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for part: $1, $2, $3, $5, $6, $7, $8
4136 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $3, $4, $7, $8, $9, $10, $11, $12, $13, $14, $15
4136 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for region: $2
4137 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4137 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4137 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4137 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4137 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4137 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4137 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4137 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4138 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4138 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4138 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4138 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4138 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4138 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4138 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4138 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4138 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4138 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4138 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4138 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4138 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4140 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4140 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4140 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4140 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4140 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4140 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4140 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4140 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4141 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4141 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4141 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4141 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4141 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4141 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4141 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4141 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4141 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4141 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4141 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4141 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4141 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4143 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4143 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4143 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4143 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4143 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4143 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4143 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4143 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4143 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4143 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4143 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4143 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4143 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4143 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4143 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4144 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4144 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4144 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4144 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4144 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4144 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4145 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4145 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4145 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4145 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4145 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4145 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4145 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4145 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4145 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4145 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4146 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4146 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4146 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4146 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4146 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4146 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4146 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4146 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4146 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4146 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4146 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4147 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4147 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4147 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4147 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4147 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4147 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4147 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4148 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4148 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4148 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4148 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4148 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4148 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4148 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4148 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4148 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4148 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4148 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4148 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4148 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4148 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4149 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4150 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4150 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4150 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4150 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4150 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4150 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4150 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4150 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4150 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4150 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4150 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4150 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4150 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4150 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4150 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4150 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4151 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4151 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4151 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4151 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4152 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4152 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4152 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4152 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4152 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4152 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4152 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4152 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4152 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4152 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4152 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4152 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4152 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4152 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4152 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4152 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4152 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4153 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4153 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 110 Bag: 120 tuple: 110
4153 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 120 Bag: 120 tuple: 110
4153 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 25 Bag: 120 tuple: 110
4182 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 15 Bag: 120 tuple: 110
4182 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 15 Bag: 120 tuple: 110
4182 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4182 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 15 Bag: 120 tuple: 110
4182 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 15 Bag: 120 tuple: 110
4182 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4182 [main] DEBUG org.apache.pig.data.SchemaTupleFrontend  - Registering Schema for generation [{long,long,chararray}] with id [4] and context: FOREACH
4188 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 15 Bag: 120 tuple: 110
4188 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4188 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 15 Bag: 120 tuple: 110
4188 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4188 [main] DEBUG org.apache.pig.data.SchemaTupleFrontend  - Registering Schema for generation [{long,int}] with id [5] and context: FOREACH
4189 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4189 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4189 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4189 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4189 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 55 Bag: 120 tuple: 110
4189 [main] DEBUG org.apache.pig.impl.logicalLayer.schema.Schema$FieldSchema  - t: 10 Bag: 120 tuple: 110
4189 [main] DEBUG org.apache.pig.data.SchemaTupleFrontend  - Registering Schema for generation [{int,chararray,int}] with id [6] and context: FOREACH
4193 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 0: java.lang.IllegalArgumentException: Wrong FS: alluxio://neu-5-1:19998/tmp/temp-143354088, expected: hdfs://neu-5-1:9000
4212 [main] INFO  org.apache.pig.Main  - Pig script completed in 4 seconds and 365 milliseconds (4365 ms)
