Running Repeat #1 HDFS HDFS
Going to run:
/root/papers/KARIZ/expriments/benchmark/BenchmarkScripts/tpch/pig/run_tpch.sh /tpch/in /user/root/tpch/out_hdfs21 1 HDFS

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-3-2]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-7]
ok: [neu-5-3]
ok: [neu-5-10]
ok: [neu-3-11]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-3]
changed: [neu-5-10]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q1
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs21 -param reducers=1 -f queries/Q1.pig

68   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
69   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
953  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1064 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1692 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q1.pig-bcd7263b-b9af-49d2-b7b9-03df09e21932
1693 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2679 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 3 time(s).
2680 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_CHARARRAY 1 time(s).
2749 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: GROUP_BY,ORDER_BY,FILTER
2901 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2965 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
3042 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
3156 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for LineItems: $0, $1, $2, $3, $11, $12, $13, $14, $15
3243 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3297 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3333 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-109
3344 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 3
3344 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 3
4179 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
4185 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
4189 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
4189 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
4189 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4493 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1554336181/tmp1103323076/pig-0.17.0-core-h2.jar
4515 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1554336181/tmp724067028/automaton-1.11-8.jar
4531 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1554336181/tmp-873792832/antlr-runtime-3.4.jar
4548 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1554336181/tmp1019255318/joda-time-2.9.4.jar
4564 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4572 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4572 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4572 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4683 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
5029 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
5186 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2492
5186 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases LineItems,PriceSummary,StatusGroup,SubLine,SubLineItems
5187 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: LineItems[3,12],SubLineItems[4,15],LineItems[-1,-1],SubLine[6,10],PriceSummary[9,15],StatusGroup[8,14] C: PriceSummary[9,15],StatusGroup[8,14] R: PriceSummary[9,15]
5193 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
10203 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
10411 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
10411 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
10412 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:34:54	2019-01-28 11:35:00	GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2492	LineItems,PriceSummary,StatusGroup,SubLine,SubLineItems	GROUP_BY,COMBINER	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/lineitem"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2492	->	null,
null	->	null,
null


10413 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
10414 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
10441 [main] INFO  org.apache.pig.Main  - Pig script completed in 10 seconds and 675 milliseconds (10675 ms)
Q1 times (sec):	14

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-1]
ok: [neu-3-2]
ok: [neu-5-10]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-3-7]
ok: [neu-3-11]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-5-1]
changed: [neu-3-7]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q2
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs21 -param reducers=1 -f queries/Q2.pig

64   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
65   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
899  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1013 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1621 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q2.pig-b1ad995c-60af-4e6e-bc4b-94070a23353c
1621 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2645 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_LONG 1 time(s).
2693 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,FILTER,LIMIT
2742 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2785 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2840 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2998 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3067 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-217
3072 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3072 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3072 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3073 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3080 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 8
3080 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 8
3634 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3640 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3645 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3645 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3645 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3871 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1376311036/tmp-583582147/pig-0.17.0-core-h2.jar
3893 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1376311036/tmp-792257789/automaton-1.11-8.jar
3907 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1376311036/tmp1422913785/antlr-runtime-3.4.jar
3923 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1376311036/tmp461915935/joda-time-2.9.4.jar
3942 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
3950 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3950 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3950 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4044 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4242 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4547 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2493
4547 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases FR_N,FRegion,Nation,Region
4547 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: Region[11,9],Region[-1,-1],FRegion[13,10],FR_N[14,7],Nation[9,9],Nation[-1,-1],FR_N[14,7] C:  R: 
4552 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9562 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9730 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9731 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9732 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:35:24	2019-01-28 11:35:30	HASH_JOIN,GROUP_BY,ORDER_BY,FILTER,LIMIT

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2493	FR_N,FRegion,Nation,Region	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/region
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/region
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/region"
Failed to read data from "/tpch/in/nation"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2493	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null


9733 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9735 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9754 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 927 milliseconds (9927 ms)
Q2 times (sec):	11

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-5-3]
ok: [neu-3-2]
ok: [neu-5-1]
ok: [neu-5-6]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-3]
changed: [neu-5-10]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q3
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs21 -param reducers=1 -f queries/Q3.pig

61   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
62   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
895  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1007 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1598 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q3.pig-bcf2b64f-20f0-4476-8ba8-3dae934fd8ee
1598 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2543 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 1 time(s).
2583 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,FILTER,LIMIT
2634 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2670 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2724 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2792 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $1, $2, $3, $4, $7, $8, $9, $11, $12, $13, $14, $15
2796 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $5, $6, $8
2796 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $1, $2, $3, $4, $5, $7
2883 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
2925 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
2959 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-135
2963 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
2963 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
2971 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 6
2971 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 6
3558 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3563 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3568 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3568 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3568 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3787 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp851770633/tmp-863571474/pig-0.17.0-core-h2.jar
3806 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp851770633/tmp-1633831976/automaton-1.11-8.jar
3822 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp851770633/tmp-339679919/antlr-runtime-3.4.jar
3838 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp851770633/tmp-1550427029/joda-time-2.9.4.jar
3854 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
3862 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3862 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3863 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
3953 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4164 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4456 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2494
4456 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases customer,fcustomer,forders,o1,orders,selo1
4456 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: customer[4,11],customer[-1,-1],fcustomer[11,12],fcustomer[-1,-1],o1[15,5],orders[6,9],orders[-1,-1],forders[12,10],o1[15,5] C:  R: selo1[16,8]
4462 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9472 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9646 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9647 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9648 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:35:49	2019-01-28 11:35:55	HASH_JOIN,GROUP_BY,ORDER_BY,FILTER,LIMIT

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2494	customer,fcustomer,forders,o1,orders,selo1	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/orders
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/orders
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/orders"
Failed to read data from "/tpch/in/customer"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2494	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null


9649 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9650 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9669 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 842 milliseconds (9842 ms)
Q3 times (sec):	12

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-5-6]
ok: [neu-5-3]
ok: [neu-3-2]
ok: [neu-5-1]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-3]
changed: [neu-5-10]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q4
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs21 -param reducers=1 -f queries/Q4.pig

66   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
67   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
937  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1052 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1675 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q4.pig-5f709cfb-2887-43b3-b762-e7f48c984ecd
1675 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2590 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_CHARARRAY 2 time(s).
2591 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_LONG 1 time(s).
2642 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: COGROUP,GROUP_BY,ORDER_BY,FILTER
2693 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2741 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2800 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2871 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for LineItem: $1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $13, $14, $15
2955 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3002 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3030 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-82
3041 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 4
3041 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 4
3630 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3635 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3640 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3640 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3641 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3838 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1530120196/tmp-2109768168/pig-0.17.0-core-h2.jar
3879 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1530120196/tmp-581624837/automaton-1.11-8.jar
3895 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1530120196/tmp-117699005/antlr-runtime-3.4.jar
3910 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1530120196/tmp1210378664/joda-time-2.9.4.jar
3926 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
3934 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3934 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3934 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4028 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4256 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4531 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2495
4531 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases COG1,CommitDateFilter,CommitDateFilter0,DateFilter,Fil1,LineItem,Orders,OrdersCount
4531 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: Orders[3,9],DateFilter[7,13],Orders[-1,-1],COG1[11,7],LineItem[5,11],CommitDateFilter0[8,20],CommitDateFilter[-1,-1],COG1[11,7] C:  R: COG1[-1,-1],Fil1[12,7],OrdersCount[14,14]
4537 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9546 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9718 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9719 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9720 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:36:17	2019-01-28 11:36:23	COGROUP,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2495	COG1,CommitDateFilter,CommitDateFilter0,DateFilter,Fil1,LineItem,Orders,OrdersCount	COGROUP	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/lineitem"
Failed to read data from "/tpch/in/orders"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2495	->	null,
null	->	null,
null	->	null,
null


9720 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9722 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9741 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 923 milliseconds (9923 ms)
Q4 times (sec):	11

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-5-6]
ok: [neu-5-3]
ok: [neu-3-2]
ok: [neu-5-1]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-5-1]
changed: [neu-3-7]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q5
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs21 -param reducers=1 -f queries/Q5.pig

66   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
67   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
923  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1048 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1699 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q5.pig-7424a3e2-01fd-44eb-9506-049247613445
1700 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2852 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 1 time(s).
2898 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
2946 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2989 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
3057 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
3134 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $1, $2, $4, $5, $6, $7
3138 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $5, $6, $7, $8
3139 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $1, $3, $4, $7, $8, $9, $10, $11, $12, $13, $14, $15
3140 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $4, $5, $6
3140 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $3
3140 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for region: $2
3227 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3270 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3300 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-232
3304 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3304 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3304 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3305 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3305 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3312 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 8
3312 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 8
3898 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3903 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3908 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3909 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3909 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4105 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1251047616/tmp-1267348793/pig-0.17.0-core-h2.jar
4124 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1251047616/tmp1581807396/automaton-1.11-8.jar
4152 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1251047616/tmp602586980/antlr-runtime-3.4.jar
4173 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1251047616/tmp854160494/joda-time-2.9.4.jar
4189 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4197 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4197 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4197 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4283 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4484 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4787 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2496
4787 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fregion,n1,nation,region,seln1
4787 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: nation[12,9],nation[-1,-1],n1[19,5],region[14,9],region[-1,-1],fregion[16,10],fregion[-1,-1],n1[19,5] C:  R: seln1[20,8]
4793 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9803 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9980 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9980 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9982 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:36:43	2019-01-28 11:36:49	HASH_JOIN,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2496	fregion,n1,nation,region,seln1	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/nation"
Failed to read data from "/tpch/in/region"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2496	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null


9982 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9984 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
10003 [main] INFO  org.apache.pig.Main  - Pig script completed in 10 seconds and 183 milliseconds (10183 ms)
Q5 times (sec):	12

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-3-2]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-3]
changed: [neu-5-10]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-5-1]
changed: [neu-3-7]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q6
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs21 -param reducers=1 -f queries/Q6.pig

63   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
64   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
899  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1007 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1618 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q6.pig-58b859f7-59ba-4312-bc6d-d42c70237ae1
1619 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2522 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_CHARARRAY 2 time(s).
2523 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_INT 1 time(s).
2523 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 4 time(s).
2560 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: GROUP_BY,FILTER
2609 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2651 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2698 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $0, $1, $2, $3, $7, $8, $9, $11, $12, $13, $14, $15
2760 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2835 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
2852 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
2888 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 1
2888 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 1
3470 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3477 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3482 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3482 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3482 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3732 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1309247238/tmp2013875843/pig-0.17.0-core-h2.jar
3753 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1309247238/tmp439033649/automaton-1.11-8.jar
3768 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1309247238/tmp-2091454462/antlr-runtime-3.4.jar
3784 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1309247238/tmp7821504/joda-time-2.9.4.jar
3798 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
3806 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3807 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3807 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
3899 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4096 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4402 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2497
4402 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases flineitem,grpResult,lineitem,saving,sumResult
4403 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: lineitem[4,11],flineitem[7,12],saving[-1,-1],sumResult[11,12],grpResult[10,12] C: sumResult[11,12],grpResult[10,12] R: sumResult[11,12]
4410 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9424 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9614 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9614 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9616 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:37:10	2019-01-28 11:37:16	GROUP_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2497	flineitem,grpResult,lineitem,saving,sumResult	GROUP_BY,COMBINER	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	/user/root/tpch/out_hdfs21/Q6out,

Input(s):
Failed to read data from "/tpch/in/lineitem"

Output(s):
Failed to produce result in "/user/root/tpch/out_hdfs21/Q6out"

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2497


9616 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9620 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9639 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 822 milliseconds (9822 ms)
Q6 times (sec):	11

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-2]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-3]
changed: [neu-5-10]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q7
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs21 -param reducers=1 -f queries/Q7.pig

59   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
60   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
879  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
995  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1606 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q7.pig-cdfdb8c1-4036-4476-8e9a-2c98c8426c71
1606 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2692 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 1 time(s).
2739 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
2788 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2831 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2887 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2967 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $4, $5, $6, $7, $8
2971 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $1, $2, $4, $5, $6, $7
2971 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $4, $5, $6
2972 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem0: $1, $3, $4, $7, $8, $9, $11, $12, $13, $14, $15
2972 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation20: $2, $3
2973 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation10: $2, $3
3075 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3106 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 100
3107 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - Insert a file-concatenation job
3113 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 100
3114 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - Insert a file-concatenation job
3132 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3160 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-251
3164 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3164 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3164 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3171 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 10
3171 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 10
3756 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3761 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3765 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3998 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp394269145/tmp-1807909194/pig-0.17.0-core-h2.jar
4019 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp394269145/tmp1443060210/automaton-1.11-8.jar
4033 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp394269145/tmp789836315/antlr-runtime-3.4.jar
4050 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp394269145/tmp-808738016/joda-time-2.9.4.jar
4066 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4074 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4074 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4074 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4121 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
4122 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
4122 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4157 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp394269145/tmp-1093558322/pig-0.17.0-core-h2.jar
4169 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp394269145/tmp1669217773/automaton-1.11-8.jar
4180 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp394269145/tmp-1232536226/antlr-runtime-3.4.jar
4195 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp394269145/tmp1599709241/joda-time-2.9.4.jar
4197 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4198 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4198 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4198 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4217 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 2 map-reduce job(s) waiting for submission.
4411 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4450 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4722 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2498
4722 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases nation1,nation10
4722 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: nation10[12,11],nation10[-1,-1],nation1[16,10] C:  R: 
4727 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2499
4727 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases nation2,nation20
4727 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: nation20[14,11],nation20[-1,-1],nation2[17,10] C:  R: 
4730 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9743 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9905 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9913 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9913 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 2 map reduce job(s) failed!
9915 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:37:36	2019-01-28 11:37:42	REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2498	nation1,nation10	MAP_ONLY	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	
job_1546715600715_2499	nation2,nation20	MAP_ONLY	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/nation"
Failed to read data from "/tpch/in/nation"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2498	->	null,
null	->	null,
null	->	null,
job_1546715600715_2499	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null


9915 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9917 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9942 [main] INFO  org.apache.pig.Main  - Pig script completed in 10 seconds and 105 milliseconds (10105 ms)
Q7 times (sec):	11

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-5-3]
ok: [neu-3-2]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q8
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs21 -param reducers=1 -f queries/Q8.pig

59   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
60   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
882  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1001 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1587 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q8.pig-2128c129-1a1a-44ed-b149-4040de4b8d57
1588 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2705 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 2 time(s).
2751 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
2799 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2836 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2890 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
3014 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $5, $6, $7, $8
3018 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $4, $5, $6
3019 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $3
3019 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $1, $2, $4, $5, $6, $7
3020 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for part: $1, $2, $3, $5, $6, $7, $8
3020 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $3, $4, $7, $8, $9, $10, $11, $12, $13, $14, $15
3021 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for region: $2
3138 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3154 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 100
3155 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - Insert a file-concatenation job
3158 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 100
3160 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - Insert a file-concatenation job
3165 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 100
3165 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 0
3166 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - Insert a file-concatenation job
3184 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3214 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-294
3218 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3219 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3219 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3219 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3228 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 14
3228 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 map-only splittees.
3229 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 out of total 3 MR operators.
3229 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 13
3867 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3873 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3877 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3877 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3877 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4083 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp620167891/tmp517754266/pig-0.17.0-core-h2.jar
4108 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp620167891/tmp-463260924/automaton-1.11-8.jar
4122 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp620167891/tmp-1599069562/antlr-runtime-3.4.jar
4135 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp620167891/tmp-1202475605/joda-time-2.9.4.jar
4151 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4159 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4159 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4159 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4247 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
4248 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
4249 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4284 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp620167891/tmp1231503277/pig-0.17.0-core-h2.jar
4298 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp620167891/tmp2057191501/automaton-1.11-8.jar
4309 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp620167891/tmp921718563/antlr-runtime-3.4.jar
4324 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp620167891/tmp1210148329/joda-time-2.9.4.jar
4326 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4327 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4327 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4327 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4346 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
4347 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
4347 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4378 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp620167891/tmp-633497355/pig-0.17.0-core-h2.jar
4397 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp620167891/tmp-1794408122/automaton-1.11-8.jar
4409 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp620167891/tmp2025347306/antlr-runtime-3.4.jar
4422 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp620167891/tmp-256358055/joda-time-2.9.4.jar
4424 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up multi store job
4425 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4425 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4425 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4439 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 3 map-reduce job(s) waiting for submission.
4646 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4685 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4712 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4946 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2500
4946 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fpart,lineitem,p1,part
4946 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: lineitem[8,11],lineitem[-1,-1],p1[33,5],part[16,7],part[-1,-1],fpart[19,8],fpart[-1,-1],p1[33,5] C:  R: p1[-1,-1]
4949 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2501
4949 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fregion,region
4949 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: region[14,9],region[-1,-1],fregion[17,10],fregion[-1,-1] C:  R: 
4951 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2502
4951 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases nation
4951 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: nation[12,9],nation[-1,-1],nation[-1,-1] C:  R: 
4954 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9969 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
10236 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
10243 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
10249 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
10249 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 3 map reduce job(s) failed!
10251 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:38:02	2019-01-28 11:38:08	REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2500	fpart,lineitem,p1,part	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/part
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/part
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	
job_1546715600715_2502	nation	MULTI_QUERY,MAP_ONLY	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	
job_1546715600715_2501	fregion,region	MAP_ONLY	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/region
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/region
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/part"
Failed to read data from "/tpch/in/lineitem"
Failed to read data from "/tpch/in/nation"
Failed to read data from "/tpch/in/region"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2500	->	null,
job_1546715600715_2502	->	null,null,
null	->	null,
null	->	null,
job_1546715600715_2501	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null


10251 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
10253 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
10273 [main] INFO  org.apache.pig.Main  - Pig script completed in 10 seconds and 446 milliseconds (10446 ms)
Q8 times (sec):	12

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-3-2]
ok: [neu-5-1]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q9
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs21 -param reducers=1 -f queries/Q9.pig

61   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
61   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
882  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
999  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1644 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q9.pig-5adc5aa7-bd74-44d6-8f66-da1906fafc16
1644 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2782 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 1 time(s).
2824 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
2873 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2917 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2971 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
3052 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $1, $2, $3, $5, $6, $7, $8
3056 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for partsupp: $2, $4
3056 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $4, $5, $6
3057 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $2, $3
3057 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $3, $7, $8, $9, $10, $11, $12, $13, $14, $15
3058 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for part: $2, $3, $4, $5, $6, $7, $8
3160 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3189 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 100
3190 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - Insert a file-concatenation job
3211 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3241 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-246
3245 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3246 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3246 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3246 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3253 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 9
3254 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 9
3859 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3865 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3870 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3870 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3871 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4071 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1951031698/tmp1397509639/pig-0.17.0-core-h2.jar
4097 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1951031698/tmp-1738928212/automaton-1.11-8.jar
4114 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1951031698/tmp-557392882/antlr-runtime-3.4.jar
4128 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1951031698/tmp-1035044243/joda-time-2.9.4.jar
4144 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4152 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4152 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4152 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4241 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
4241 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
4242 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4274 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1951031698/tmp-1667478472/pig-0.17.0-core-h2.jar
4300 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1951031698/tmp-1813142749/automaton-1.11-8.jar
4314 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1951031698/tmp1644954346/antlr-runtime-3.4.jar
4330 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1951031698/tmp-643362290/joda-time-2.9.4.jar
4332 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4332 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4332 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4333 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4348 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 2 map-reduce job(s) waiting for submission.
4570 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4614 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4853 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2503
4853 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fpart,j1,lineitem,part
4853 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: lineitem[8,11],lineitem[-1,-1],j1[22,5],part[18,7],part[-1,-1],fpart[20,8],fpart[-1,-1],j1[22,5] C:  R: j1[-1,-1]
4858 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2504
4859 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases nation
4859 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: nation[12,9],nation[-1,-1] C:  R: 
4863 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9874 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
10557 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
10566 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
10566 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 2 map reduce job(s) failed!
10568 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:38:27	2019-01-28 11:38:34	REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2503	fpart,j1,lineitem,part	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	
job_1546715600715_2504	nation	MAP_ONLY	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/lineitem"
Failed to read data from "/tpch/in/part"
Failed to read data from "/tpch/in/nation"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2503	->	null,
job_1546715600715_2504	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null


10568 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
10570 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
10588 [main] INFO  org.apache.pig.Main  - Pig script completed in 10 seconds and 766 milliseconds (10766 ms)
Q9 times (sec):	12

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-11]
ok: [neu-3-7]
ok: [neu-3-2]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-5-1]
changed: [neu-3-7]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q10
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs21 -param reducers=1 -f queries/Q10.pig

61   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
62   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
893  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1018 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1599 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q10.pig-4782c935-0ee4-4b23-b23d-a0e2e27ee842
1599 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2750 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 1 time(s).
2796 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,FILTER,LIMIT
2847 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2890 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2944 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
3016 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $1, $2, $3, $4, $7, $9, $10, $11, $12, $13, $14, $15
3020 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $2, $3
3020 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $6
3020 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $5, $6, $7, $8
3110 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3151 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3182 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-231
3186 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3186 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3186 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3193 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 7
3193 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 7
3804 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3810 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3815 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3815 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3815 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4026 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-928668289/tmp956799716/pig-0.17.0-core-h2.jar
4058 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-928668289/tmp1830131145/automaton-1.11-8.jar
4072 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-928668289/tmp-538408630/antlr-runtime-3.4.jar
4089 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-928668289/tmp124724880/joda-time-2.9.4.jar
4104 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4112 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4113 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4113 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4201 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4412 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4704 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2505
4704 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases c1,customer,forders,orders,selc1
4704 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: customer[4,11],customer[-1,-1],c1[24,5],orders[6,9],orders[-1,-1],forders[21,10],forders[-1,-1],c1[24,5] C:  R: selc1[25,8]
4710 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9719 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9888 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9889 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9890 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:38:54	2019-01-28 11:39:00	HASH_JOIN,GROUP_BY,ORDER_BY,FILTER,LIMIT

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2505	c1,customer,forders,orders,selc1	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/customer
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/customer
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/customer"
Failed to read data from "/tpch/in/orders"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2505	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null


9890 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9892 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
10011 [main] INFO  org.apache.pig.Main  - Pig script completed in 10 seconds and 82 milliseconds (10082 ms)
Q10 times (sec):	11

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-3-2]
ok: [neu-5-1]
ok: [neu-3-7]
ok: [neu-3-11]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-3]
changed: [neu-5-10]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q11
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs21 -param reducers=1 -f queries/Q11.pig

66   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
67   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
893  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1005 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1573 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q11.pig-585c7665-7887-4e20-85f7-898c2d115285
1573 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2553 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 1 time(s).
2598 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
2649 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2692 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2733 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for partsupp: $4
2737 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $4, $5, $6
2737 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $2, $3
2800 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2877 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
2903 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
2920 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
2933 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-125
2938 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
2938 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
2947 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 6
2947 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 0 map-reduce splittees.
2947 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 0 out of total 3 MR operators.
2947 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 6
3531 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3536 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3541 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3541 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3541 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3768 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp542816255/tmp-1327628560/pig-0.17.0-core-h2.jar
3800 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp542816255/tmp883292514/automaton-1.11-8.jar
3816 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp542816255/tmp-634983015/antlr-runtime-3.4.jar
3832 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp542816255/tmp-438736272/joda-time-2.9.4.jar
3847 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
3856 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3856 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3856 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
3944 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4159 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4448 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2506
4448 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fnation,j1,nation,selj1,supplier
4448 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: supplier[5,11],supplier[-1,-1],j1[11,5],nation[7,9],nation[-1,-1],fnation[9,10],fnation[-1,-1],j1[11,5] C:  R: selj1[13,8]
4456 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9466 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9645 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9645 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9646 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:39:19	2019-01-28 11:39:25	HASH_JOIN,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2506	fnation,j1,nation,selj1,supplier	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/nation"
Failed to read data from "/tpch/in/supplier"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2506	->	null,
null	->	null,null,
null	->	null,
null	->	null,
null	->	null,
null


9647 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9649 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9667 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 846 milliseconds (9846 ms)
Q11 times (sec):	12

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-3-2]
ok: [neu-5-1]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q12
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs21 -param reducers=1 -f queries/Q12.pig

64   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
65   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
879  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
989  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1578 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q12.pig-0b5a60dc-666f-4944-b7e7-6284f9a4667b
1578 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2515 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
2564 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2607 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2651 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $1, $2, $3, $4, $6, $7, $8
2655 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $1, $2, $3, $4, $5, $6, $7, $8, $9, $13, $15
2714 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2796 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
2846 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-111
2851 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
2858 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 4
2858 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 4
3423 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3429 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3433 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3434 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3434 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3636 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-517350687/tmp177672465/pig-0.17.0-core-h2.jar
3661 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-517350687/tmp993671207/automaton-1.11-8.jar
3677 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-517350687/tmp-459753396/antlr-runtime-3.4.jar
3695 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-517350687/tmp-253803475/joda-time-2.9.4.jar
3711 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
3719 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3719 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3719 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
3831 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4034 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4335 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2507
4335 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases flineitem,l1,lineitem,orders,sell1
4335 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: orders[4,9],orders[-1,-1],l1[12,5],lineitem[6,11],lineitem[-1,-1],flineitem[8,12],flineitem[-1,-1],l1[12,5] C:  R: sell1[13,8]
4341 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9350 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9549 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9550 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9551 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:39:44	2019-01-28 11:39:50	HASH_JOIN,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2507	flineitem,l1,lineitem,orders,sell1	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/orders
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/orders
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/orders"
Failed to read data from "/tpch/in/lineitem"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2507	->	null,
null	->	null,
null	->	null,
null


9552 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9554 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9574 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 745 milliseconds (9745 ms)
Q12 times (sec):	11

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-5-3]
ok: [neu-3-2]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-3]
changed: [neu-5-10]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q13
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs21 -param reducers=1 -f queries/Q13.pig

60   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
61   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
864  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
982  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1648 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q13.pig-41ba07bb-9e88-4399-9776-42975253556e
1648 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2607 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_LONG 1 time(s).
2653 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: COGROUP,GROUP_BY,ORDER_BY,FILTER
2713 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2765 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2834 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2916 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $1, $2, $3, $4, $5, $6, $7
2920 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $4, $5, $6, $7
3018 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3066 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3097 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-69
3112 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 4
3112 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 4
3675 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3681 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3685 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3685 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3686 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3882 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1330009575/tmp-1301194555/pig-0.17.0-core-h2.jar
4258 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1330009575/tmp969394084/automaton-1.11-8.jar
4296 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1330009575/tmp-55300739/antlr-runtime-3.4.jar
4319 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1330009575/tmp695331345/joda-time-2.9.4.jar
4334 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4342 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4342 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4342 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4435 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4640 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4938 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2508
4939 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases COG,COG1,COG2,customer,forders,orders,pcustomer,porders
4939 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: orders[5,9],orders[-1,-1],forders[7,10],porders[9,10],COG1[13,7],customer[3,11],pcustomer[-1,-1],COG1[13,7] C:  R: COG2[14,7],COG[15,6]
4945 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9954 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
10598 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
10599 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
10600 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:40:09	2019-01-28 11:40:16	COGROUP,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2508	COG,COG1,COG2,customer,forders,orders,pcustomer,porders	COGROUP	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/customer
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/customer
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/customer"
Failed to read data from "/tpch/in/orders"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2508	->	null,
null	->	null,
null	->	null,
null


10601 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
10603 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
10623 [main] INFO  org.apache.pig.Main  - Pig script completed in 10 seconds and 790 milliseconds (10790 ms)
Q13 times (sec):	12

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-3-2]
ok: [neu-5-3]
ok: [neu-5-10]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-7]
ok: [neu-3-11]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-3]
changed: [neu-5-10]
changed: [neu-3-11]
changed: [neu-5-6]
changed: [neu-5-1]
changed: [neu-3-2]
changed: [neu-3-7]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q14
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs21 -param reducers=1 -f queries/Q14.pig

64   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
65   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
909  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1020 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1629 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q14.pig-85e48698-ce00-49c4-918b-cefbd901f81f
1630 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2633 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 2 time(s).
2688 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,FILTER
2738 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2780 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2834 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2924 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $0, $2, $3, $4, $7, $8, $9, $11, $12, $13, $14, $15
3018 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3034 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 1
3039 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3056 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3073 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3082 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 5
3083 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 map-only splittees.
3083 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 out of total 3 MR operators.
3085 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged MR job 130 into MR job 178
3085 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged MR job 132 into MR job 178
3085 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Requested parallelism of splitter: 1
3085 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 map-reduce splittees.
3086 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 out of total 3 MR operators.
3086 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 3
3697 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3702 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3707 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3707 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3708 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3940 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp621224168/tmp-268208612/pig-0.17.0-core-h2.jar
3967 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp621224168/tmp1505676239/automaton-1.11-8.jar
3984 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp621224168/tmp-874111929/antlr-runtime-3.4.jar
4002 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp621224168/tmp98518117/joda-time-2.9.4.jar
4018 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4026 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4026 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4027 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4122 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4327 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4625 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2509
4625 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases filtered_lineitem,lineitem,lineitem2,lineitem_part,part
4626 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: lineitem[3,11],lineitem[-1,-1],filtered_lineitem[7,20],lineitem2[8,12],lineitem_part[10,16],part[5,7],part[-1,-1],lineitem_part[10,16] C:  R: 
4631 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9640 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9812 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9813 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9814 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:40:35	2019-01-28 11:40:41	HASH_JOIN,GROUP_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2509	filtered_lineitem,lineitem,lineitem2,lineitem_part,part	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/part
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/part
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/part"
Failed to read data from "/tpch/in/lineitem"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2509	->	null,
null	->	null,
null


9815 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9817 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9836 [main] INFO  org.apache.pig.Main  - Pig script completed in 10 seconds and 17 milliseconds (10017 ms)
Q14 times (sec):	12

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-3-2]
ok: [neu-5-3]
ok: [neu-5-1]
ok: [neu-5-6]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-3]
changed: [neu-5-10]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q15
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs21 -param reducers=1 -f queries/Q15.pig

62   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
63   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
900  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1012 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1603 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q15.pig-e4c6ea0b-c59f-4e66-8543-a340568a8762
1603 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2538 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 1 time(s).
2590 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
2641 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2684 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2739 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2804 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $3, $5, $6
2808 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $0, $1, $3, $4, $7, $8, $9, $11, $12, $13, $14, $15
2896 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
2923 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
2942 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
2956 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-116
2960 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
2969 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 5
2969 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 0 map-reduce splittees.
2970 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 0 out of total 3 MR operators.
2970 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 5
3555 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3561 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3565 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3565 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3565 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3766 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp757670054/tmp-564618640/pig-0.17.0-core-h2.jar
3800 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp757670054/tmp248477083/automaton-1.11-8.jar
3821 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp757670054/tmp-498824387/antlr-runtime-3.4.jar
3837 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp757670054/tmp1485637978/joda-time-2.9.4.jar
3852 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
3861 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3861 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3861 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
3959 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4166 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4462 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2510
4462 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases flineitem,glineitem,lineitem,revenue,sumlineitem
4463 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: lineitem[3,11],lineitem[-1,-1],flineitem[7,12],sumlineitem[9,14],revenue[13,10],glineitem[11,12] C: revenue[13,10],glineitem[11,12] R: revenue[13,10]
4467 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9475 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9654 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9654 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9656 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:41:00	2019-01-28 11:41:06	HASH_JOIN,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2510	flineitem,glineitem,lineitem,revenue,sumlineitem	GROUP_BY,COMBINER	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/lineitem"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2510	->	null,null,
null	->	null,
null	->	null,
null	->	null,
null


9656 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9658 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9677 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 849 milliseconds (9849 ms)
Q15 times (sec):	12

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-2]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q16
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs21 -param reducers=1 -f queries/Q16.pig

62   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
63   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
881  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
993  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
2508 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q16.pig-d49554b6-4bdc-42f1-9480-ddbba7f7ccd2
2508 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
3446 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_CHARARRAY 4 time(s).
3486 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
3537 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
3574 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
3620 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for parts: $1, $2, $6, $7, $8
3624 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for partsupp: $2, $3, $4
3625 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $3, $4, $5
3682 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
3764 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3809 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3841 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-113
3846 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3846 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3854 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 5
3854 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 5
4430 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
4435 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
4440 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
4440 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
4441 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4647 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-2037282266/tmp-1436942759/pig-0.17.0-core-h2.jar
4684 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-2037282266/tmp-1082611700/automaton-1.11-8.jar
4710 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-2037282266/tmp-1358643572/antlr-runtime-3.4.jar
4725 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-2037282266/tmp-1087969719/joda-time-2.9.4.jar
4742 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4751 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4751 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4751 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4845 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
5042 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
5349 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2511
5349 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fpartsupp,fs1,fsupplier,partsupp,pss,supplier
5349 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: supplier[17,11],fsupplier[19,12],fs1[-1,-1],pss[22,6],partsupp[15,11],partsupp[-1,-1],pss[22,6] C:  R: fpartsupp[24,12]
5355 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
10364 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
10533 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
10534 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
10535 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:41:26	2019-01-28 11:41:32	HASH_JOIN,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2511	fpartsupp,fs1,fsupplier,partsupp,pss,supplier	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/partsupp
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/partsupp
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/partsupp"
Failed to read data from "/tpch/in/supplier"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2511	->	null,
null	->	null,
null	->	null,
null	->	null,
null


10536 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
10537 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
10556 [main] INFO  org.apache.pig.Main  - Pig script completed in 10 seconds and 729 milliseconds (10729 ms)
Q16 times (sec):	12

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-2]
ok: [neu-3-7]
ok: [neu-3-11]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-5-1]
changed: [neu-3-7]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q17
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs21 -param reducers=1 -f queries/Q17.pig

77   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
77   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
892  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1003 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1597 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q17.pig-03f7ac02-fece-4872-8cda-0c0b0c5e35fb
1597 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2548 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 1 time(s).
2549 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_LONG 1 time(s).
2598 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: COGROUP,GROUP_BY,FILTER
2663 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2722 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2795 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2864 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $0, $2, $3, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15
2868 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for part: $1, $2, $4, $5, $7, $8
2956 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
2989 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3027 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 2
3027 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 2
3633 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3640 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3646 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3647 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3647 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3870 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1052114587/tmp1377087973/pig-0.17.0-core-h2.jar
3890 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1052114587/tmp-47604369/automaton-1.11-8.jar
3908 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1052114587/tmp1211498255/antlr-runtime-3.4.jar
3945 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1052114587/tmp-1134057097/joda-time-2.9.4.jar
3961 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
3969 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3969 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3970 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4071 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4289 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4574 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2512
4574 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases COG,COG1,COG2,COG3,lineitem,part
4574 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: part[5,7],part[-1,-1],part[8,7],part[9,7],COG1[11,7],lineitem[3,11],lineitem[-1,-1],COG1[11,7] C:  R: COG1[-1,-1],COG1[12,7],COG2[13,7],COG3[15,7],COG[16,6]
4580 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9590 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9765 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9766 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9768 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:41:51	2019-01-28 11:41:57	COGROUP,GROUP_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2512	COG,COG1,COG2,COG3,lineitem,part	COGROUP	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/lineitem"
Failed to read data from "/tpch/in/part"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2512	->	null,
null


9768 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9771 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9792 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 961 milliseconds (9961 ms)
Q17 times (sec):	12

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-3-2]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-5-3]
ok: [neu-3-7]
ok: [neu-3-11]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-5-1]
changed: [neu-3-7]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q18
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs21 -param reducers=1 -f queries/Q18.pig

55   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
56   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
885  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
998  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1575 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q18.pig-19af8792-f309-4e77-9453-c91f11077c02
1575 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2596 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 1 time(s).
2638 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,COGROUP,GROUP_BY,ORDER_BY,FILTER
2692 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2736 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2791 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2861 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $1, $2, $3, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15
2866 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $5, $6, $7, $8
2950 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
2992 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3022 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-132
3027 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3034 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 5
3034 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 5
3614 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3619 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3624 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3624 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3624 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3856 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-476566346/tmp-1774786324/pig-0.17.0-core-h2.jar
3958 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-476566346/tmp78485335/automaton-1.11-8.jar
3971 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-476566346/tmp347888596/antlr-runtime-3.4.jar
3986 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-476566346/tmp1711339072/joda-time-2.9.4.jar
4003 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4011 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4012 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4012 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4106 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4313 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4609 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2513
4609 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases COG,lineitem,lineitem_orders,orders
4609 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: lineitem[3,11],lineitem[-1,-1],COG[11,6],orders[7,9],orders[-1,-1],COG[11,6] C:  R: COG[-1,-1],COG[13,6],lineitem_orders[15,18]
4613 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9621 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9809 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9810 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9811 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:42:17	2019-01-28 11:42:23	HASH_JOIN,COGROUP,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2513	COG,lineitem,lineitem_orders,orders	COGROUP	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/lineitem"
Failed to read data from "/tpch/in/orders"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2513	->	null,
null	->	null,
null	->	null,
null	->	null,
null


9811 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9813 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9832 [main] INFO  org.apache.pig.Main  - Pig script completed in 10 seconds and 17 milliseconds (10017 ms)
Q18 times (sec):	12

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-2]
ok: [neu-3-7]
ok: [neu-3-11]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q19
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs21 -param reducers=1 -f queries/Q19.pig

52   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
53   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
873  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
990  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1604 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q19.pig-947e9680-7775-4a04-a22e-5deca3fedf9d
1604 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2515 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_LONG 6 time(s).
2515 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 7 time(s).
2559 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,FILTER
2608 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2644 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2698 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
3035 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $0, $2, $3, $7, $8, $9, $10, $11, $12, $15
3039 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for part: $1, $2, $4, $7, $8
3125 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3157 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3186 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3192 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 2
3192 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 2
3780 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3786 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3790 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3791 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3791 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4013 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1164641757/tmp-994851748/pig-0.17.0-core-h2.jar
4035 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1164641757/tmp277652166/automaton-1.11-8.jar
4059 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1164641757/tmp-1416035695/antlr-runtime-3.4.jar
4076 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1164641757/tmp-197854889/joda-time-2.9.4.jar
4093 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4101 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4101 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4102 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4217 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4426 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4721 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2514
4721 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fltResult,lineitem,lpart,part,volume
4721 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: part[6,7],part[-1,-1],lpart[8,8],lineitem[4,11],lineitem[-1,-1],lpart[8,8] C:  R: lpart[-1,-1],fltResult[10,12],volume[37,9]
4726 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9736 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9912 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9912 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9913 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:42:42	2019-01-28 11:42:49	HASH_JOIN,GROUP_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2514	fltResult,lineitem,lpart,part,volume	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/lineitem"
Failed to read data from "/tpch/in/part"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2514	->	null,
null


9914 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9916 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9934 [main] INFO  org.apache.pig.Main  - Pig script completed in 10 seconds and 105 milliseconds (10105 ms)
Q19 times (sec):	12

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-2]
ok: [neu-3-7]
ok: [neu-3-11]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q20
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs21 -param reducers=1 -f queries/Q20.pig

61   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
62   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
883  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
998  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1605 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q20.pig-f914e556-ef2e-46d2-8db7-212e89d4be31
1606 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2655 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 1 time(s).
2700 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,DISTINCT,FILTER
2749 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2792 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2841 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $4, $5, $6
2846 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $2, $3
2846 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for partsupp: $3, $4
2846 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $0, $3, $5, $6, $7, $8, $9, $11, $12, $13, $14, $15
2847 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for part: $2, $3, $4, $5, $6, $7, $8
2915 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
3012 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3061 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3099 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-233
3106 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3106 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3107 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3107 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3117 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 9
3118 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 9
3706 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3711 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3716 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3716 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3716 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3958 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1325686331/tmp951944661/pig-0.17.0-core-h2.jar
3977 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1325686331/tmp-171850801/automaton-1.11-8.jar
3996 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1325686331/tmp1268128338/antlr-runtime-3.4.jar
4013 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1325686331/tmp1280728623/joda-time-2.9.4.jar
4031 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4040 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4040 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4041 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4129 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
4129 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
4130 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
4130 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
4130 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4166 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1325686331/tmp-1195947034/pig-0.17.0-core-h2.jar
4178 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1325686331/tmp570050232/automaton-1.11-8.jar
4190 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1325686331/tmp-1182880882/antlr-runtime-3.4.jar
4205 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1325686331/tmp851702005/joda-time-2.9.4.jar
4207 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4208 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4208 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4208 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4236 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
4237 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
4238 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
4238 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
4238 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4273 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1325686331/tmp-583436096/pig-0.17.0-core-h2.jar
4303 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1325686331/tmp-460559873/automaton-1.11-8.jar
4315 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1325686331/tmp132499236/antlr-runtime-3.4.jar
4329 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1325686331/tmp653307458/joda-time-2.9.4.jar
4331 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4331 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4331 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4331 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4332 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting identity combiner class.
4345 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 3 map-reduce job(s) waiting for submission.
4563 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4603 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4628 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4851 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2515
4851 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases lineitem,lineitem1,lineitem2,lineitem3,lineitem4
4851 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: lineitem[9,11],lineitem[-1,-1],lineitem2[11,12],lineitem1[10,12],lineitem4[13,12],lineitem3[12,12] C: lineitem4[13,12],lineitem3[12,12] R: lineitem4[13,12]
4854 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2516
4855 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases nation,nation1,s_n,supplier
4855 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: supplier[26,11],supplier[-1,-1],s_n[28,6],nation[23,9],nation[-1,-1],nation1[24,10],nation1[-1,-1],s_n[28,6] C:  R: s_n[-1,-1]
4857 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2517
4857 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases part,part2,part3
4858 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: part[3,7],part[-1,-1],part2[5,8],part3[-1,-1] C:  R: 
4860 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9878 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
10163 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
10172 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
10180 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
10180 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 3 map reduce job(s) failed!
10183 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:43:08	2019-01-28 11:43:14	HASH_JOIN,GROUP_BY,ORDER_BY,DISTINCT,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2515	lineitem,lineitem1,lineitem2,lineitem3,lineitem4	GROUP_BY,COMBINER	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	
job_1546715600715_2517	part,part2,part3	DISTINCT	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/part
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/part
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	
job_1546715600715_2516	nation,nation1,s_n,supplier	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/lineitem"
Failed to read data from "/tpch/in/part"
Failed to read data from "/tpch/in/nation"
Failed to read data from "/tpch/in/supplier"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2515	->	null,
job_1546715600715_2517	->	null,
null	->	null,
null	->	null,
null	->	null,
job_1546715600715_2516	->	null,
null	->	null,
null	->	null,
null


10184 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
10186 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
10205 [main] INFO  org.apache.pig.Main  - Pig script completed in 10 seconds and 376 milliseconds (10376 ms)
Q20 times (sec):	12

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-2]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-5-1]
changed: [neu-3-7]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q21
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs21 -param reducers=1 -f queries/Q21.pig

55   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
56   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
883  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1001 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1602 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q21.pig-b025b6d7-e52d-4336-9412-5ceb9c5e3d5c
1602 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2713 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_LONG 2 time(s).
2766 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER,LIMIT
2813 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2857 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2909 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
3008 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $1, $3, $4, $5, $6, $7, $8, $9, $10, $13, $14, $15
3012 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $1, $3, $4, $5, $6, $7, $8
3012 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $2, $4, $5, $6
3115 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3132 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 100
3133 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - Insert a file-concatenation job
3151 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3182 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-172
3188 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3188 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3198 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 10
3199 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 map-only splittees.
3199 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 out of total 3 MR operators.
3199 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 9
3801 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3807 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3811 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3811 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3812 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4000 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-578711090/tmp-421383733/pig-0.17.0-core-h2.jar
4034 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-578711090/tmp-621145965/automaton-1.11-8.jar
4047 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-578711090/tmp534359607/antlr-runtime-3.4.jar
4062 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-578711090/tmp1658667081/joda-time-2.9.4.jar
4079 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up multi store job
4086 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4086 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4087 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4176 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
4176 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
4177 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4211 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-578711090/tmp-2046475031/pig-0.17.0-core-h2.jar
4225 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-578711090/tmp265294743/automaton-1.11-8.jar
4236 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-578711090/tmp264905248/antlr-runtime-3.4.jar
4249 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-578711090/tmp-2062835737/joda-time-2.9.4.jar
4251 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4253 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4253 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4253 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4271 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 2 map-reduce job(s) waiting for submission.
4474 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4512 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4776 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2518
4776 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases L2,fL2,gl,lineitem,t1
4776 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: lineitem[5,11],lineitem[-1,-1],gl[16,5] C:  R: L2[18,5],fL2[20,6],t1[21,13]
4784 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2519
4784 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fn,nation
4784 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: nation[9,9],nation[-1,-1],fn[33,5] C:  R: 
4787 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9797 [main] INFO  org.apache.pig.tools.pigstats.JobStats  - using output size reader: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.FileBasedOutputSizeReader
9804 [main] WARN  org.apache.pig.tools.pigstats.JobStats  - unable to find the output file
java.io.FileNotFoundException: File /user/root/tpch/out_hdfs21/Q21_fL2_fL2 does not exist.
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:904)
	at org.apache.hadoop.hdfs.DistributedFileSystem.access$600(DistributedFileSystem.java:114)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:964)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:961)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:961)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.FileBasedOutputSizeReader.getPathSize(FileBasedOutputSizeReader.java:84)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.FileBasedOutputSizeReader.getOutputSize(FileBasedOutputSizeReader.java:79)
	at org.apache.pig.tools.pigstats.JobStats.getOutputSize(JobStats.java:351)
	at org.apache.pig.tools.pigstats.mapreduce.MRJobStats.addOneOutputStats(MRJobStats.java:464)
	at org.apache.pig.tools.pigstats.mapreduce.MRJobStats.addOutputStatistics(MRJobStats.java:450)
	at org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil.addFailedJobStats(MRPigStatsUtil.java:196)
	at org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil.accumulateStats(MRPigStatsUtil.java:171)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher.launchPig(MapReduceLauncher.java:379)
	at org.apache.pig.backend.hadoop.executionengine.HExecutionEngine.launchPig(HExecutionEngine.java:290)
	at org.apache.pig.PigServer.launchPlan(PigServer.java:1475)
	at org.apache.pig.PigServer.executeCompiledLogicalPlan(PigServer.java:1460)
	at org.apache.pig.PigServer.execute(PigServer.java:1449)
	at org.apache.pig.PigServer.executeBatch(PigServer.java:489)
	at org.apache.pig.PigServer.executeBatch(PigServer.java:472)
	at org.apache.pig.tools.grunt.GruntParser.executeBatch(GruntParser.java:171)
	at org.apache.pig.tools.grunt.GruntParser.processFsCommand(GruntParser.java:1168)
	at org.apache.pig.tools.pigscript.parser.PigScriptParser.parse(PigScriptParser.java:136)
	at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:230)
	at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:205)
	at org.apache.pig.tools.grunt.Grunt.exec(Grunt.java:81)
	at org.apache.pig.Main.run(Main.java:500)
	at org.apache.pig.Main.main(Main.java:175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:234)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:148)
9810 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
10035 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
10043 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
10043 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 2 map reduce job(s) failed!
10045 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:43:35	2019-01-28 11:43:41	REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER,LIMIT

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2518	L2,fL2,gl,lineitem,t1	GROUP_BY,MULTI_QUERY	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	/user/root/tpch/out_hdfs21/Q21_fL2_fL2,
job_1546715600715_2519	fn,nation	MAP_ONLY	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/lineitem"
Failed to read data from "/tpch/in/nation"

Output(s):
Failed to produce result in "/user/root/tpch/out_hdfs21/Q21_fL2_fL2"

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2518	->	null,
job_1546715600715_2519	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null


10046 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
10049 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
10068 [main] INFO  org.apache.pig.Main  - Pig script completed in 10 seconds and 254 milliseconds (10254 ms)
Q21 times (sec):	12

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-5-3]
ok: [neu-3-2]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-7]
ok: [neu-3-11]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q22
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs21 -param reducers=1 -f queries/Q22.pig

59   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
60   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
875  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
985  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1600 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q22.pig-c568aae8-4637-46ae-9f47-33498652cd67
1600 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2596 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
2656 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2698 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2740 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $0, $2, $3, $4, $5, $6, $7, $8
2806 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2892 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
2919 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
2936 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
2952 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-141
2964 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 6
2964 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 map-reduce splittees.
2965 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 out of total 3 MR operators.
2965 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 5
3537 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3542 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3547 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3547 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3547 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3755 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1086680995/tmp-535699737/pig-0.17.0-core-h2.jar
3788 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1086680995/tmp770713332/automaton-1.11-8.jar
3802 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1086680995/tmp-427544470/antlr-runtime-3.4.jar
3830 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1086680995/tmp-87812554/joda-time-2.9.4.jar
3847 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up multi store job
3856 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3856 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3856 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
3960 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4170 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4464 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2520
4464 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases avg_customer_filter,customer,customer_filter,customer_filter_group
4464 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: customer[3,11],customer[-1,-1],customer_filter[6,18],avg_customer_filter[8,22],customer_filter_group[7,24] C: avg_customer_filter[8,22],customer_filter_group[7,24] R: avg_customer_filter[8,22]
4473 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9487 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9662 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9662 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9664 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:44:00	2019-01-28 11:44:06	HASH_JOIN,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2520	avg_customer_filter,customer,customer_filter,customer_filter_group	MULTI_QUERY,COMBINER	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/customer
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/customer
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/customer"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2520	->	null,
null	->	null,
null	->	null,
null	->	null,
null


9664 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9666 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9780 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 857 milliseconds (9857 ms)
Q22 times (sec):	12

Total times (sec):	260

Run Round1 times (sec):	611

Running Repeat #2 HDFS HDFS
Going to run:
/root/papers/KARIZ/expriments/benchmark/BenchmarkScripts/tpch/pig/run_tpch.sh /tpch/in /user/root/tpch/out_hdfs22 1 HDFS

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-3-2]
ok: [neu-5-3]
ok: [neu-5-1]
ok: [neu-5-6]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
changed: [neu-3-2]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q1
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs22 -param reducers=1 -f queries/Q1.pig

66   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
67   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
900  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1011 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1612 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q1.pig-a15ba691-8cec-476b-9799-f999d2490c5a
1612 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2572 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 3 time(s).
2573 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_CHARARRAY 1 time(s).
2617 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: GROUP_BY,ORDER_BY,FILTER
2668 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2705 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2757 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2872 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for LineItems: $0, $1, $2, $3, $11, $12, $13, $14, $15
2958 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
2997 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3032 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-109
3043 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 3
3043 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 3
3632 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3638 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3642 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3642 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3642 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3864 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1333224883/tmp1291088608/pig-0.17.0-core-h2.jar
3889 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1333224883/tmp102792075/automaton-1.11-8.jar
3905 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1333224883/tmp-148147288/antlr-runtime-3.4.jar
3922 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1333224883/tmp340606350/joda-time-2.9.4.jar
3939 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
3947 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3948 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3948 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4067 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4275 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4570 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2521
4570 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases LineItems,PriceSummary,StatusGroup,SubLine,SubLineItems
4570 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: LineItems[3,12],SubLineItems[4,15],LineItems[-1,-1],SubLine[6,10],PriceSummary[9,15],StatusGroup[8,14] C: PriceSummary[9,15],StatusGroup[8,14] R: PriceSummary[9,15]
4575 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9584 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9765 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9765 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9767 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:44:28	2019-01-28 11:44:34	GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2521	LineItems,PriceSummary,StatusGroup,SubLine,SubLineItems	GROUP_BY,COMBINER	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/lineitem"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2521	->	null,
null	->	null,
null


9767 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9769 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9788 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 972 milliseconds (9972 ms)
Q1 times (sec):	12

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-5-3]
ok: [neu-3-2]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-7]
ok: [neu-3-11]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-3]
changed: [neu-5-10]
changed: [neu-3-11]
changed: [neu-5-6]
changed: [neu-5-1]
changed: [neu-3-2]
changed: [neu-3-7]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q2
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs22 -param reducers=1 -f queries/Q2.pig

54   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
55   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
888  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1002 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1589 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q2.pig-12fff5cd-6e41-44ee-81e5-e6f9264bf915
1590 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2659 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_LONG 1 time(s).
2707 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,FILTER,LIMIT
2755 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2792 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2844 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
3009 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3082 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-217
3089 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3089 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3089 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3089 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3098 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 8
3098 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 8
4424 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
4430 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
4434 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
4434 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
4435 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4666 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp651165657/tmp2024035391/pig-0.17.0-core-h2.jar
4685 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp651165657/tmp-545752002/automaton-1.11-8.jar
4698 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp651165657/tmp1138009023/antlr-runtime-3.4.jar
4713 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp651165657/tmp22545768/joda-time-2.9.4.jar
4733 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4742 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4742 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4743 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4828 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
5026 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
5331 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2522
5331 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases FR_N,FRegion,Nation,Region
5331 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: Region[11,9],Region[-1,-1],FRegion[13,10],FR_N[14,7],Nation[9,9],Nation[-1,-1],FR_N[14,7] C:  R: 
5336 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
10346 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
10522 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
10522 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
10524 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:44:57	2019-01-28 11:45:03	HASH_JOIN,GROUP_BY,ORDER_BY,FILTER,LIMIT

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2522	FR_N,FRegion,Nation,Region	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/region
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/region
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/region"
Failed to read data from "/tpch/in/nation"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2522	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null


10524 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
10526 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
10545 [main] INFO  org.apache.pig.Main  - Pig script completed in 10 seconds and 725 milliseconds (10725 ms)
Q2 times (sec):	12

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-5-3]
ok: [neu-3-7]
ok: [neu-5-10]
ok: [neu-3-2]
ok: [neu-3-11]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q3
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs22 -param reducers=1 -f queries/Q3.pig

64   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
65   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
884  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
996  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1610 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q3.pig-6e9b6842-2475-46f0-9b66-5ee1c9621061
1610 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2563 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 1 time(s).
3238 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,FILTER,LIMIT
3287 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
3331 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
3384 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
3454 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $1, $2, $3, $4, $7, $8, $9, $11, $12, $13, $14, $15
3458 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $5, $6, $8
3459 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $1, $2, $3, $4, $5, $7
3551 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3591 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3623 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-135
3628 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3628 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3635 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 6
3635 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 6
4222 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
4228 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
4232 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
4232 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
4233 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4453 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1343901181/tmp37785771/pig-0.17.0-core-h2.jar
4472 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1343901181/tmp-21217836/automaton-1.11-8.jar
4486 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1343901181/tmp-598338400/antlr-runtime-3.4.jar
4501 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1343901181/tmp1458708269/joda-time-2.9.4.jar
4516 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4524 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4525 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4525 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4615 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4828 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
5119 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2523
5119 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases customer,fcustomer,forders,o1,orders,selo1
5119 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: customer[4,11],customer[-1,-1],fcustomer[11,12],fcustomer[-1,-1],o1[15,5],orders[6,9],orders[-1,-1],forders[12,10],o1[15,5] C:  R: selo1[16,8]
5125 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
10135 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
10300 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
10301 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
10303 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:45:26	2019-01-28 11:45:32	HASH_JOIN,GROUP_BY,ORDER_BY,FILTER,LIMIT

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2523	customer,fcustomer,forders,o1,orders,selo1	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/orders
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/orders
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/orders"
Failed to read data from "/tpch/in/customer"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2523	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null


10303 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
10305 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
10325 [main] INFO  org.apache.pig.Main  - Pig script completed in 10 seconds and 495 milliseconds (10495 ms)
Q3 times (sec):	12

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-3-2]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-5-3]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-3]
changed: [neu-5-10]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-5-1]
changed: [neu-3-7]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q4
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs22 -param reducers=1 -f queries/Q4.pig

61   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
62   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
886  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
995  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1600 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q4.pig-17afd06a-8d96-4212-bc7a-9fd9aaf91872
1600 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2469 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_CHARARRAY 2 time(s).
2470 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_LONG 1 time(s).
2512 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: COGROUP,GROUP_BY,ORDER_BY,FILTER
2560 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2595 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2650 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2724 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for LineItem: $1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $13, $14, $15
2809 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
2850 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
2878 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-82
2889 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 4
2890 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 4
3459 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3466 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3470 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3471 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3471 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3691 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1561917133/tmp2139991095/pig-0.17.0-core-h2.jar
3735 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1561917133/tmp1780513359/automaton-1.11-8.jar
3760 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1561917133/tmp-1838535712/antlr-runtime-3.4.jar
3780 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1561917133/tmp-2055570105/joda-time-2.9.4.jar
3796 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
3804 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3804 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3805 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
3902 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4110 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4406 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2524
4406 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases COG1,CommitDateFilter,CommitDateFilter0,DateFilter,Fil1,LineItem,Orders,OrdersCount
4406 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: Orders[3,9],DateFilter[7,13],Orders[-1,-1],COG1[11,7],LineItem[5,11],CommitDateFilter0[8,20],CommitDateFilter[-1,-1],COG1[11,7] C:  R: COG1[-1,-1],Fil1[12,7],OrdersCount[14,14]
4411 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9419 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9594 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9595 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9596 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:45:54	2019-01-28 11:46:00	COGROUP,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2524	COG1,CommitDateFilter,CommitDateFilter0,DateFilter,Fil1,LineItem,Orders,OrdersCount	COGROUP	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/lineitem"
Failed to read data from "/tpch/in/orders"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2524	->	null,
null	->	null,
null	->	null,
null


9596 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9598 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9617 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 793 milliseconds (9793 ms)
Q4 times (sec):	11

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-3-2]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-3]
changed: [neu-5-10]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q5
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs22 -param reducers=1 -f queries/Q5.pig

63   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
64   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
884  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
999  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1599 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q5.pig-2ea77c57-ccda-4ffc-8f54-9b104329493f
1599 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2655 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 1 time(s).
2698 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
2749 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2786 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2840 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2918 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $1, $2, $4, $5, $6, $7
2922 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $5, $6, $7, $8
2923 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $1, $3, $4, $7, $8, $9, $10, $11, $12, $13, $14, $15
2924 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $4, $5, $6
2924 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $3
2924 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for region: $2
3014 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3060 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3091 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-232
3095 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3096 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3096 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3096 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3096 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3103 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 8
3103 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 8
3692 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3697 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3702 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3702 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3703 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3904 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-780061231/tmp-537638893/pig-0.17.0-core-h2.jar
3935 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-780061231/tmp196121065/automaton-1.11-8.jar
3950 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-780061231/tmp-1067803726/antlr-runtime-3.4.jar
3977 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-780061231/tmp1979327380/joda-time-2.9.4.jar
3994 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4001 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4002 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4002 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4087 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4299 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4590 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2525
4590 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fregion,n1,nation,region,seln1
4590 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: nation[12,9],nation[-1,-1],n1[19,5],region[14,9],region[-1,-1],fregion[16,10],fregion[-1,-1],n1[19,5] C:  R: seln1[20,8]
4597 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9607 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9767 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9768 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9769 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:46:19	2019-01-28 11:46:25	HASH_JOIN,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2525	fregion,n1,nation,region,seln1	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/nation"
Failed to read data from "/tpch/in/region"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2525	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null


9770 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9771 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9790 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 961 milliseconds (9961 ms)
Q5 times (sec):	11

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-3-2]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-7]
ok: [neu-3-11]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q6
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs22 -param reducers=1 -f queries/Q6.pig

63   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
64   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
882  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
991  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1603 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q6.pig-5497f41d-c628-41cd-b43e-efb3be91ccf7
1604 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2431 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_CHARARRAY 2 time(s).
2431 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_INT 1 time(s).
2431 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 4 time(s).
2472 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: GROUP_BY,FILTER
2520 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2555 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2600 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $0, $1, $2, $3, $7, $8, $9, $11, $12, $13, $14, $15
2662 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2736 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
2753 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
2787 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 1
2788 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 1
3359 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3365 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3370 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3370 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3371 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3601 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-534897773/tmp682957123/pig-0.17.0-core-h2.jar
3626 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-534897773/tmp-381350122/automaton-1.11-8.jar
3649 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-534897773/tmp834477636/antlr-runtime-3.4.jar
3665 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-534897773/tmp1743235474/joda-time-2.9.4.jar
3680 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
3688 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3688 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3688 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
3783 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
3998 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4286 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2526
4286 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases flineitem,grpResult,lineitem,saving,sumResult
4287 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: lineitem[4,11],flineitem[7,12],saving[-1,-1],sumResult[11,12],grpResult[10,12] C: sumResult[11,12],grpResult[10,12] R: sumResult[11,12]
4294 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9306 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9476 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9476 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9478 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:46:43	2019-01-28 11:46:49	GROUP_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2526	flineitem,grpResult,lineitem,saving,sumResult	GROUP_BY,COMBINER	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	/user/root/tpch/out_hdfs22/Q6out,

Input(s):
Failed to read data from "/tpch/in/lineitem"

Output(s):
Failed to produce result in "/user/root/tpch/out_hdfs22/Q6out"

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2526


9478 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9482 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9501 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 674 milliseconds (9674 ms)
Q6 times (sec):	11

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-3-2]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-7]
ok: [neu-3-11]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-3]
changed: [neu-5-10]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q7
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs22 -param reducers=1 -f queries/Q7.pig

62   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
63   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
890  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1008 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1610 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q7.pig-06bfeae6-c9d4-40a3-a3ac-f78ae6775e59
1610 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2769 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 1 time(s).
2815 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
2866 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2910 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2963 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
3040 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $4, $5, $6, $7, $8
3045 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $1, $2, $4, $5, $6, $7
3046 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $4, $5, $6
3046 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem0: $1, $3, $4, $7, $8, $9, $11, $12, $13, $14, $15
3047 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation20: $2, $3
3047 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation10: $2, $3
3148 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3178 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 100
3179 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - Insert a file-concatenation job
3185 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 100
3186 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - Insert a file-concatenation job
3205 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3232 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-251
3236 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3237 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3237 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3244 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 10
3244 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 10
3837 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3842 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3847 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4057 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1879671728/tmp627166555/pig-0.17.0-core-h2.jar
4091 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1879671728/tmp-891027285/automaton-1.11-8.jar
4107 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1879671728/tmp1392063977/antlr-runtime-3.4.jar
4124 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1879671728/tmp1518142411/joda-time-2.9.4.jar
4140 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4148 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4148 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4148 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4195 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
4195 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
4196 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4230 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1879671728/tmp1679260461/pig-0.17.0-core-h2.jar
4242 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1879671728/tmp-1847137760/automaton-1.11-8.jar
4256 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1879671728/tmp1637518643/antlr-runtime-3.4.jar
4270 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1879671728/tmp1910719852/joda-time-2.9.4.jar
4272 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4273 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4273 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4273 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4291 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 2 map-reduce job(s) waiting for submission.
4503 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4545 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4795 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2527
4796 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases nation1,nation10
4796 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: nation10[12,11],nation10[-1,-1],nation1[16,10] C:  R: 
4801 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2528
4801 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases nation2,nation20
4801 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: nation20[14,11],nation20[-1,-1],nation2[17,10] C:  R: 
4804 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9818 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
10006 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
10016 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
10017 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 2 map reduce job(s) failed!
10019 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:47:08	2019-01-28 11:47:14	REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2527	nation1,nation10	MAP_ONLY	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	
job_1546715600715_2528	nation2,nation20	MAP_ONLY	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/nation"
Failed to read data from "/tpch/in/nation"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2527	->	null,
null	->	null,
null	->	null,
job_1546715600715_2528	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null


10019 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
10022 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
10042 [main] INFO  org.apache.pig.Main  - Pig script completed in 10 seconds and 229 milliseconds (10229 ms)
Q7 times (sec):	12

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-3-2]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-7]
ok: [neu-3-11]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q8
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs22 -param reducers=1 -f queries/Q8.pig

51   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
52   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
875  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
991  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
3605 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q8.pig-9e566de7-4090-49e8-81b2-09f21bd054cc
3606 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
4742 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 2 time(s).
4785 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
4833 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
4878 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
4932 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
5046 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $5, $6, $7, $8
5050 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $4, $5, $6
5051 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $3
5051 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $1, $2, $4, $5, $6, $7
5051 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for part: $1, $2, $3, $5, $6, $7, $8
5052 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $3, $4, $7, $8, $9, $10, $11, $12, $13, $14, $15
5052 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for region: $2
5176 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
5194 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 100
5196 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - Insert a file-concatenation job
5199 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 100
5200 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - Insert a file-concatenation job
5206 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 100
5206 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 0
5207 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - Insert a file-concatenation job
5225 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
5255 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-294
5260 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
5261 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
5261 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
5262 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
5271 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 14
5272 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 map-only splittees.
5272 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 out of total 3 MR operators.
5272 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 13
10765 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
10771 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
10776 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
10776 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
10776 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
11165 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1361572662/tmp-1525220495/pig-0.17.0-core-h2.jar
11183 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1361572662/tmp1685592541/automaton-1.11-8.jar
11197 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1361572662/tmp-1004493365/antlr-runtime-3.4.jar
11218 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1361572662/tmp695680140/joda-time-2.9.4.jar
11237 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
11245 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
11245 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
11245 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
11337 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
11338 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
11339 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
11374 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1361572662/tmp177177221/pig-0.17.0-core-h2.jar
11386 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1361572662/tmp-432581098/automaton-1.11-8.jar
11398 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1361572662/tmp521431176/antlr-runtime-3.4.jar
11412 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1361572662/tmp1630608454/joda-time-2.9.4.jar
11414 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
11414 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
11415 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
11415 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
11432 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
11433 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
11433 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
11481 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1361572662/tmp-837456356/pig-0.17.0-core-h2.jar
11493 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1361572662/tmp1964982605/automaton-1.11-8.jar
11504 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1361572662/tmp1649088241/antlr-runtime-3.4.jar
11561 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1361572662/tmp2043438714/joda-time-2.9.4.jar
11564 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up multi store job
11565 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
11565 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
11565 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
11580 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 3 map-reduce job(s) waiting for submission.
12661 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
12679 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2529
12679 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fpart,lineitem,p1,part
12679 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: lineitem[8,11],lineitem[-1,-1],p1[33,5],part[16,7],part[-1,-1],fpart[19,8],fpart[-1,-1],p1[33,5] C:  R: p1[-1,-1]
12703 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
12706 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2530
12706 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fregion,region
12706 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: region[14,9],region[-1,-1],fregion[17,10],fregion[-1,-1] C:  R: 
12731 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
12734 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2531
12734 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases nation
12734 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: nation[12,9],nation[-1,-1],nation[-1,-1] C:  R: 
12736 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
17750 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
20181 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
20188 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
20194 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
20194 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 3 map reduce job(s) failed!
20196 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:47:40	2019-01-28 11:47:50	REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2529	fpart,lineitem,p1,part	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/part
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/part
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	
job_1546715600715_2531	nation	MULTI_QUERY,MAP_ONLY	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	
job_1546715600715_2530	fregion,region	MAP_ONLY	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/region
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/region
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/part"
Failed to read data from "/tpch/in/lineitem"
Failed to read data from "/tpch/in/nation"
Failed to read data from "/tpch/in/region"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2529	->	null,
job_1546715600715_2531	->	null,null,
null	->	null,
null	->	null,
job_1546715600715_2530	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null


20197 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
20199 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
20218 [main] INFO  org.apache.pig.Main  - Pig script completed in 20 seconds and 389 milliseconds (20389 ms)
Q8 times (sec):	23

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-5-3]
ok: [neu-3-2]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-7]
ok: [neu-3-11]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-5-1]
changed: [neu-3-7]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q9
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs22 -param reducers=1 -f queries/Q9.pig

52   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
53   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
866  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
981  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
2785 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q9.pig-fb1f43c0-e06e-4ee9-8f12-f8615a2158da
2785 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
3928 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 1 time(s).
3972 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
4021 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
4083 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
4157 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
4274 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $1, $2, $3, $5, $6, $7, $8
4278 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for partsupp: $2, $4
4279 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $4, $5, $6
4279 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $2, $3
4280 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $3, $7, $8, $9, $10, $11, $12, $13, $14, $15
4280 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for part: $2, $3, $4, $5, $6, $7, $8
4388 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
4418 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 100
4418 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - Insert a file-concatenation job
4438 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
4468 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-246
4472 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
4472 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
4472 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
4473 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
4480 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 9
4480 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 9
14123 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
14129 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
14134 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
14134 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
14134 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
14359 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-24216328/tmp163658528/pig-0.17.0-core-h2.jar
14386 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-24216328/tmp171909877/automaton-1.11-8.jar
14400 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-24216328/tmp-1288421319/antlr-runtime-3.4.jar
14415 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-24216328/tmp-636473707/joda-time-2.9.4.jar
14432 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
14441 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
14441 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
14442 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
14533 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
14533 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
14534 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
14568 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-24216328/tmp-1438239769/pig-0.17.0-core-h2.jar
14581 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-24216328/tmp-1511300215/automaton-1.11-8.jar
14593 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-24216328/tmp-270227910/antlr-runtime-3.4.jar
14607 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-24216328/tmp1614582444/joda-time-2.9.4.jar
14609 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
14610 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
14610 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
14610 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
14626 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 2 map-reduce job(s) waiting for submission.
14836 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
14876 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
15131 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2532
15131 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fpart,j1,lineitem,part
15131 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: lineitem[8,11],lineitem[-1,-1],j1[22,5],part[18,7],part[-1,-1],fpart[20,8],fpart[-1,-1],j1[22,5] C:  R: j1[-1,-1]
15135 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2533
15135 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases nation
15135 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: nation[12,9],nation[-1,-1] C:  R: 
15138 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
20151 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
20485 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
20493 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
20493 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 2 map reduce job(s) failed!
20495 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:48:37	2019-01-28 11:48:44	REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2532	fpart,j1,lineitem,part	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	
job_1546715600715_2533	nation	MAP_ONLY	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/lineitem"
Failed to read data from "/tpch/in/part"
Failed to read data from "/tpch/in/nation"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2532	->	null,
job_1546715600715_2533	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null


20495 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
20497 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
20516 [main] INFO  org.apache.pig.Main  - Pig script completed in 20 seconds and 688 milliseconds (20688 ms)
Q9 times (sec):	23

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-2]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-3]
changed: [neu-5-10]
changed: [neu-3-2]
changed: [neu-3-11]
changed: [neu-5-6]
changed: [neu-5-1]
changed: [neu-3-7]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q10
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs22 -param reducers=1 -f queries/Q10.pig

65   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
66   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
891  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1008 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
2834 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q10.pig-925ea24d-6ea3-49c3-ba59-4abfac21530a
2834 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
3995 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 1 time(s).
4040 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,FILTER,LIMIT
4086 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
4129 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
4179 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
4253 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $1, $2, $3, $4, $7, $9, $10, $11, $12, $13, $14, $15
4257 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $2, $3
4257 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $6
4258 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $5, $6, $7, $8
4340 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
4379 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
4407 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-231
4412 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
4412 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
4412 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
4419 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 7
4419 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 7
8086 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
8092 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
8096 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
8096 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
8097 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
8287 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1166709694/tmp1561131212/pig-0.17.0-core-h2.jar
8325 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1166709694/tmp1646137665/automaton-1.11-8.jar
8340 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1166709694/tmp808483166/antlr-runtime-3.4.jar
8354 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1166709694/tmp-2026431411/joda-time-2.9.4.jar
8370 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
8378 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
8378 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
8379 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
8466 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
8658 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
8970 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2534
8970 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases c1,customer,forders,orders,selc1
8970 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: customer[4,11],customer[-1,-1],c1[24,5],orders[6,9],orders[-1,-1],forders[21,10],forders[-1,-1],c1[24,5] C:  R: selc1[25,8]
8976 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
13984 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
14971 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
14971 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
14973 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:49:29	2019-01-28 11:49:36	HASH_JOIN,GROUP_BY,ORDER_BY,FILTER,LIMIT

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2534	c1,customer,forders,orders,selc1	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/customer
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/customer
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/customer"
Failed to read data from "/tpch/in/orders"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2534	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null


14973 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
14975 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
15097 [main] INFO  org.apache.pig.Main  - Pig script completed in 15 seconds and 172 milliseconds (15172 ms)
Q10 times (sec):	21

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-5-3]
ok: [neu-3-2]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-7]
ok: [neu-3-11]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q11
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs22 -param reducers=1 -f queries/Q11.pig

60   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
61   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
925  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1042 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1700 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q11.pig-fcf6457b-b5b8-455c-a8a3-a8bd5586ae15
1700 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2672 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 1 time(s).
2721 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
2770 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2812 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2850 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for partsupp: $4
2854 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $4, $5, $6
2854 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $2, $3
2918 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2996 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3023 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3040 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3054 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-125
3059 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3059 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3067 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 6
3068 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 0 map-reduce splittees.
3068 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 0 out of total 3 MR operators.
3068 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 6
3639 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3645 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3649 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3649 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3650 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3856 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp787748354/tmp-2099673712/pig-0.17.0-core-h2.jar
3890 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp787748354/tmp1056616989/automaton-1.11-8.jar
3904 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp787748354/tmp-914597071/antlr-runtime-3.4.jar
3920 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp787748354/tmp-1627250774/joda-time-2.9.4.jar
3935 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
3943 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3943 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3944 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4032 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4237 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4536 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2535
4536 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fnation,j1,nation,selj1,supplier
4536 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: supplier[5,11],supplier[-1,-1],j1[11,5],nation[7,9],nation[-1,-1],fnation[9,10],fnation[-1,-1],j1[11,5] C:  R: selj1[13,8]
4542 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9550 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9703 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9704 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9705 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:49:59	2019-01-28 11:50:05	HASH_JOIN,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2535	fnation,j1,nation,selj1,supplier	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/nation"
Failed to read data from "/tpch/in/supplier"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2535	->	null,
null	->	null,null,
null	->	null,
null	->	null,
null	->	null,
null


9706 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9707 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9726 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 903 milliseconds (9903 ms)
Q11 times (sec):	12

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-3-2]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-5-3]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-3]
changed: [neu-5-10]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q12
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs22 -param reducers=1 -f queries/Q12.pig

60   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
61   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
908  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1029 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1629 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q12.pig-11f739d6-edcd-411d-87d2-1f33638a8771
1630 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2588 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
2639 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2676 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2718 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $1, $2, $3, $4, $6, $7, $8
2722 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $1, $2, $3, $4, $5, $6, $7, $8, $9, $13, $15
2783 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2865 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
2920 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-111
2925 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
2932 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 4
2932 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 4
3577 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3583 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3587 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3587 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3588 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3805 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp365688936/tmp1152674778/pig-0.17.0-core-h2.jar
3825 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp365688936/tmp-1240044509/automaton-1.11-8.jar
3841 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp365688936/tmp102458513/antlr-runtime-3.4.jar
3858 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp365688936/tmp365244187/joda-time-2.9.4.jar
3874 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
3882 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3882 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3882 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4006 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4218 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4510 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2536
4510 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases flineitem,l1,lineitem,orders,sell1
4511 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: orders[4,9],orders[-1,-1],l1[12,5],lineitem[6,11],lineitem[-1,-1],flineitem[8,12],flineitem[-1,-1],l1[12,5] C:  R: sell1[13,8]
4516 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9526 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9699 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9699 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9701 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:50:24	2019-01-28 11:50:30	HASH_JOIN,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2536	flineitem,l1,lineitem,orders,sell1	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/orders
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/orders
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/orders"
Failed to read data from "/tpch/in/lineitem"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2536	->	null,
null	->	null,
null	->	null,
null


9701 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9703 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9723 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 906 milliseconds (9906 ms)
Q12 times (sec):	11

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-3-2]
ok: [neu-5-3]
ok: [neu-5-1]
ok: [neu-5-6]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q13
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs22 -param reducers=1 -f queries/Q13.pig

56   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
57   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
872  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
981  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1554 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q13.pig-b86b5eed-8a27-4be1-bfab-0cf095676e7b
1555 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2434 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_LONG 1 time(s).
2475 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: COGROUP,GROUP_BY,ORDER_BY,FILTER
2526 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2562 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2617 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2682 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $1, $2, $3, $4, $5, $6, $7
2686 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $4, $5, $6, $7
2769 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
2811 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
2840 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-69
2852 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 4
2852 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 4
3441 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3446 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3451 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3451 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3451 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3660 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp645899807/tmp-263906408/pig-0.17.0-core-h2.jar
3676 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp645899807/tmp-1998741663/automaton-1.11-8.jar
3700 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp645899807/tmp1540582369/antlr-runtime-3.4.jar
3732 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp645899807/tmp-28895360/joda-time-2.9.4.jar
3748 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
3756 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3756 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3756 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
3850 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4062 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4354 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2537
4354 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases COG,COG1,COG2,customer,forders,orders,pcustomer,porders
4354 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: orders[5,9],orders[-1,-1],forders[7,10],porders[9,10],COG1[13,7],customer[3,11],pcustomer[-1,-1],COG1[13,7] C:  R: COG2[14,7],COG[15,6]
4359 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9370 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9550 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9550 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9552 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:50:49	2019-01-28 11:50:55	COGROUP,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2537	COG,COG1,COG2,customer,forders,orders,pcustomer,porders	COGROUP	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/customer
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/customer
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/customer"
Failed to read data from "/tpch/in/orders"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2537	->	null,
null	->	null,
null	->	null,
null


9552 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9554 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9573 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 741 milliseconds (9741 ms)
Q13 times (sec):	11

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-3-2]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-7]
ok: [neu-3-11]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q14
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs22 -param reducers=1 -f queries/Q14.pig

62   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
63   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
914  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1027 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1590 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q14.pig-22cb1338-92be-41b8-9fd5-08f709cec989
1591 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2518 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 2 time(s).
2574 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,FILTER
2625 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2662 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2715 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2807 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $0, $2, $3, $4, $7, $8, $9, $11, $12, $13, $14, $15
2902 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
2918 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 1
2924 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
2941 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
2959 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
2968 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 5
2969 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 map-only splittees.
2969 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 out of total 3 MR operators.
2971 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged MR job 130 into MR job 178
2971 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged MR job 132 into MR job 178
2972 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Requested parallelism of splitter: 1
2972 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 map-reduce splittees.
2972 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 out of total 3 MR operators.
2972 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 3
3549 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3555 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3560 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3560 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3560 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3782 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp2123362202/tmp1225589321/pig-0.17.0-core-h2.jar
3801 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp2123362202/tmp-2019004868/automaton-1.11-8.jar
3822 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp2123362202/tmp-650513391/antlr-runtime-3.4.jar
3838 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp2123362202/tmp723433313/joda-time-2.9.4.jar
3853 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
3861 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3861 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3862 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
3956 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4159 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4459 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2538
4460 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases filtered_lineitem,lineitem,lineitem2,lineitem_part,part
4460 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: lineitem[3,11],lineitem[-1,-1],filtered_lineitem[7,20],lineitem2[8,12],lineitem_part[10,16],part[5,7],part[-1,-1],lineitem_part[10,16] C:  R: 
4466 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9477 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9649 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9650 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9652 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:51:13	2019-01-28 11:51:20	HASH_JOIN,GROUP_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2538	filtered_lineitem,lineitem,lineitem2,lineitem_part,part	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/part
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/part
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/part"
Failed to read data from "/tpch/in/lineitem"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2538	->	null,
null	->	null,
null


9652 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9654 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9683 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 847 milliseconds (9847 ms)
Q14 times (sec):	12

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-3-2]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-5-1]
changed: [neu-3-7]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q15
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs22 -param reducers=1 -f queries/Q15.pig

60   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
61   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
895  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1007 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1569 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q15.pig-05553480-ed68-47a3-9af9-29ad17b0ff4c
1569 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2512 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 1 time(s).
2571 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
2635 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2693 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2763 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2844 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $3, $5, $6
2848 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $0, $1, $3, $4, $7, $8, $9, $11, $12, $13, $14, $15
2937 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
2965 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
2983 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
2997 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-116
3002 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3014 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 5
3015 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 0 map-reduce splittees.
3015 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 0 out of total 3 MR operators.
3015 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 5
3642 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3648 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3653 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3653 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3653 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3863 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-239714624/tmp-286700858/pig-0.17.0-core-h2.jar
3904 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-239714624/tmp1311596031/automaton-1.11-8.jar
3919 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-239714624/tmp-1708297953/antlr-runtime-3.4.jar
3935 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-239714624/tmp-1998817382/joda-time-2.9.4.jar
3951 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
3959 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3959 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3959 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4064 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4274 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4568 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2539
4568 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases flineitem,glineitem,lineitem,revenue,sumlineitem
4568 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: lineitem[3,11],lineitem[-1,-1],flineitem[7,12],sumlineitem[9,14],revenue[13,10],glineitem[11,12] C: revenue[13,10],glineitem[11,12] R: revenue[13,10]
4573 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9581 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9781 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9781 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9784 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:51:38	2019-01-28 11:51:45	HASH_JOIN,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2539	flineitem,glineitem,lineitem,revenue,sumlineitem	GROUP_BY,COMBINER	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/lineitem"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2539	->	null,null,
null	->	null,
null	->	null,
null	->	null,
null


9784 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9787 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9806 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 977 milliseconds (9977 ms)
Q15 times (sec):	12

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-3-2]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q16
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs22 -param reducers=1 -f queries/Q16.pig

62   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
63   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
881  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
994  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1619 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q16.pig-dc58241f-8367-4268-a918-f6b05767a27e
1619 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2559 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_CHARARRAY 4 time(s).
2614 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
2663 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2700 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2747 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for parts: $1, $2, $6, $7, $8
2751 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for partsupp: $2, $3, $4
2751 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $3, $4, $5
2807 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2887 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
2932 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
2965 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-113
2969 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
2970 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
2977 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 5
2977 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 5
3554 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3560 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3565 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3565 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3565 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3783 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp567953448/tmp-243225261/pig-0.17.0-core-h2.jar
3811 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp567953448/tmp-1774028308/automaton-1.11-8.jar
3825 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp567953448/tmp1993565320/antlr-runtime-3.4.jar
3842 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp567953448/tmp681607591/joda-time-2.9.4.jar
3857 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
3865 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3865 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3866 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
3959 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4160 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4462 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2540
4462 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fpartsupp,fs1,fsupplier,partsupp,pss,supplier
4462 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: supplier[17,11],fsupplier[19,12],fs1[-1,-1],pss[22,6],partsupp[15,11],partsupp[-1,-1],pss[22,6] C:  R: fpartsupp[24,12]
4468 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9479 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9662 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9663 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9664 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:52:03	2019-01-28 11:52:09	HASH_JOIN,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2540	fpartsupp,fs1,fsupplier,partsupp,pss,supplier	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/partsupp
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/partsupp
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/partsupp"
Failed to read data from "/tpch/in/supplier"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2540	->	null,
null	->	null,
null	->	null,
null	->	null,
null


9664 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9666 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9685 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 857 milliseconds (9857 ms)
Q16 times (sec):	12

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-3-2]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-7]
ok: [neu-3-11]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q17
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs22 -param reducers=1 -f queries/Q17.pig

60   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
61   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
880  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
999  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1628 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q17.pig-5afd625c-0db6-4bef-9c22-a97f643c2f0e
1628 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2574 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 1 time(s).
2575 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_LONG 1 time(s).
2624 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: COGROUP,GROUP_BY,FILTER
2689 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2747 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2811 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2879 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $0, $2, $3, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15
2883 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for part: $1, $2, $4, $5, $7, $8
2968 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3002 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3041 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 2
3041 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 2
3607 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3613 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3618 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3618 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3618 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3830 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp772111915/tmp-620867953/pig-0.17.0-core-h2.jar
3847 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp772111915/tmp-192812915/automaton-1.11-8.jar
3875 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp772111915/tmp-922303059/antlr-runtime-3.4.jar
3905 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp772111915/tmp1349742862/joda-time-2.9.4.jar
3921 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
3929 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3929 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3929 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4032 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4265 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4536 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2541
4536 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases COG,COG1,COG2,COG3,lineitem,part
4536 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: part[5,7],part[-1,-1],part[8,7],part[9,7],COG1[11,7],lineitem[3,11],lineitem[-1,-1],COG1[11,7] C:  R: COG1[-1,-1],COG1[12,7],COG2[13,7],COG3[15,7],COG[16,6]
4541 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9551 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9708 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9708 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9710 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:52:28	2019-01-28 11:52:34	COGROUP,GROUP_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2541	COG,COG1,COG2,COG3,lineitem,part	COGROUP	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/lineitem"
Failed to read data from "/tpch/in/part"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2541	->	null,
null


9710 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9712 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9733 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 905 milliseconds (9905 ms)
Q17 times (sec):	11

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-3-2]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q18
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs22 -param reducers=1 -f queries/Q18.pig

64   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
65   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
896  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1009 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1629 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q18.pig-e5284de4-8fd8-41af-98d3-efd6a1f6c3ef
1630 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2656 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 1 time(s).
2703 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,COGROUP,GROUP_BY,ORDER_BY,FILTER
2755 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2798 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2854 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2926 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $1, $2, $3, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15
2930 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $5, $6, $7, $8
3014 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3055 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3087 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-132
3092 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3099 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 5
3099 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 5
3667 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3673 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3678 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3678 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3678 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3911 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp19508504/tmp-615904059/pig-0.17.0-core-h2.jar
3929 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp19508504/tmp759714282/automaton-1.11-8.jar
3945 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp19508504/tmp1455387395/antlr-runtime-3.4.jar
3962 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp19508504/tmp64045753/joda-time-2.9.4.jar
3979 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
3987 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3987 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3988 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4081 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4281 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4585 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2542
4585 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases COG,lineitem,lineitem_orders,orders
4585 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: lineitem[3,11],lineitem[-1,-1],COG[11,6],orders[7,9],orders[-1,-1],COG[11,6] C:  R: COG[-1,-1],COG[13,6],lineitem_orders[15,18]
4592 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9602 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9796 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9796 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9798 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:52:53	2019-01-28 11:52:59	HASH_JOIN,COGROUP,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2542	COG,lineitem,lineitem_orders,orders	COGROUP	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/lineitem"
Failed to read data from "/tpch/in/orders"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2542	->	null,
null	->	null,
null	->	null,
null	->	null,
null


9798 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9800 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9820 [main] INFO  org.apache.pig.Main  - Pig script completed in 10 seconds and 4 milliseconds (10004 ms)
Q18 times (sec):	11

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-3-2]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q19
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs22 -param reducers=1 -f queries/Q19.pig

61   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
62   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
880  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
994  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1555 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q19.pig-61143502-b681-478c-bfe8-8e1f5ddbabf2
1555 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2470 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_LONG 6 time(s).
2471 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 7 time(s).
2516 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,FILTER
2564 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2606 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2660 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
3000 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $0, $2, $3, $7, $8, $9, $10, $11, $12, $15
3004 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for part: $1, $2, $4, $7, $8
3086 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3117 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3150 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3156 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 2
3156 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 2
3742 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3748 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3753 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3753 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3753 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3967 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1679932293/tmp-497518850/pig-0.17.0-core-h2.jar
3991 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1679932293/tmp615505921/automaton-1.11-8.jar
4005 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1679932293/tmp-1792880688/antlr-runtime-3.4.jar
4021 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1679932293/tmp1182949603/joda-time-2.9.4.jar
4038 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4046 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4046 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4046 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4163 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4354 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4666 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2543
4666 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fltResult,lineitem,lpart,part,volume
4666 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: part[6,7],part[-1,-1],lpart[8,8],lineitem[4,11],lineitem[-1,-1],lpart[8,8] C:  R: lpart[-1,-1],fltResult[10,12],volume[37,9]
4671 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9679 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9845 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9845 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9847 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:53:18	2019-01-28 11:53:24	HASH_JOIN,GROUP_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2543	fltResult,lineitem,lpart,part,volume	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/lineitem"
Failed to read data from "/tpch/in/part"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2543	->	null,
null


9847 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9849 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9868 [main] INFO  org.apache.pig.Main  - Pig script completed in 10 seconds and 39 milliseconds (10039 ms)
Q19 times (sec):	11

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-3-2]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-3]
changed: [neu-5-10]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q20
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs22 -param reducers=1 -f queries/Q20.pig

61   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
62   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
916  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1045 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1648 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q20.pig-9e7a74a8-1774-4b39-9e68-a8dedeb9ee35
1648 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2829 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 1 time(s).
2880 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,DISTINCT,FILTER
2929 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2974 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
3023 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $4, $5, $6
3027 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $2, $3
3027 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for partsupp: $3, $4
3028 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $0, $3, $5, $6, $7, $8, $9, $11, $12, $13, $14, $15
3029 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for part: $2, $3, $4, $5, $6, $7, $8
3092 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
3175 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3220 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3248 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-233
3252 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3252 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3253 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3253 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3260 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 9
3260 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 9
3869 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3875 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3880 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3880 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3880 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4111 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1037213649/tmp1190651553/pig-0.17.0-core-h2.jar
4134 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1037213649/tmp-796518206/automaton-1.11-8.jar
4149 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1037213649/tmp-1920866558/antlr-runtime-3.4.jar
4164 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1037213649/tmp-641524230/joda-time-2.9.4.jar
4182 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4191 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4191 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4192 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4283 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
4283 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
4284 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
4284 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
4284 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4321 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1037213649/tmp-634353928/pig-0.17.0-core-h2.jar
4335 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1037213649/tmp-286902389/automaton-1.11-8.jar
4346 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1037213649/tmp-1613773755/antlr-runtime-3.4.jar
4360 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1037213649/tmp904614877/joda-time-2.9.4.jar
4362 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4363 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4363 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4363 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4392 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
4393 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
4394 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
4394 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
4394 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4423 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1037213649/tmp1412949361/pig-0.17.0-core-h2.jar
4437 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1037213649/tmp-1888928431/automaton-1.11-8.jar
4449 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1037213649/tmp679633836/antlr-runtime-3.4.jar
4463 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1037213649/tmp1740390041/joda-time-2.9.4.jar
4466 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4466 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4466 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4466 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4467 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting identity combiner class.
4482 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 3 map-reduce job(s) waiting for submission.
4683 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4725 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4750 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4988 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2544
4988 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases lineitem,lineitem1,lineitem2,lineitem3,lineitem4
4988 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: lineitem[9,11],lineitem[-1,-1],lineitem2[11,12],lineitem1[10,12],lineitem4[13,12],lineitem3[12,12] C: lineitem4[13,12],lineitem3[12,12] R: lineitem4[13,12]
4992 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2545
4993 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases nation,nation1,s_n,supplier
4993 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: supplier[26,11],supplier[-1,-1],s_n[28,6],nation[23,9],nation[-1,-1],nation1[24,10],nation1[-1,-1],s_n[28,6] C:  R: s_n[-1,-1]
4996 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2546
4997 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases part,part2,part3
4997 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: part[3,7],part[-1,-1],part2[5,8],part3[-1,-1] C:  R: 
5000 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
10016 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
10259 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
10266 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
10271 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
10272 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 3 map reduce job(s) failed!
10273 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:53:43	2019-01-28 11:53:49	HASH_JOIN,GROUP_BY,ORDER_BY,DISTINCT,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2544	lineitem,lineitem1,lineitem2,lineitem3,lineitem4	GROUP_BY,COMBINER	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	
job_1546715600715_2546	part,part2,part3	DISTINCT	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/part
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/part
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	
job_1546715600715_2545	nation,nation1,s_n,supplier	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/lineitem"
Failed to read data from "/tpch/in/part"
Failed to read data from "/tpch/in/nation"
Failed to read data from "/tpch/in/supplier"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2544	->	null,
job_1546715600715_2546	->	null,
null	->	null,
null	->	null,
null	->	null,
job_1546715600715_2545	->	null,
null	->	null,
null	->	null,
null


10274 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
10276 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
10295 [main] INFO  org.apache.pig.Main  - Pig script completed in 10 seconds and 482 milliseconds (10482 ms)
Q20 times (sec):	12

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-5-3]
ok: [neu-3-2]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-7]
ok: [neu-3-11]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-3]
changed: [neu-5-10]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q21
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs22 -param reducers=1 -f queries/Q21.pig

60   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
62   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
882  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1003 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1591 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q21.pig-38416bc3-5f8b-457a-9ea3-85220a06114a
1591 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2654 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_LONG 2 time(s).
2709 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER,LIMIT
2757 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2801 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2854 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2963 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $1, $3, $4, $5, $6, $7, $8, $9, $10, $13, $14, $15
2967 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $1, $3, $4, $5, $6, $7, $8
2968 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $2, $4, $5, $6
3076 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3096 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 100
3097 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - Insert a file-concatenation job
3118 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3153 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-172
3158 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3159 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3169 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 10
3170 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 map-only splittees.
3170 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 out of total 3 MR operators.
3170 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 9
3756 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3761 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3766 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3766 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3767 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3975 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-211890341/tmp-1010497791/pig-0.17.0-core-h2.jar
4003 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-211890341/tmp1594484280/automaton-1.11-8.jar
4017 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-211890341/tmp-295446949/antlr-runtime-3.4.jar
4034 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-211890341/tmp-381192218/joda-time-2.9.4.jar
4051 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up multi store job
4059 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4059 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4059 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4153 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
4154 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
4155 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4187 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-211890341/tmp1189364314/pig-0.17.0-core-h2.jar
4203 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-211890341/tmp-616099968/automaton-1.11-8.jar
4214 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-211890341/tmp-1665711626/antlr-runtime-3.4.jar
4228 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-211890341/tmp804377210/joda-time-2.9.4.jar
4230 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4232 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4232 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4232 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4250 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 2 map-reduce job(s) waiting for submission.
4455 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4495 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4754 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2547
4755 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases L2,fL2,gl,lineitem,t1
4755 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: lineitem[5,11],lineitem[-1,-1],gl[16,5] C:  R: L2[18,5],fL2[20,6],t1[21,13]
4760 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2548
4761 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fn,nation
4761 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: nation[9,9],nation[-1,-1],fn[33,5] C:  R: 
4764 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9776 [main] INFO  org.apache.pig.tools.pigstats.JobStats  - using output size reader: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.FileBasedOutputSizeReader
9786 [main] WARN  org.apache.pig.tools.pigstats.JobStats  - unable to find the output file
java.io.FileNotFoundException: File /user/root/tpch/out_hdfs22/Q21_fL2_fL2 does not exist.
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:904)
	at org.apache.hadoop.hdfs.DistributedFileSystem.access$600(DistributedFileSystem.java:114)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:964)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:961)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:961)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.FileBasedOutputSizeReader.getPathSize(FileBasedOutputSizeReader.java:84)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.FileBasedOutputSizeReader.getOutputSize(FileBasedOutputSizeReader.java:79)
	at org.apache.pig.tools.pigstats.JobStats.getOutputSize(JobStats.java:351)
	at org.apache.pig.tools.pigstats.mapreduce.MRJobStats.addOneOutputStats(MRJobStats.java:464)
	at org.apache.pig.tools.pigstats.mapreduce.MRJobStats.addOutputStatistics(MRJobStats.java:450)
	at org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil.addFailedJobStats(MRPigStatsUtil.java:196)
	at org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil.accumulateStats(MRPigStatsUtil.java:171)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher.launchPig(MapReduceLauncher.java:379)
	at org.apache.pig.backend.hadoop.executionengine.HExecutionEngine.launchPig(HExecutionEngine.java:290)
	at org.apache.pig.PigServer.launchPlan(PigServer.java:1475)
	at org.apache.pig.PigServer.executeCompiledLogicalPlan(PigServer.java:1460)
	at org.apache.pig.PigServer.execute(PigServer.java:1449)
	at org.apache.pig.PigServer.executeBatch(PigServer.java:489)
	at org.apache.pig.PigServer.executeBatch(PigServer.java:472)
	at org.apache.pig.tools.grunt.GruntParser.executeBatch(GruntParser.java:171)
	at org.apache.pig.tools.grunt.GruntParser.processFsCommand(GruntParser.java:1168)
	at org.apache.pig.tools.pigscript.parser.PigScriptParser.parse(PigScriptParser.java:136)
	at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:230)
	at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:205)
	at org.apache.pig.tools.grunt.Grunt.exec(Grunt.java:81)
	at org.apache.pig.Main.run(Main.java:500)
	at org.apache.pig.Main.main(Main.java:175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:234)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:148)
9795 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
10025 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
10034 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
10034 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 2 map reduce job(s) failed!
10036 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:54:08	2019-01-28 11:54:14	REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER,LIMIT

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2547	L2,fL2,gl,lineitem,t1	GROUP_BY,MULTI_QUERY	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	/user/root/tpch/out_hdfs22/Q21_fL2_fL2,
job_1546715600715_2548	fn,nation	MAP_ONLY	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/lineitem"
Failed to read data from "/tpch/in/nation"

Output(s):
Failed to produce result in "/user/root/tpch/out_hdfs22/Q21_fL2_fL2"

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2547	->	null,
job_1546715600715_2548	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null


10036 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
10039 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
10058 [main] INFO  org.apache.pig.Main  - Pig script completed in 10 seconds and 229 milliseconds (10229 ms)
Q21 times (sec):	11

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-3-2]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-3]
changed: [neu-5-10]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q22
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs22 -param reducers=1 -f queries/Q22.pig

52   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
52   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
872  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
984  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1571 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q22.pig-c1f7bad7-5836-4940-ad93-6913a8a42dcf
1572 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2561 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
2612 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2648 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2696 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $0, $2, $3, $4, $5, $6, $7, $8
2781 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2886 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
2917 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
2934 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
2950 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-141
2966 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 6
2967 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 map-reduce splittees.
2967 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 out of total 3 MR operators.
2967 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 5
3543 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3549 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3553 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3553 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3554 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3761 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-5967730/tmp-1115230453/pig-0.17.0-core-h2.jar
3789 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-5967730/tmp-1632669776/automaton-1.11-8.jar
3804 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-5967730/tmp-1936152779/antlr-runtime-3.4.jar
3836 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-5967730/tmp1633456989/joda-time-2.9.4.jar
3852 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up multi store job
3860 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3860 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3861 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
3961 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4170 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4464 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2549
4464 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases avg_customer_filter,customer,customer_filter,customer_filter_group
4464 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: customer[3,11],customer[-1,-1],customer_filter[6,18],avg_customer_filter[8,22],customer_filter_group[7,24] C: avg_customer_filter[8,22],customer_filter_group[7,24] R: avg_customer_filter[8,22]
4471 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9484 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9644 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9644 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9646 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:54:33	2019-01-28 11:54:39	HASH_JOIN,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2549	avg_customer_filter,customer,customer_filter,customer_filter_group	MULTI_QUERY,COMBINER	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/customer
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/customer
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/customer"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2549	->	null,
null	->	null,
null	->	null,
null	->	null,
null


9646 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9648 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9763 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 839 milliseconds (9839 ms)
Q22 times (sec):	11

Total times (sec):	285

Run Round2 times (sec):	632

Running Repeat #3 HDFS HDFS
Going to run:
/root/papers/KARIZ/expriments/benchmark/BenchmarkScripts/tpch/pig/run_tpch.sh /tpch/in /user/root/tpch/out_hdfs23 1 HDFS

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-2]
ok: [neu-3-7]
ok: [neu-3-11]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q1
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs23 -param reducers=1 -f queries/Q1.pig

66   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
67   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
894  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1005 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1602 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q1.pig-cdaaf1e4-d1e2-4ae5-a250-2cf4d2f1fd0b
1602 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2507 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 3 time(s).
2508 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_CHARARRAY 1 time(s).
2552 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: GROUP_BY,ORDER_BY,FILTER
2604 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2647 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2702 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2817 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for LineItems: $0, $1, $2, $3, $11, $12, $13, $14, $15
2905 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
2945 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
2983 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-109
2995 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 3
2995 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 3
3595 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3601 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3606 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3606 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3606 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3828 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1939943556/tmp244628578/pig-0.17.0-core-h2.jar
3854 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1939943556/tmp-886776665/automaton-1.11-8.jar
3867 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1939943556/tmp225251260/antlr-runtime-3.4.jar
3882 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1939943556/tmp-1078906431/joda-time-2.9.4.jar
3898 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
3906 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3906 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3906 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4029 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4236 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4532 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2550
4532 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases LineItems,PriceSummary,StatusGroup,SubLine,SubLineItems
4532 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: LineItems[3,12],SubLineItems[4,15],LineItems[-1,-1],SubLine[6,10],PriceSummary[9,15],StatusGroup[8,14] C: PriceSummary[9,15],StatusGroup[8,14] R: PriceSummary[9,15]
4536 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9544 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9702 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9702 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9703 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:54:58	2019-01-28 11:55:04	GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2550	LineItems,PriceSummary,StatusGroup,SubLine,SubLineItems	GROUP_BY,COMBINER	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/lineitem"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2550	->	null,
null	->	null,
null


9704 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9705 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9724 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 903 milliseconds (9903 ms)
Q1 times (sec):	11

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-3-2]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-3-11]
ok: [neu-3-7]
ok: [neu-5-1]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q2
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs23 -param reducers=1 -f queries/Q2.pig

59   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
60   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
904  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1025 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1604 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q2.pig-235a2d04-1a49-4263-8b78-95eb9c74face
1604 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2639 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_LONG 1 time(s).
2684 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,FILTER,LIMIT
2733 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2776 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2832 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2989 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3061 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-217
3067 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3067 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3067 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3067 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3075 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 8
3075 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 8
3648 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3654 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3659 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3659 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3659 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3897 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1106503016/tmp891965122/pig-0.17.0-core-h2.jar
3921 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1106503016/tmp1676667248/automaton-1.11-8.jar
3962 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1106503016/tmp224244139/antlr-runtime-3.4.jar
3977 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1106503016/tmp1113918579/joda-time-2.9.4.jar
3995 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4004 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4004 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4004 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4089 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4300 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4593 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2551
4593 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases FR_N,FRegion,Nation,Region
4593 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: Region[11,9],Region[-1,-1],FRegion[13,10],FR_N[14,7],Nation[9,9],Nation[-1,-1],FR_N[14,7] C:  R: 
4598 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9606 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9777 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9778 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9780 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:55:26	2019-01-28 11:55:32	HASH_JOIN,GROUP_BY,ORDER_BY,FILTER,LIMIT

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2551	FR_N,FRegion,Nation,Region	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/region
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/region
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/region"
Failed to read data from "/tpch/in/nation"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2551	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null


9780 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9782 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9801 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 972 milliseconds (9972 ms)
Q2 times (sec):	11

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-5-3]
ok: [neu-3-2]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q3
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs23 -param reducers=1 -f queries/Q3.pig

59   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
60   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
887  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
998  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1600 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q3.pig-d1398ba3-341b-408b-b46e-e9c847bd74f9
1600 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2548 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 1 time(s).
2588 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,FILTER,LIMIT
2639 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2684 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2739 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2809 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $1, $2, $3, $4, $7, $8, $9, $11, $12, $13, $14, $15
2813 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $5, $6, $8
2814 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $1, $2, $3, $4, $5, $7
2902 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
2947 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
2979 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-135
2983 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
2984 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
2992 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 6
2992 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 6
3581 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3586 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3591 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3591 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3591 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3802 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-96923573/tmp1814332399/pig-0.17.0-core-h2.jar
3828 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-96923573/tmp-688852040/automaton-1.11-8.jar
3842 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-96923573/tmp-1627132657/antlr-runtime-3.4.jar
3860 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-96923573/tmp-1500019949/joda-time-2.9.4.jar
3876 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
3884 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3884 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3884 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
3972 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4169 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4475 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2552
4475 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases customer,fcustomer,forders,o1,orders,selo1
4475 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: customer[4,11],customer[-1,-1],fcustomer[11,12],fcustomer[-1,-1],o1[15,5],orders[6,9],orders[-1,-1],forders[12,10],o1[15,5] C:  R: selo1[16,8]
4481 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9491 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9651 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9651 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9653 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:55:51	2019-01-28 11:55:57	HASH_JOIN,GROUP_BY,ORDER_BY,FILTER,LIMIT

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2552	customer,fcustomer,forders,o1,orders,selo1	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/orders
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/orders
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/orders"
Failed to read data from "/tpch/in/customer"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2552	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null


9653 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9655 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9673 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 845 milliseconds (9845 ms)
Q3 times (sec):	11

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-3-2]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-3]
changed: [neu-5-10]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q4
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs23 -param reducers=1 -f queries/Q4.pig

61   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
62   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
883  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
993  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1557 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q4.pig-88354139-7303-4f20-a88f-8b88135de315
1558 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2440 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_CHARARRAY 2 time(s).
2440 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_LONG 1 time(s).
2485 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: COGROUP,GROUP_BY,ORDER_BY,FILTER
2536 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2583 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2638 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2712 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for LineItem: $1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $13, $14, $15
2797 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
2839 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
2868 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-82
2880 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 4
2880 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 4
3479 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3484 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3489 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3489 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3490 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3690 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp172240276/tmp-1283960206/pig-0.17.0-core-h2.jar
3720 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp172240276/tmp-1414352654/automaton-1.11-8.jar
3735 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp172240276/tmp-2087251879/antlr-runtime-3.4.jar
3759 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp172240276/tmp2107751361/joda-time-2.9.4.jar
3775 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
3784 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3784 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3784 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
3877 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4082 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4380 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2553
4380 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases COG1,CommitDateFilter,CommitDateFilter0,DateFilter,Fil1,LineItem,Orders,OrdersCount
4380 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: Orders[3,9],DateFilter[7,13],Orders[-1,-1],COG1[11,7],LineItem[5,11],CommitDateFilter0[8,20],CommitDateFilter[-1,-1],COG1[11,7] C:  R: COG1[-1,-1],Fil1[12,7],OrdersCount[14,14]
4386 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9394 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9560 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9560 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9562 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:56:16	2019-01-28 11:56:22	COGROUP,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2553	COG1,CommitDateFilter,CommitDateFilter0,DateFilter,Fil1,LineItem,Orders,OrdersCount	COGROUP	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/lineitem"
Failed to read data from "/tpch/in/orders"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2553	->	null,
null	->	null,
null	->	null,
null


9562 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9564 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9582 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 753 milliseconds (9753 ms)
Q4 times (sec):	11

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-3-2]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q5
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs23 -param reducers=1 -f queries/Q5.pig

60   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
61   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
878  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
998  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1557 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q5.pig-94c89d5a-4cc9-4ca6-96a2-cd36560b2f62
1557 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2650 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 1 time(s).
2693 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
2743 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2787 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2840 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2924 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $1, $2, $4, $5, $6, $7
2928 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $5, $6, $7, $8
2929 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $1, $3, $4, $7, $8, $9, $10, $11, $12, $13, $14, $15
2929 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $4, $5, $6
2929 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $3
2930 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for region: $2
3020 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3065 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3095 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-232
3099 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3099 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3100 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3100 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3100 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3107 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 8
3107 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 8
3716 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3724 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3730 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3731 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3731 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3931 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1183831026/tmp342685804/pig-0.17.0-core-h2.jar
3947 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1183831026/tmp950836953/automaton-1.11-8.jar
3967 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1183831026/tmp-1411771345/antlr-runtime-3.4.jar
3983 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1183831026/tmp1443068647/joda-time-2.9.4.jar
4001 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4010 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4011 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4011 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4094 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4322 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4597 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2554
4598 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fregion,n1,nation,region,seln1
4598 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: nation[12,9],nation[-1,-1],n1[19,5],region[14,9],region[-1,-1],fregion[16,10],fregion[-1,-1],n1[19,5] C:  R: seln1[20,8]
4602 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9611 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9791 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9791 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9793 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:56:40	2019-01-28 11:56:46	HASH_JOIN,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2554	fregion,n1,nation,region,seln1	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/nation"
Failed to read data from "/tpch/in/region"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2554	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null


9793 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9795 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9814 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 985 milliseconds (9985 ms)
Q5 times (sec):	12

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-5-3]
ok: [neu-3-2]
ok: [neu-5-6]
ok: [neu-3-11]
ok: [neu-3-7]
ok: [neu-5-1]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q6
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs23 -param reducers=1 -f queries/Q6.pig

62   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
63   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
886  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
994  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1566 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q6.pig-3d091ba4-64b4-4d45-b6b2-b2daa5ea0ec9
1566 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2437 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_CHARARRAY 2 time(s).
2438 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_INT 1 time(s).
2438 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 4 time(s).
2475 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: GROUP_BY,FILTER
2528 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2570 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2617 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $0, $1, $2, $3, $7, $8, $9, $11, $12, $13, $14, $15
2680 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2755 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
2772 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
2809 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 1
2810 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 1
3400 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3408 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3413 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3413 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3413 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3618 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-559570602/tmp1011637505/pig-0.17.0-core-h2.jar
3636 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-559570602/tmp210065922/automaton-1.11-8.jar
3659 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-559570602/tmp191856254/antlr-runtime-3.4.jar
3677 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-559570602/tmp1485734910/joda-time-2.9.4.jar
3691 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
3699 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3699 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3699 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
3790 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4002 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4293 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2555
4294 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases flineitem,grpResult,lineitem,saving,sumResult
4294 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: lineitem[4,11],flineitem[7,12],saving[-1,-1],sumResult[11,12],grpResult[10,12] C: sumResult[11,12],grpResult[10,12] R: sumResult[11,12]
4298 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9311 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9486 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9486 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9487 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:57:20	2019-01-28 11:57:26	GROUP_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2555	flineitem,grpResult,lineitem,saving,sumResult	GROUP_BY,COMBINER	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	/user/root/tpch/out_hdfs23/Q6out,

Input(s):
Failed to read data from "/tpch/in/lineitem"

Output(s):
Failed to produce result in "/user/root/tpch/out_hdfs23/Q6out"

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2555


9488 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9492 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9510 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 686 milliseconds (9686 ms)
Q6 times (sec):	11

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-5-3]
ok: [neu-3-2]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q7
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs23 -param reducers=1 -f queries/Q7.pig

70   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
71   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
887  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1003 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1572 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q7.pig-638b2dbe-7fb4-4e37-8838-f21635d10407
1572 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2759 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 1 time(s).
2815 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
2879 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2941 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
3016 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
3126 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $4, $5, $6, $7, $8
3131 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $1, $2, $4, $5, $6, $7
3131 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $4, $5, $6
3132 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem0: $1, $3, $4, $7, $8, $9, $11, $12, $13, $14, $15
3133 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation20: $2, $3
3133 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation10: $2, $3
3268 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3302 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 100
3303 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - Insert a file-concatenation job
3309 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 100
3310 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - Insert a file-concatenation job
3330 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3366 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-251
3372 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3372 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3372 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3383 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 10
3383 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 10
4141 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
4147 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
4152 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4375 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1113565324/tmp-905566675/pig-0.17.0-core-h2.jar
4394 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1113565324/tmp1360834526/automaton-1.11-8.jar
4409 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1113565324/tmp-551245505/antlr-runtime-3.4.jar
4424 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1113565324/tmp970530531/joda-time-2.9.4.jar
4441 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4449 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4449 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4449 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4494 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
4494 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
4495 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4527 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1113565324/tmp610115420/pig-0.17.0-core-h2.jar
4539 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1113565324/tmp-1791367555/automaton-1.11-8.jar
4551 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1113565324/tmp-491657817/antlr-runtime-3.4.jar
4564 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1113565324/tmp-897267748/joda-time-2.9.4.jar
4566 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4567 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4567 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4567 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4584 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 2 map-reduce job(s) waiting for submission.
4797 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4837 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
5089 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2556
5089 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases nation1,nation10
5089 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: nation10[12,11],nation10[-1,-1],nation1[16,10] C:  R: 
5094 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2557
5094 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases nation2,nation20
5094 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: nation20[14,11],nation20[-1,-1],nation2[17,10] C:  R: 
5096 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
10111 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
10270 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
10278 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
10279 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 2 map reduce job(s) failed!
10281 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:57:45	2019-01-28 11:57:51	REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2556	nation1,nation10	MAP_ONLY	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	
job_1546715600715_2557	nation2,nation20	MAP_ONLY	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/nation"
Failed to read data from "/tpch/in/nation"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2556	->	null,
null	->	null,
null	->	null,
job_1546715600715_2557	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null


10281 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
10283 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
10302 [main] INFO  org.apache.pig.Main  - Pig script completed in 10 seconds and 472 milliseconds (10472 ms)
Q7 times (sec):	12

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-3-2]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q8
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs23 -param reducers=1 -f queries/Q8.pig

64   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
65   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
889  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1010 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1605 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q8.pig-e521c461-0ed5-4a6c-a633-7523c9dea784
1605 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2752 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 2 time(s).
2798 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
2847 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2891 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2947 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
3053 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $5, $6, $7, $8
3058 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $4, $5, $6
3058 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $3
3059 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $1, $2, $4, $5, $6, $7
3059 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for part: $1, $2, $3, $5, $6, $7, $8
3060 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $3, $4, $7, $8, $9, $10, $11, $12, $13, $14, $15
3060 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for region: $2
3172 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3189 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 100
3190 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - Insert a file-concatenation job
3193 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 100
3194 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - Insert a file-concatenation job
3200 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 100
3200 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 0
3201 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - Insert a file-concatenation job
3219 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3251 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-294
3255 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3256 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3256 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3256 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3265 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 14
3266 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 map-only splittees.
3266 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 out of total 3 MR operators.
3266 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 13
3860 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3866 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3870 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3870 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3870 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4072 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp830833405/tmp-1908786703/pig-0.17.0-core-h2.jar
4091 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp830833405/tmp-32778932/automaton-1.11-8.jar
4110 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp830833405/tmp1886810129/antlr-runtime-3.4.jar
4125 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp830833405/tmp-1668113159/joda-time-2.9.4.jar
4141 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4149 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4149 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4149 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4241 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
4241 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
4242 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4291 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp830833405/tmp258648554/pig-0.17.0-core-h2.jar
4306 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp830833405/tmp-1107692087/automaton-1.11-8.jar
4324 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp830833405/tmp2091352042/antlr-runtime-3.4.jar
4338 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp830833405/tmp2008831892/joda-time-2.9.4.jar
4340 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4340 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4340 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4340 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4359 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
4359 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
4360 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4393 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp830833405/tmp-1446338289/pig-0.17.0-core-h2.jar
4404 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp830833405/tmp1192985296/automaton-1.11-8.jar
4415 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp830833405/tmp-83671239/antlr-runtime-3.4.jar
4428 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp830833405/tmp-1600149082/joda-time-2.9.4.jar
4430 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up multi store job
4431 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4431 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4431 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4444 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 3 map-reduce job(s) waiting for submission.
4645 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4685 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4713 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4950 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2558
4950 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fpart,lineitem,p1,part
4950 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: lineitem[8,11],lineitem[-1,-1],p1[33,5],part[16,7],part[-1,-1],fpart[19,8],fpart[-1,-1],p1[33,5] C:  R: p1[-1,-1]
4955 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2559
4955 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fregion,region
4955 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: region[14,9],region[-1,-1],fregion[17,10],fregion[-1,-1] C:  R: 
4958 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2560
4958 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases nation
4958 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: nation[12,9],nation[-1,-1],nation[-1,-1] C:  R: 
4962 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9976 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
10238 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
10243 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
10249 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
10249 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 3 map reduce job(s) failed!
10251 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:58:10	2019-01-28 11:58:16	REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2558	fpart,lineitem,p1,part	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/part
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/part
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	
job_1546715600715_2560	nation	MULTI_QUERY,MAP_ONLY	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	
job_1546715600715_2559	fregion,region	MAP_ONLY	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/region
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/region
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/part"
Failed to read data from "/tpch/in/lineitem"
Failed to read data from "/tpch/in/nation"
Failed to read data from "/tpch/in/region"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2558	->	null,
job_1546715600715_2560	->	null,null,
null	->	null,
null	->	null,
job_1546715600715_2559	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null


10251 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
10253 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
10272 [main] INFO  org.apache.pig.Main  - Pig script completed in 10 seconds and 451 milliseconds (10451 ms)
Q8 times (sec):	12

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-5-3]
ok: [neu-3-2]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q9
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs23 -param reducers=1 -f queries/Q9.pig

58   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
59   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
877  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
994  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1618 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q9.pig-6610c77b-aa7c-4078-8a39-4b928cc91ab6
1618 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2743 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 1 time(s).
2787 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
2835 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2879 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2933 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
3013 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $1, $2, $3, $5, $6, $7, $8
3017 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for partsupp: $2, $4
3018 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $4, $5, $6
3018 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $2, $3
3019 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $3, $7, $8, $9, $10, $11, $12, $13, $14, $15
3019 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for part: $2, $3, $4, $5, $6, $7, $8
3117 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3147 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 100
3148 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - Insert a file-concatenation job
3168 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3197 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-246
3202 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3202 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3202 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3202 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3210 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 9
3210 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 9
3793 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3799 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3803 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3803 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3804 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3998 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1106623805/tmp1072440915/pig-0.17.0-core-h2.jar
4021 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1106623805/tmp-360477477/automaton-1.11-8.jar
4034 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1106623805/tmp472176427/antlr-runtime-3.4.jar
4048 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1106623805/tmp-1641560440/joda-time-2.9.4.jar
4064 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4072 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4072 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4072 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4160 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
4161 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
4161 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4196 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1106623805/tmp933152886/pig-0.17.0-core-h2.jar
4209 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1106623805/tmp1611091381/automaton-1.11-8.jar
4219 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1106623805/tmp735966384/antlr-runtime-3.4.jar
4233 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1106623805/tmp-1277018557/joda-time-2.9.4.jar
4236 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4236 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4236 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4236 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4252 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 2 map-reduce job(s) waiting for submission.
4445 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4484 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4757 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2561
4757 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fpart,j1,lineitem,part
4757 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: lineitem[8,11],lineitem[-1,-1],j1[22,5],part[18,7],part[-1,-1],fpart[20,8],fpart[-1,-1],j1[22,5] C:  R: j1[-1,-1]
4762 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2562
4762 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases nation
4762 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: nation[12,9],nation[-1,-1] C:  R: 
4766 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9779 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
10018 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
10027 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
10027 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 2 map reduce job(s) failed!
10029 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:58:35	2019-01-28 11:58:42	REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2561	fpart,j1,lineitem,part	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	
job_1546715600715_2562	nation	MAP_ONLY	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/lineitem"
Failed to read data from "/tpch/in/part"
Failed to read data from "/tpch/in/nation"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2561	->	null,
job_1546715600715_2562	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null


10029 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
10031 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
10050 [main] INFO  org.apache.pig.Main  - Pig script completed in 10 seconds and 219 milliseconds (10219 ms)
Q9 times (sec):	12

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-5-3]
ok: [neu-3-2]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-7]
ok: [neu-3-11]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q10
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs23 -param reducers=1 -f queries/Q10.pig

69   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
70   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
939  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1070 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1654 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q10.pig-14964425-e1f0-44c0-aff1-0f3f1f7fc970
1655 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2796 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 1 time(s).
2843 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,FILTER,LIMIT
2891 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2934 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2987 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
3062 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $1, $2, $3, $4, $7, $9, $10, $11, $12, $13, $14, $15
3066 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $2, $3
3067 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $6
3067 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $5, $6, $7, $8
3155 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3195 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3226 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-231
3230 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3231 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3231 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3237 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 7
3238 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 7
3802 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3808 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3812 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3813 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3813 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4032 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1654684654/tmp1339937259/pig-0.17.0-core-h2.jar
4058 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1654684654/tmp-839105716/automaton-1.11-8.jar
4073 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1654684654/tmp1483759281/antlr-runtime-3.4.jar
4090 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1654684654/tmp608884509/joda-time-2.9.4.jar
4106 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4114 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4114 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4114 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4200 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4415 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4704 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2563
4704 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases c1,customer,forders,orders,selc1
4704 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: customer[4,11],customer[-1,-1],c1[24,5],orders[6,9],orders[-1,-1],forders[21,10],forders[-1,-1],c1[24,5] C:  R: selc1[25,8]
4709 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9718 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9899 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9899 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9901 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:59:00	2019-01-28 11:59:07	HASH_JOIN,GROUP_BY,ORDER_BY,FILTER,LIMIT

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2563	c1,customer,forders,orders,selc1	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/customer
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/customer
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/customer"
Failed to read data from "/tpch/in/orders"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2563	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null


9901 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9903 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
10028 [main] INFO  org.apache.pig.Main  - Pig script completed in 10 seconds and 92 milliseconds (10092 ms)
Q10 times (sec):	12

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-5-3]
ok: [neu-3-2]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q11
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs23 -param reducers=1 -f queries/Q11.pig

62   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
63   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
881  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
992  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1587 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q11.pig-968e889f-80eb-499b-9b73-e8610447d952
1587 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2539 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 1 time(s).
2587 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
2637 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2673 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2713 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for partsupp: $4
2717 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $4, $5, $6
2717 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $2, $3
2780 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2857 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
2884 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
2901 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
2915 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-125
2919 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
2920 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
2928 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 6
2928 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 0 map-reduce splittees.
2928 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 0 out of total 3 MR operators.
2928 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 6
3501 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3507 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3511 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3511 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3512 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3735 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1570712297/tmp-957527333/pig-0.17.0-core-h2.jar
3776 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1570712297/tmp-1252164055/automaton-1.11-8.jar
3796 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1570712297/tmp1640489711/antlr-runtime-3.4.jar
3815 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1570712297/tmp217908678/joda-time-2.9.4.jar
3830 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
3839 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3839 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3839 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
3928 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4140 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4431 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2564
4431 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fnation,j1,nation,selj1,supplier
4432 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: supplier[5,11],supplier[-1,-1],j1[11,5],nation[7,9],nation[-1,-1],fnation[9,10],fnation[-1,-1],j1[11,5] C:  R: selj1[13,8]
4436 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9445 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9609 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9610 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9611 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:59:25	2019-01-28 11:59:31	HASH_JOIN,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2564	fnation,j1,nation,selj1,supplier	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/nation"
Failed to read data from "/tpch/in/supplier"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2564	->	null,
null	->	null,null,
null	->	null,
null	->	null,
null	->	null,
null


9612 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9613 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9632 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 812 milliseconds (9812 ms)
Q11 times (sec):	12

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-3-2]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-7]
ok: [neu-3-11]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q12
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs23 -param reducers=1 -f queries/Q12.pig

61   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
61   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
889  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1001 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1594 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q12.pig-bb8ae452-4a94-4994-9664-b0d3be604aa3
1594 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2538 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
2588 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2632 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2673 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $1, $2, $3, $4, $6, $7, $8
2677 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $1, $2, $3, $4, $5, $6, $7, $8, $9, $13, $15
2735 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2816 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
2866 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-111
2871 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
2878 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 4
2878 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 4
3475 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3482 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3486 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3486 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3487 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3692 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1839502955/tmp2034829653/pig-0.17.0-core-h2.jar
3711 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1839502955/tmp1176170304/automaton-1.11-8.jar
3726 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1839502955/tmp1833513588/antlr-runtime-3.4.jar
3755 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1839502955/tmp1092483158/joda-time-2.9.4.jar
3772 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
3781 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3781 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3781 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
3878 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4075 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4381 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2565
4381 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases flineitem,l1,lineitem,orders,sell1
4381 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: orders[4,9],orders[-1,-1],l1[12,5],lineitem[6,11],lineitem[-1,-1],flineitem[8,12],flineitem[-1,-1],l1[12,5] C:  R: sell1[13,8]
4388 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9397 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9578 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9578 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9580 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 11:59:52	2019-01-28 11:59:58	HASH_JOIN,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2565	flineitem,l1,lineitem,orders,sell1	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/orders
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/orders
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/orders"
Failed to read data from "/tpch/in/lineitem"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2565	->	null,
null	->	null,
null	->	null,
null


9580 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9582 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9601 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 771 milliseconds (9771 ms)
Q12 times (sec):	11

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-3-2]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-7]
ok: [neu-3-11]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-3]
changed: [neu-5-10]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-5-1]
changed: [neu-3-7]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q13
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs23 -param reducers=1 -f queries/Q13.pig

60   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
61   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
897  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1008 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1652 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q13.pig-d19f35a4-4b05-4bbc-852c-7d8353771e76
1652 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2528 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_LONG 1 time(s).
2569 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: COGROUP,GROUP_BY,ORDER_BY,FILTER
2617 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2652 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2724 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2807 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for customer: $1, $2, $3, $4, $5, $6, $7
2812 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $3, $4, $5, $6, $7
2915 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
2965 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3000 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-69
3016 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 4
3016 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 4
3631 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3637 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3641 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3641 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3642 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3889 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp56841639/tmp589613114/pig-0.17.0-core-h2.jar
3912 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp56841639/tmp1607387303/automaton-1.11-8.jar
3929 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp56841639/tmp1929580689/antlr-runtime-3.4.jar
3945 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp56841639/tmp1594148141/joda-time-2.9.4.jar
3961 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
3969 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3969 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3969 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4060 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4265 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4564 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2566
4564 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases COG,COG1,COG2,customer,forders,orders,pcustomer,porders
4564 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: orders[5,9],orders[-1,-1],forders[7,10],porders[9,10],COG1[13,7],customer[3,11],pcustomer[-1,-1],COG1[13,7] C:  R: COG2[14,7],COG[15,6]
4570 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9580 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9750 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9750 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9752 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 12:00:17	2019-01-28 12:00:23	COGROUP,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2566	COG,COG1,COG2,customer,forders,orders,pcustomer,porders	COGROUP	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/customer
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/customer
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/customer"
Failed to read data from "/tpch/in/orders"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2566	->	null,
null	->	null,
null	->	null,
null


9752 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9754 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9772 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 950 milliseconds (9950 ms)
Q13 times (sec):	11

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-3-2]
ok: [neu-5-3]
ok: [neu-5-1]
ok: [neu-5-6]
ok: [neu-3-7]
ok: [neu-3-11]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q14
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs23 -param reducers=1 -f queries/Q14.pig

62   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
63   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
882  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
993  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1638 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q14.pig-91c92af0-b32a-4e97-9d3b-d06d15b5d3d3
1638 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2571 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 2 time(s).
2624 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,FILTER
2673 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2716 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2770 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2859 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $0, $2, $3, $4, $7, $8, $9, $11, $12, $13, $14, $15
2951 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
2967 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 1
2973 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
2990 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3007 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3016 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 5
3017 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 map-only splittees.
3017 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 out of total 3 MR operators.
3019 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged MR job 130 into MR job 178
3019 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged MR job 132 into MR job 178
3019 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Requested parallelism of splitter: 1
3019 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 map-reduce splittees.
3019 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 out of total 3 MR operators.
3020 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 3
3667 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3673 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3678 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3678 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3678 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3888 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp833149136/tmp1769102139/pig-0.17.0-core-h2.jar
3909 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp833149136/tmp1441378910/automaton-1.11-8.jar
3923 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp833149136/tmp1919333953/antlr-runtime-3.4.jar
3939 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp833149136/tmp-582206374/joda-time-2.9.4.jar
3955 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
3963 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3963 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3963 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4060 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4259 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4563 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2567
4563 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases filtered_lineitem,lineitem,lineitem2,lineitem_part,part
4564 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: lineitem[3,11],lineitem[-1,-1],filtered_lineitem[7,20],lineitem2[8,12],lineitem_part[10,16],part[5,7],part[-1,-1],lineitem_part[10,16] C:  R: 
4569 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9578 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9744 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9745 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9746 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 12:00:42	2019-01-28 12:00:48	HASH_JOIN,GROUP_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2567	filtered_lineitem,lineitem,lineitem2,lineitem_part,part	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/part
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/part
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/part"
Failed to read data from "/tpch/in/lineitem"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2567	->	null,
null	->	null,
null


9746 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9748 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9767 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 937 milliseconds (9937 ms)
Q14 times (sec):	11

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-5-3]
ok: [neu-3-2]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q15
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs23 -param reducers=1 -f queries/Q15.pig

66   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
67   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
905  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1016 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1597 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q15.pig-359bc66e-dcc4-4c9c-bf2a-fac3fbdea963
1597 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2543 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 1 time(s).
2592 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
2642 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2689 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2743 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2821 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $3, $5, $6
2826 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $0, $1, $3, $4, $7, $8, $9, $11, $12, $13, $14, $15
2936 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
2971 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
2990 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3010 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-116
3017 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3030 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 5
3030 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 0 map-reduce splittees.
3030 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 0 out of total 3 MR operators.
3030 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 5
3640 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3646 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3650 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3650 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3650 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3854 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1424561235/tmp-1599449395/pig-0.17.0-core-h2.jar
3884 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1424561235/tmp1310639261/automaton-1.11-8.jar
3905 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1424561235/tmp-1823667214/antlr-runtime-3.4.jar
3922 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1424561235/tmp-3156884/joda-time-2.9.4.jar
3937 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
3945 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3945 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3945 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4040 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4257 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4543 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2568
4543 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases flineitem,glineitem,lineitem,revenue,sumlineitem
4544 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: lineitem[3,11],lineitem[-1,-1],flineitem[7,12],sumlineitem[9,14],revenue[13,10],glineitem[11,12] C: revenue[13,10],glineitem[11,12] R: revenue[13,10]
4549 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9558 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9732 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9732 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9734 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 12:01:07	2019-01-28 12:01:13	HASH_JOIN,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2568	flineitem,glineitem,lineitem,revenue,sumlineitem	GROUP_BY,COMBINER	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/lineitem"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2568	->	null,null,
null	->	null,
null	->	null,
null	->	null,
null


9735 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9737 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9758 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 935 milliseconds (9935 ms)
Q15 times (sec):	11

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-5-3]
ok: [neu-3-2]
ok: [neu-5-1]
ok: [neu-5-6]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-5-1]
changed: [neu-3-7]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q16
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs23 -param reducers=1 -f queries/Q16.pig

54   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
55   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
887  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1000 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1650 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q16.pig-8a2ed017-6319-4b6b-8ff6-eb7c0b20e7fc
1651 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2678 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_CHARARRAY 4 time(s).
2722 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
2769 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2811 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2855 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for parts: $1, $2, $6, $7, $8
2858 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for partsupp: $2, $3, $4
2859 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $1, $2, $3, $4, $5
2913 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2991 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3030 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3059 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-113
3063 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3064 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3071 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 5
3071 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 5
3607 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3613 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3617 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3618 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3618 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3866 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-1883895954/tmp1091262756/pig-0.17.0-core-h2.jar
3891 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1883895954/tmp-1527537496/automaton-1.11-8.jar
3905 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1883895954/tmp782419546/antlr-runtime-3.4.jar
3921 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-1883895954/tmp555133129/joda-time-2.9.4.jar
3937 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
3944 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3945 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3945 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4035 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4233 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4539 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2569
4540 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fpartsupp,fs1,fsupplier,partsupp,pss,supplier
4540 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: supplier[17,11],fsupplier[19,12],fs1[-1,-1],pss[22,6],partsupp[15,11],partsupp[-1,-1],pss[22,6] C:  R: fpartsupp[24,12]
4546 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9556 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9724 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9724 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9726 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 12:01:32	2019-01-28 12:01:38	HASH_JOIN,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2569	fpartsupp,fs1,fsupplier,partsupp,pss,supplier	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/partsupp
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/partsupp
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/partsupp"
Failed to read data from "/tpch/in/supplier"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2569	->	null,
null	->	null,
null	->	null,
null	->	null,
null


9726 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9728 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9747 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 939 milliseconds (9939 ms)
Q16 times (sec):	11

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-3-2]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-5-1]
changed: [neu-3-7]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q17
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs23 -param reducers=1 -f queries/Q17.pig

60   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
61   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
884  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
995  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1600 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q17.pig-81d66cb6-aa2e-4ab5-afe4-023e12290215
1600 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2509 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 1 time(s).
2510 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_LONG 1 time(s).
2553 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: COGROUP,GROUP_BY,FILTER
2606 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2649 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2703 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2771 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $0, $2, $3, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15
2775 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for part: $1, $2, $4, $5, $7, $8
2864 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
2897 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
2934 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 2
2934 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 2
3527 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3533 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3537 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3537 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3538 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3725 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-320353426/tmp-1651574179/pig-0.17.0-core-h2.jar
3754 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-320353426/tmp-282551092/automaton-1.11-8.jar
3785 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-320353426/tmp-856852867/antlr-runtime-3.4.jar
3824 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-320353426/tmp2096386405/joda-time-2.9.4.jar
3840 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
3848 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3848 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3848 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
3948 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4165 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4451 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2570
4452 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases COG,COG1,COG2,COG3,lineitem,part
4452 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: part[5,7],part[-1,-1],part[8,7],part[9,7],COG1[11,7],lineitem[3,11],lineitem[-1,-1],COG1[11,7] C:  R: COG1[-1,-1],COG1[12,7],COG2[13,7],COG3[15,7],COG[16,6]
4457 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9467 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9631 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9631 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9632 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 12:01:57	2019-01-28 12:02:03	COGROUP,GROUP_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2570	COG,COG1,COG2,COG3,lineitem,part	COGROUP	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/lineitem"
Failed to read data from "/tpch/in/part"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2570	->	null,
null


9633 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9634 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9653 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 824 milliseconds (9824 ms)
Q17 times (sec):	11

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-5-3]
ok: [neu-3-2]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-5-1]
changed: [neu-3-7]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q18
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs23 -param reducers=1 -f queries/Q18.pig

58   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
59   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
875  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
987  [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1583 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q18.pig-976ff41a-ed9f-4a8e-821c-aa0e90508dbf
1584 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2520 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 1 time(s).
2564 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,COGROUP,GROUP_BY,ORDER_BY,FILTER
2612 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2648 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2703 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2774 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $1, $2, $3, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15
2779 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $2, $5, $6, $7, $8
2861 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
2903 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
2933 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-132
2938 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
2945 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 5
2945 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 5
3521 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3526 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3531 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3531 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3531 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3750 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-2094698065/tmp166064392/pig-0.17.0-core-h2.jar
3773 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-2094698065/tmp54064821/automaton-1.11-8.jar
3798 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-2094698065/tmp361311548/antlr-runtime-3.4.jar
3815 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-2094698065/tmp-808362174/joda-time-2.9.4.jar
3831 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
3839 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3839 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3839 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
3934 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4137 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4437 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2571
4438 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases COG,lineitem,lineitem_orders,orders
4438 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: lineitem[3,11],lineitem[-1,-1],COG[11,6],orders[7,9],orders[-1,-1],COG[11,6] C:  R: COG[-1,-1],COG[13,6],lineitem_orders[15,18]
4444 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9454 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9638 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9639 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9640 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 12:02:21	2019-01-28 12:02:27	HASH_JOIN,COGROUP,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2571	COG,lineitem,lineitem_orders,orders	COGROUP	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/lineitem"
Failed to read data from "/tpch/in/orders"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2571	->	null,
null	->	null,
null	->	null,
null	->	null,
null


9641 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9643 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9662 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 830 milliseconds (9830 ms)
Q18 times (sec):	11

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-3-2]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-5-1]
changed: [neu-3-7]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q19
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs23 -param reducers=1 -f queries/Q19.pig

61   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
62   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
890  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1005 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1621 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q19.pig-a4cb9f4f-dd71-4363-bf8a-211751f683d5
1621 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2607 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_LONG 6 time(s).
2608 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 7 time(s).
2654 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,FILTER
2702 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2745 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2800 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
3135 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $0, $2, $3, $7, $8, $9, $10, $11, $12, $15
3139 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for part: $1, $2, $4, $7, $8
3223 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3253 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3283 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3289 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 2
3289 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 2
3864 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3870 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3874 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3875 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3875 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4077 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-224276595/tmp441312490/pig-0.17.0-core-h2.jar
4094 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-224276595/tmp422622846/automaton-1.11-8.jar
4108 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-224276595/tmp1511074505/antlr-runtime-3.4.jar
4130 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp-224276595/tmp1197922885/joda-time-2.9.4.jar
4146 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4154 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4154 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4154 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4270 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4492 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4774 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2572
4774 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fltResult,lineitem,lpart,part,volume
4774 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: part[6,7],part[-1,-1],lpart[8,8],lineitem[4,11],lineitem[-1,-1],lpart[8,8] C:  R: lpart[-1,-1],fltResult[10,12],volume[37,9]
4780 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9790 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9955 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9955 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9957 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 12:02:46	2019-01-28 12:02:52	HASH_JOIN,GROUP_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2572	fltResult,lineitem,lpart,part,volume	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/lineitem"
Failed to read data from "/tpch/in/part"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2572	->	null,
null


9957 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9959 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9978 [main] INFO  org.apache.pig.Main  - Pig script completed in 10 seconds and 163 milliseconds (10163 ms)
Q19 times (sec):	12

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-3-2]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q20
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs23 -param reducers=1 -f queries/Q20.pig

58   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
59   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
887  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1002 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1637 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q20.pig-40b576d5-de94-4021-b159-68655b32f86f
1637 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2662 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 1 time(s).
2708 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,DISTINCT,FILTER
2756 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2800 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2849 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $4, $5, $6
2853 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for nation: $2, $3
2853 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for partsupp: $3, $4
2854 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $0, $3, $5, $6, $7, $8, $9, $11, $12, $13, $14, $15
2854 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for part: $2, $3, $4, $5, $6, $7, $8
2916 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
3000 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3047 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3075 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-233
3080 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3080 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3080 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3081 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3088 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 9
3088 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 9
3648 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3654 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3659 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3659 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3659 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3898 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1685611428/tmp1271534690/pig-0.17.0-core-h2.jar
3922 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1685611428/tmp-93161306/automaton-1.11-8.jar
3937 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1685611428/tmp1932142249/antlr-runtime-3.4.jar
3953 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1685611428/tmp273915101/joda-time-2.9.4.jar
3969 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
3977 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3977 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3977 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4066 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
4067 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
4068 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
4068 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
4068 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4104 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1685611428/tmp1485651892/pig-0.17.0-core-h2.jar
4118 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1685611428/tmp181776018/automaton-1.11-8.jar
4132 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1685611428/tmp-1342137941/antlr-runtime-3.4.jar
4148 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1685611428/tmp-1286709712/joda-time-2.9.4.jar
4150 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4151 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4151 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4151 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4184 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
4185 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
4185 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
4186 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
4186 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4220 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1685611428/tmp-2064451637/pig-0.17.0-core-h2.jar
4232 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1685611428/tmp2091054440/automaton-1.11-8.jar
4244 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1685611428/tmp2048710978/antlr-runtime-3.4.jar
4258 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1685611428/tmp-138758502/joda-time-2.9.4.jar
4260 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4261 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4261 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4261 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4262 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting identity combiner class.
4275 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 3 map-reduce job(s) waiting for submission.
4465 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4503 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4527 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4781 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2573
4781 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases lineitem,lineitem1,lineitem2,lineitem3,lineitem4
4782 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: lineitem[9,11],lineitem[-1,-1],lineitem2[11,12],lineitem1[10,12],lineitem4[13,12],lineitem3[12,12] C: lineitem4[13,12],lineitem3[12,12] R: lineitem4[13,12]
4785 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2574
4785 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases nation,nation1,s_n,supplier
4785 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: supplier[26,11],supplier[-1,-1],s_n[28,6],nation[23,9],nation[-1,-1],nation1[24,10],nation1[-1,-1],s_n[28,6] C:  R: s_n[-1,-1]
4788 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2575
4788 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases part,part2,part3
4788 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: part[3,7],part[-1,-1],part2[5,8],part3[-1,-1] C:  R: 
4791 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9804 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
10039 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
10046 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
10051 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
10051 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 3 map reduce job(s) failed!
10053 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 12:03:11	2019-01-28 12:03:18	HASH_JOIN,GROUP_BY,ORDER_BY,DISTINCT,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2573	lineitem,lineitem1,lineitem2,lineitem3,lineitem4	GROUP_BY,COMBINER	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	
job_1546715600715_2575	part,part2,part3	DISTINCT	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/part
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/part
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	
job_1546715600715_2574	nation,nation1,s_n,supplier	HASH_JOIN	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/lineitem"
Failed to read data from "/tpch/in/part"
Failed to read data from "/tpch/in/nation"
Failed to read data from "/tpch/in/supplier"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2573	->	null,
job_1546715600715_2575	->	null,
null	->	null,
null	->	null,
null	->	null,
job_1546715600715_2574	->	null,
null	->	null,
null	->	null,
null


10054 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
10056 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
10074 [main] INFO  org.apache.pig.Main  - Pig script completed in 10 seconds and 248 milliseconds (10248 ms)
Q20 times (sec):	12

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-3-2]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q21
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs23 -param reducers=1 -f queries/Q21.pig

61   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
62   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
888  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1003 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1627 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q21.pig-fdc74066-25f5-450d-ae5e-e049e46e50f1
1628 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2651 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan  - Encountered Warning IMPLICIT_CAST_TO_LONG 2 time(s).
2702 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER,LIMIT
2753 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2795 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2848 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2947 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for lineitem: $1, $3, $4, $5, $6, $7, $8, $9, $10, $13, $14, $15
2951 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $1, $3, $4, $5, $6, $7, $8
2952 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for supplier: $2, $4, $5, $6
3057 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
3074 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - number of input files: 100
3075 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - Insert a file-concatenation job
3093 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
3127 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-172
3133 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3133 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer  - Rewrite: POPackage->POForEach to POPackage(JoinPackager)
3143 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 10
3143 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 map-only splittees.
3144 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 out of total 3 MR operators.
3144 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 9
3713 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3718 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3723 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3723 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3723 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3946 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1666848019/tmp1171244039/pig-0.17.0-core-h2.jar
3965 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1666848019/tmp-847255717/automaton-1.11-8.jar
3980 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1666848019/tmp-457179640/antlr-runtime-3.4.jar
3994 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1666848019/tmp1777927483/joda-time-2.9.4.jar
4011 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up multi store job
4019 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4019 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4019 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4109 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
4109 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
4110 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
4142 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp1666848019/tmp-1001524736/pig-0.17.0-core-h2.jar
4155 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp1666848019/tmp9800217/automaton-1.11-8.jar
4168 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp1666848019/tmp-1742875424/antlr-runtime-3.4.jar
4183 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp1666848019/tmp69824457/joda-time-2.9.4.jar
4185 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up single store job
4188 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
4188 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
4188 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
4208 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 2 map-reduce job(s) waiting for submission.
4407 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4447 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4712 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2576
4713 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases L2,fL2,gl,lineitem,t1
4713 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: lineitem[5,11],lineitem[-1,-1],gl[16,5] C:  R: L2[18,5],fL2[20,6],t1[21,13]
4720 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2577
4720 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases fn,nation
4720 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: nation[9,9],nation[-1,-1],fn[33,5] C:  R: 
4723 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9736 [main] INFO  org.apache.pig.tools.pigstats.JobStats  - using output size reader: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.FileBasedOutputSizeReader
9743 [main] WARN  org.apache.pig.tools.pigstats.JobStats  - unable to find the output file
java.io.FileNotFoundException: File /user/root/tpch/out_hdfs23/Q21_fL2_fL2 does not exist.
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:904)
	at org.apache.hadoop.hdfs.DistributedFileSystem.access$600(DistributedFileSystem.java:114)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:964)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:961)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:961)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.FileBasedOutputSizeReader.getPathSize(FileBasedOutputSizeReader.java:84)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.FileBasedOutputSizeReader.getOutputSize(FileBasedOutputSizeReader.java:79)
	at org.apache.pig.tools.pigstats.JobStats.getOutputSize(JobStats.java:351)
	at org.apache.pig.tools.pigstats.mapreduce.MRJobStats.addOneOutputStats(MRJobStats.java:464)
	at org.apache.pig.tools.pigstats.mapreduce.MRJobStats.addOutputStatistics(MRJobStats.java:450)
	at org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil.addFailedJobStats(MRPigStatsUtil.java:196)
	at org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil.accumulateStats(MRPigStatsUtil.java:171)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher.launchPig(MapReduceLauncher.java:379)
	at org.apache.pig.backend.hadoop.executionengine.HExecutionEngine.launchPig(HExecutionEngine.java:290)
	at org.apache.pig.PigServer.launchPlan(PigServer.java:1475)
	at org.apache.pig.PigServer.executeCompiledLogicalPlan(PigServer.java:1460)
	at org.apache.pig.PigServer.execute(PigServer.java:1449)
	at org.apache.pig.PigServer.executeBatch(PigServer.java:489)
	at org.apache.pig.PigServer.executeBatch(PigServer.java:472)
	at org.apache.pig.tools.grunt.GruntParser.executeBatch(GruntParser.java:171)
	at org.apache.pig.tools.grunt.GruntParser.processFsCommand(GruntParser.java:1168)
	at org.apache.pig.tools.pigscript.parser.PigScriptParser.parse(PigScriptParser.java:136)
	at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:230)
	at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:205)
	at org.apache.pig.tools.grunt.Grunt.exec(Grunt.java:81)
	at org.apache.pig.Main.run(Main.java:500)
	at org.apache.pig.Main.main(Main.java:175)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:234)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:148)
9748 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9975 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9982 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9982 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 2 map reduce job(s) failed!
9984 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 12:03:36	2019-01-28 12:03:42	REPLICATED_JOIN,HASH_JOIN,GROUP_BY,ORDER_BY,FILTER,LIMIT

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2576	L2,fL2,gl,lineitem,t1	GROUP_BY,MULTI_QUERY	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/lineitem
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	/user/root/tpch/out_hdfs23/Q21_fL2_fL2,
job_1546715600715_2577	fn,nation	MAP_ONLY	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/nation
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/lineitem"
Failed to read data from "/tpch/in/nation"

Output(s):
Failed to produce result in "/user/root/tpch/out_hdfs23/Q21_fL2_fL2"

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2576	->	null,
job_1546715600715_2577	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null	->	null,
null


9984 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9988 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
10007 [main] INFO  org.apache.pig.Main  - Pig script completed in 10 seconds and 178 milliseconds (10178 ms)
Q21 times (sec):	12

Clear buffer cache on HDFS cluster
 _______________
< PLAY [hadoop] >
 ---------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

 ________________________
< TASK [Gathering Facts] >
 ------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

ok: [neu-5-10]
ok: [neu-3-2]
ok: [neu-5-3]
ok: [neu-5-6]
ok: [neu-5-1]
ok: [neu-3-11]
ok: [neu-3-7]
 ____________________________________
< TASK [delete cache from all nodes] >
 ------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

changed: [neu-5-10]
changed: [neu-5-3]
changed: [neu-3-11]
changed: [neu-3-2]
changed: [neu-5-6]
changed: [neu-3-7]
changed: [neu-5-1]
 ____________
< PLAY RECAP >
 ------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

neu-3-11                   : ok=2    changed=1    unreachable=0    failed=0   
neu-3-2                    : ok=2    changed=1    unreachable=0    failed=0   
neu-3-7                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-1                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-10                   : ok=2    changed=1    unreachable=0    failed=0   
neu-5-3                    : ok=2    changed=1    unreachable=0    failed=0   
neu-5-6                    : ok=2    changed=1    unreachable=0    failed=0   

Running Pig Query Q22
Going to run:
/opt/pig-0.17.0/bin/pig -param input=/tpch/in -param output=/user/root/tpch/out_hdfs23 -param reducers=1 -f queries/Q22.pig

60   [main] INFO  org.apache.pig.Main  - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58
60   [main] INFO  org.apache.pig.Main  - Logging error messages to: /local0/pig-err.log
891  [main] INFO  org.apache.pig.impl.util.Utils  - Default bootup file /root/.pigbootup not found
1003 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine  - Connecting to hadoop file system at: hdfs://neu-5-1:9000
1590 [main] INFO  org.apache.pig.PigServer  - Pig Script ID for the session: PIG-Q22.pig-8f241579-ca20-427c-bd66-d33c29626e60
1591 [main] WARN  org.apache.pig.PigServer  - ATS is disabled since yarn.timeline-service.enabled set to false
2615 [main] INFO  org.apache.pig.tools.pigstats.ScriptState  - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,FILTER
2666 [main] INFO  org.apache.pig.data.SchemaTupleBackend  - Key [pig.schematuple] was not set... will not generate code.
2709 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer  - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}
2751 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor  - Columns pruned for orders: $0, $2, $3, $4, $5, $6, $7, $8
2821 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager  - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128
2910 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler  - File concatenation threshold: 100 optimistic? false
2939 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
2958 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil  - Choosing to move algebraic foreach to combiner
2975 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR  - Using Secondary Key Optimization for MapReduce node scope-141
2987 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size before optimization: 6
2988 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 map-reduce splittees.
2988 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - Merged 1 out of total 3 MR operators.
2988 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer  - MR plan size after optimization: 5
3554 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState  - Pig script settings are added to the job
3560 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3
3565 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Reduce phase detected, estimating # of required reducers.
3565 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting Parallelism to 1
3565 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - This job cannot be converted run in-process
3767 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp2119948573/tmp1656749564/pig-0.17.0-core-h2.jar
3794 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp2119948573/tmp184836698/automaton-1.11-8.jar
3810 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp2119948573/tmp-253265649/antlr-runtime-3.4.jar
3839 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Added jar file:/opt/hadoop-2.8.4/share/hadoop/hdfs/lib/joda-time-2.9.4.jar to DistributedCache through /tmp/temp2119948573/tmp-1967280930/joda-time-2.9.4.jar
3854 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler  - Setting up multi store job
3863 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Key [pig.schematuple] is false, will not generate code.
3863 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Starting process to move generated code to distributed cacche
3863 [main] INFO  org.apache.pig.data.SchemaTupleFrontend  - Setting key [pig.schematuple.classes] with classes to deserialize []
3965 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 1 map-reduce job(s) waiting for submission.
4164 [JobControl] INFO  org.apache.pig.builtin.PigStorage  - Using PigTextInputFormat
4468 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - HadoopJobId: job_1546715600715_2578
4468 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Processing aliases avg_customer_filter,customer,customer_filter,customer_filter_group
4468 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - detailed locations: M: customer[3,11],customer[-1,-1],customer_filter[6,18],avg_customer_filter[8,22],customer_filter_group[7,24] C: avg_customer_filter[8,22],customer_filter_group[7,24] R: avg_customer_filter[8,22]
4476 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 0% complete
9488 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - 100% complete
9659 [main] ERROR org.apache.pig.tools.pigstats.PigStats  - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING
9659 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil  - 1 map reduce job(s) failed!
9660 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats  - Script Statistics: 

HadoopVersion	PigVersion	UserId	StartedAt	FinishedAt	Features
2.8.4	0.17.0	root	2019-01-28 12:04:01	2019-01-28 12:04:07	HASH_JOIN,GROUP_BY,ORDER_BY,FILTER

Failed!

Failed Jobs:
JobId	Alias	Feature	Message	Outputs
job_1546715600715_2578	avg_customer_filter,customer,customer_filter,customer_filter_group	MULTI_QUERY,COMBINER	Message: org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/customer
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)
	at org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)
	at java.lang.Thread.run(Thread.java:748)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)
Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://neu-5-1:9000/tpch/in/customer
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)
	... 18 more
	

Input(s):
Failed to read data from "/tpch/in/customer"

Output(s):

Counters:
Total records written : 0
Total bytes written : 0
Spillable Memory Manager spill count : 0
Total bags proactively spilled: 0
Total records proactively spilled: 0

Job DAG:
job_1546715600715_2578	->	null,
null	->	null,
null	->	null,
null	->	null,
null


9661 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher  - Failed!
9662 [main] ERROR org.apache.pig.tools.grunt.Grunt  - ERROR 6017: Stopping execution on job failure with -stop_on_failure option
9772 [main] INFO  org.apache.pig.Main  - Pig script completed in 9 seconds and 852 milliseconds (9852 ms)
Q22 times (sec):	11

Total times (sec):	251

Run Round3 times (sec):	568

Total times (sec):	1811

